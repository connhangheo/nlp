[
    {
        "content": "I want to use a track-bar to change a form's opacity.  This is my code:  decimal trans = trackBar1.Value / 5000; this.Opacity = trans;   When I try to build it, I get this error:     Cannot implicitly convert type 'decimal' to 'double'.   I tried making trans a double, but then the control doesn't work. This code has worked fine for me in VB.NET in the past.  ", 
        "type": "1", 
        "id": "4", 
        "parentId": -1
    }, 
    {
        "content": "I have an absolutely positioned div containing several children, one of which is a relatively positioned div. When I use a percentage-based width on the child div, it collapses to '0' width on Internet Explorer 7, but not on Firefox or Safari.  If I use pixel width, it works. If the parent is relatively positioned, the percentage width on the child works.   Is there something I'm missing here? Is there an easy fix for this besides the pixel-based width on the child? Is there an area of the CSS specification that covers this?  ", 
        "type": "1", 
        "id": "6", 
        "parentId": -1
    }, 
    {
        "content": "An explicit cast to double isn't necessary.  double trans = (double)trackBar1.Value / 5000.0;   Identifying the constant as 5000.0 (or as 5000d) is sufficient:  double trans = trackBar1.Value / 5000.0; double trans = trackBar1.Value / 5000d;  ", 
        "type": "2", 
        "id": "7", 
        "parentId": "4"
    }, 
    {
        "content": "Given a DateTime representing a person's birthday, how do I calculate their age?   ", 
        "type": "1", 
        "id": "9", 
        "parentId": -1
    }, 
    {
        "content": "Given a specific DateTime value, how do I display relative time, like:   2 hours ago 3 days ago a month ago  ", 
        "type": "1", 
        "id": "11", 
        "parentId": -1
    }, 
    {
        "content": "Well, here's how we do it on Stack Overflow.  var ts = new TimeSpan(DateTime.UtcNow.Ticks - dt.Ticks); double delta = Math.Abs(ts.TotalSeconds);  if (delta < 60) {   return ts.Seconds == 1 ? \"one second ago\" : ts.Seconds + \" seconds ago\"; } if (delta < 120) {   return \"a minute ago\"; } if (delta < 2700) // 45 * 60 {   return ts.Minutes + \" minutes ago\"; } if (delta < 5400) // 90 * 60 {   return \"an hour ago\"; } if (delta < 86400) // 24 * 60 * 60 {   return ts.Hours + \" hours ago\"; } if (delta < 172800) // 48 * 60 * 60 {   return \"yesterday\"; } if (delta < 2592000) // 30 * 24 * 60 * 60 {   return ts.Days + \" days ago\"; } if (delta < 31104000) // 12 * 30 * 24 * 60 * 60 {   int months = Convert.ToInt32(Math.Floor((double)ts.Days / 30));   return months <= 1 ? \"one month ago\" : months + \" months ago\"; } int years = Convert.ToInt32(Math.Floor((double)ts.Days / 365)); return years <= 1 ? \"one year ago\" : years + \" years ago\";   Suggestions? Comments? Ways to improve this algorithm? ", 
        "type": "2", 
        "id": "12", 
        "parentId": "11"
    }, 
    {
        "content": "Is there any standard way for a Web Server to be able to determine a user's timezone within a web page? Perhaps from a HTTP header? Or part of the user-agent string? ", 
        "type": "1", 
        "id": "13", 
        "parentId": -1
    }, 
    {
        "content": "What is the difference between Math.Floor() and Math.Truncate() in .NET? ", 
        "type": "1", 
        "id": "14", 
        "parentId": -1
    }, 
    {
        "content": "How do you expose a LINQ query as an ASMX web service? Usually, from the business tier, I can return a typed DataSet or DataTable which can be serialized for transport over ASMX.  How can I do the same for a LINQ query? Is there a way to populate a typed DataSet or DataTable via a LINQ query?:   public static MyDataTable CallMySproc()     {         string conn = ...;      MyDatabaseDataContext db = new MyDatabaseDataContext(conn);         MyDataTable dt = new MyDataTable();      // execute a sproc via LINQ     var query = from dr in db.MySproc().AsEnumerable     select dr;      // copy LINQ query resultset into a DataTable -this does not work !         dt = query.CopyToDataTable();      return dt; }   How can I get the resultset of a LINQ query into a DataSet or DataTable? Alternatively, is the LINQ query serializeable so that I can expose it as an ASMX web service? ", 
        "type": "1", 
        "id": "16", 
        "parentId": -1
    }, 
    {
        "content": "How do I store binary data in MySQL? ", 
        "type": "1", 
        "id": "17", 
        "parentId": -1
    }, 
    {
        "content": "For a table like this:  CREATE TABLE binary_data (     id INT(4) NOT NULL AUTO_INCREMENT PRIMARY KEY,     description CHAR(50),     bin_data LONGBLOB,     filename CHAR(50),     filesize CHAR(50),     filetype CHAR(50) );   Here is a PHP example:  <?php     // store.php3 - by Florian Dittmer <dittmer@gmx.net>     // Example php script to demonstrate the storing of binary files into     // an sql database. More information can be found at http://www.phpbuilder.com/ ?>  <html>     <head><title>Store binary data into SQL Database</title></head>      <body>         <?php             // Code that will be executed if the form has been submitted:              if ($submit) {                 // Connect to the database (you may have to adjust                 // the hostname, username or password).                  mysql_connect(\"localhost\", \"root\", \"password\");                 mysql_select_db(\"binary_data\");                  $data = mysql_real_escape_string(fread(fopen($form_data, \"r\"), filesize($form_data)));                  $result = mysql_query(\"INSERT INTO binary_data (description, bin_data, filename, filesize, filetype) \".                                     \"VALUES ('$form_description', '$data', '$form_data_name', '$form_data_size', '$form_data_type')\");                  $id= mysql_insert_id();                 print \"<p>This file has the following Database ID: <b>$id</b>\";                  mysql_close();             } else {                  // else show the form to submit new data:         ?>         <form method=\"post\" action=\"<?php echo $PHP_SELF; ?>\" enctype=\"multipart/form-data\">             File Description:<br>             <input type=\"text\" name=\"form_description\"  size=\"40\">             <input type=\"hidden\" name=\"MAX_FILE_SIZE\" value=\"1000000\">             <br>File to upload/store in database:<br>             <input type=\"file\" name=\"form_data\"  size=\"40\">             <p><input type=\"submit\" name=\"submit\" value=\"submit\">         </form>          <?php             }         ?>     </body> </html>  ", 
        "type": "2", 
        "id": "18", 
        "parentId": "17"
    }, 
    {
        "content": "Solutions are welcome in any language. :-) I'm looking for the fastest way to obtain the value of \u03c0, as a personal challenge. More specifically I'm using ways that don't involve using #defined constants like M_PI, or hard-coding the number in.  The program below tests the various ways I know of. The inline assembly version is, in theory, the fastest option, though clearly not portable; I've included it as a baseline to compare the other versions against. In my tests, with built-ins, the 4 * atan(1) version is fastest on GCC 4.2, because it auto-folds the atan(1) into a constant. With -fno-builtin specified, the atan2(0, -1) version is fastest.  Here's the main testing program (pitimes.c):  #include <math.h> #include <stdio.h> #include <time.h>  #define ITERS 10000000 #define TESTWITH(x) {                                                       \\     diff = 0.0;                                                             \\     time1 = clock();                                                        \\     for (i = 0; i < ITERS; ++i)                                             \\         diff += (x) - M_PI;                                                 \\     time2 = clock();                                                        \\     printf(\"%s\\t=> %e, time => %f\\n\", #x, diff, diffclock(time2, time1));   \\ }  static inline double diffclock(clock_t time1, clock_t time0) {     return (double) (time1 - time0) / CLOCKS_PER_SEC; }  int main() {     int i;     clock_t time1, time2;     double diff;      /* Warmup. The atan2 case catches GCC's atan folding (which would      * optimise the ``4 * atan(1) - M_PI'' to a no-op), if -fno-builtin      * is not used. */     TESTWITH(4 * atan(1))     TESTWITH(4 * atan2(1, 1))  #if defined(__GNUC__) && (defined(__i386__) || defined(__amd64__))     extern double fldpi();     TESTWITH(fldpi()) #endif      /* Actual tests start here. */     TESTWITH(atan2(0, -1))     TESTWITH(acos(-1))     TESTWITH(2 * asin(1))     TESTWITH(4 * atan2(1, 1))     TESTWITH(4 * atan(1))      return 0; }   And the inline assembly stuff (fldpi.c), noting that it will only work for x86 and x64 systems:  double fldpi() {     double pi;     asm(\"fldpi\" : \"=t\" (pi));     return pi; }   And a build script that builds all the configurations I'm testing (build.sh):  #!/bin/sh gcc -O3 -Wall -c           -m32 -o fldpi-32.o fldpi.c gcc -O3 -Wall -c           -m64 -o fldpi-64.o fldpi.c  gcc -O3 -Wall -ffast-math  -m32 -o pitimes1-32 pitimes.c fldpi-32.o gcc -O3 -Wall              -m32 -o pitimes2-32 pitimes.c fldpi-32.o -lm gcc -O3 -Wall -fno-builtin -m32 -o pitimes3-32 pitimes.c fldpi-32.o -lm gcc -O3 -Wall -ffast-math  -m64 -o pitimes1-64 pitimes.c fldpi-64.o -lm gcc -O3 -Wall              -m64 -o pitimes2-64 pitimes.c fldpi-64.o -lm gcc -O3 -Wall -fno-builtin -m64 -o pitimes3-64 pitimes.c fldpi-64.o -lm   Apart from testing between various compiler flags (I've compared 32-bit against 64-bit too, because the optimisations are different), I've also tried switching the order of the tests around. The atan2(0, -1) version still comes out top every time, though. ", 
        "type": "1", 
        "id": "19", 
        "parentId": -1
    }, 
    {
        "content": "Many years ago, to provide an age calculator gimmick on my website, I wrote a function to calculate age to a fraction. This is a quick port of that function to C# (from the PHP version). I'm afraid I haven't been able to test the C# version, but hope you enjoy all the same!    (Admittedly this is a bit gimmicky for the purposes of showing user profiles on Stack Overflow, but maybe readers will find some use for it. :-))    double AgeDiff(DateTime date1, DateTime date2) {    double years = date2.Year - date1.Year;    /*     * If date2 and date1 + round(date2 - date1) are on different sides     * of 29 February, then our partial year is considered to have 366     * days total, otherwise it's 365. Note that 59 is the day number     * of 29 Feb.     */    double fraction = 365            + (DateTime.IsLeapYear(date2.Year) && date2.DayOfYear >= 59            && (date1.DayOfYear < 59 || date1.DayOfYear > date2.DayOfYear)            ? 1 : 0);    /*     * The only really nontrivial case is if date1 is in a leap year,     * and date2 is not. So let's handle the others first.     */    if (DateTime.IsLeapYear(date2.Year) == DateTime.IsLeapYear(date1.Year))        return years + (date2.DayOfYear - date1.DayOfYear) / fraction;    /*     * If date2 is in a leap year, but date1 is not and is March or     * beyond, shift up by a day.     */    if (DateTime.IsLeapYear(date2.Year)) {        return years + (date2.DayOfYear - date1.DayOfYear                - (date1.DayOfYear >= 59 ? 1 : 0)) / fraction;    }    /*     * If date1 is not on 29 February, shift down date1 by a day if     * March or later. Proceed normally.     */    if (date1.DayOfYear != 59) {        return years + (date2.DayOfYear - date1.DayOfYear                + (date1.DayOfYear > 59 ? 1 : 0)) / fraction;    }    /*     * Okay, here date1 is on 29 February, and date2 is not on a leap     * year. What to do now? On 28 Feb in date2's year, the ``age''     * should be just shy of a whole number, and on 1 Mar should be     * just over. Perhaps the easiest way is to a point halfway     * between those two: 58.5.     */    return years + (date2.DayOfYear - 58.5) / fraction;}", 
        "type": "2", 
        "id": "21", 
        "parentId": "9"
    }, 
    {
        "content": "The best way that I know of because of leap years and everything is:    DateTime birthDate = new DateTime(2000,3,1);int age = (int)Math.Floor((DateTime.Now - birthDate).TotalDays / 365.25D);    Hope this helps.", 
        "type": "2", 
        "id": "22", 
        "parentId": "9"
    }, 
    {
        "content": "If I have a trigger before the update on a table, how can I throw an error that prevents the update on that table? ", 
        "type": "1", 
        "id": "24", 
        "parentId": -1
    }, 
    {
        "content": "I've been having issues getting the C sockets API to work properly in C++. Specifically, even though I'm including sys/socket.h, I'm still getting compile time errors telling me that AF_INET is not defined. Am I missing something obvious, or could this be related to the fact that I'm doing this coding on z/OS and my problems are much more complicated?    Update: Upon further investigation, I discovered that there is an #ifdef that I'm hitting. Apparently z/OS isn't happy unless I define which type of sockets I'm using with:  #define _OE_SOCKETS   Now, I personally have no idea what this _OE_SOCKETS is actually for, so if any z/OS sockets programmers are out there (all 3 of you), perhaps you could give me a rundown on how this all works? ", 
        "type": "1", 
        "id": "25", 
        "parentId": -1
    }, 
    {
        "content": "The answer by phpguy is correct but I think there is a lot of confusion in the  additional details there.  The basic answer is in a BLOB data type / attribute domain. BLOB is short for Binary Large Object and that column data type is specific for handling binary data.  See the relevant manual page for MySQL. ", 
        "type": "2", 
        "id": "26", 
        "parentId": "17"
    }, 
    {
        "content": "@jeff    IMHO yours seems a little long.  However it does seem a little more robust with support for \"yesterday\" and \"years\".  But in my experience when this is used the person is most likely to view the content in the first 30 days.  It is only the really hardcore people that come after that.  So that is why I usually elect to keep this short and simple.    This is the method I am currently using on one of my websites.  This only returns a relative day, hour, time.  And then the user has to slap on \"ago\" in the output.    public static string ToLongString(this TimeSpan time){    string output = String.Empty;    if (time.Days > 0)        output += time.Days + \" days \";    if ((time.Days == 0 || time.Days == 1) && time.Hours > 0)        output += time.Hours + \" hr \";    if (time.Days == 0 && time.Minutes > 0)        output += time.Minutes + \" min \";    if (output.Length == 0)        output += time.Seconds + \" sec\";    return output.Trim();}", 
        "type": "2", 
        "id": "27", 
        "parentId": "11"
    }, 
    {
        "content": "There are no HTTP headers that will report the clients timezone so far although it has been suggested to include it in the HTTP specification.    If it was me, I would probably try to fetch the timezone using clientside JavaScript and then submit it to the server using Ajax or something.", 
        "type": "2", 
        "id": "29", 
        "parentId": "13"
    }, 
    {
        "content": "I've had no trouble using the BSD sockets API in C++, in GNU/Linux. Here's the sample program I used:    #include <sys/socket.h>intmain(){    return AF_INET;}    So my take on this is that z/OS is probably the complicating factor here, however, because I've never used z/OS before, much less programmed in it, I can't say this definitively. :-P", 
        "type": "2", 
        "id": "30", 
        "parentId": "25"
    }, 
    {
        "content": "The parent div needs to have a defined width, either in pixels or as a percentage. In Internet Explorer 7, the parent div needs a defined width for child percentage divs to work correctly. ", 
        "type": "2", 
        "id": "31", 
        "parentId": "6"
    }, 
    {
        "content": "Math.Floor rounds down, Math.Ceiling rounds up, and Math.Truncate rounds towards zero. Thus, Math.Truncate is like Math.Floor for positive numbers, and like Math.Ceiling for negative numbers. Here's the reference.  For completeness, Math.Round rounds to the nearest integer. If the number is exactly midway between two integers, then it rounds towards the even one. Reference.  See also: Pax Diablo's answer. Highly recommended! ", 
        "type": "2", 
        "id": "33", 
        "parentId": "14"
    }, 
    {
        "content": "How do I forcefully unload a ByteArray from memory in ActionScript 3?  I have tried (without success):  byteArray.length = 0; byteArray = new ByteArray();   And  for ( var i:int=0; i < byteArray.length; i++ ) {     byteArray[i] = null; }  ", 
        "type": "1", 
        "id": "34", 
        "parentId": -1
    }, 
    {
        "content": "How can I monitor an SQL Server database for changes to a table without using triggers or modifying the structure of the database in any way? My preferred programming environment is .NET and C#.  I'd like to be able to support any SQL Server 2000 SP4 or newer. My application is a bolt-on data visualization for another company's product. Our customer base is in the thousands, so I don't want to have to put in requirements that we modify the third-party vendor's table at every installation.  By \"changes to a table\" I mean changes to table data, not changes to table structure.  Ultimately, I would like the change to trigger an event in my application, instead of having to check for changes at an interval.    The best course of action given my requirements (no triggers or schema modification, SQL Server 2000 and 2005) seems to be to use the BINARY_CHECKSUM function in T-SQL. The way I plan to implement is this:  Every X seconds run the following query:  SELECT CHECKSUM_AGG(BINARY_CHECKSUM(*)) FROM sample_table WITH (NOLOCK);   and compare that against the stored value. If the value has changed, go through the table row by row using the query  select row_id,BINARY_CHECKSUM(*) from sample_table WITH (NOLOCK);   and compare the returned checksums against stored values. ", 
        "type": "1", 
        "id": "36", 
        "parentId": -1
    }, 
    {
        "content": "Sure I can post a test app.    #include <sys/socket.h>int main(){    return AF_INET;}    Compile/Link Output:    cxx -Wc,xplink -Wl,xplink -o inet_test inet.C    \"./inet.C\", line 5.16: CCN5274 (S) The name lookup for \"AF_INET\" did not find a declaration.    CCN0797(I) Compilation failed for file ./inet.C. Object file not created.    A check of sys/sockets.h does include the definition I need, and as far as I can tell, it is not being blocked by any #ifdef statements.    I have however noticed it contains a the following:    #ifdef __cplusplus  extern \"C\" {#endif    which encapsulates basically the whole file. Not sure if it matters.", 
        "type": "2", 
        "id": "37", 
        "parentId": "25"
    }, 
    {
        "content": "I am aware that in .NET there are three timer types (see Comparing the Timer Classes in the .NET Framework Class Library). I have chosen a threaded timer as the other types can drift if the main thread is busy, and I need this to be reliable.  The way this timer works in the control of the timer is put on another thread so it can always tick along with the work begin completed on the parent thread when it is not busy.  The issue with this timer in a console application is that while the timer is ticking along on another thread the main thread is not doing anything so the application closes.  I tried adding a while true loop, but then the main thread is too busy when the timer does go off. ", 
        "type": "1", 
        "id": "39", 
        "parentId": -1
    }, 
    {
        "content": "I am starting a new web application in PHP and this time around I want to create something that people can extend by using a plugin interface.   How does one go about writing 'hooks' into their code so that plugins can attach to specific events? ", 
        "type": "1", 
        "id": "42", 
        "parentId": -1
    }, 
    {
        "content": "Consider using a ManualResetEvent to block the main thread at the end of its processing, and call Reset() on it once the timer's processing has finished.  If this is something that needs to run constantly, consider moving this into a service process instead of a console app. ", 
        "type": "2", 
        "id": "44", 
        "parentId": "39"
    }, 
    {
        "content": "You can use something like Console.ReadLine() to block the main thread, so other background threads (like timer threads) will still work. You may also use an AutoResetEvent to block the execution, then (when you need to) you can call Set() method on that AutoResetEvent object to release the main thread. Also ensure that your reference to Timer object doesn't go out of scope and garbage collected. ", 
        "type": "2", 
        "id": "45", 
        "parentId": "39"
    }, 
    {
        "content": "Let's say you create a Wizard in an HTML form. One button goes back and one goes forward.  Since the back button appears first in the markup, when you press Enter it will use that button to submit the form.   Example:  <form>    <input type=\"text\" name=\"field1\" /> <!-- put your cursor in this field and press Enter -->     <input type=\"submit\" name=\"prev\" value=\"Previous Page\" /> <!-- This is the button that will submit -->    <input type=\"submit\" name=\"next\" value=\"Next Page\" /> <!-- But this is the button that I WANT to submit --> </form>   What I would like to do, is get to decide which button is used to submit the form when a user presses Enter. That way, when you press Enter the Wizard will move to the next page, not the previous. Do you have to use tabindex to do this? ", 
        "type": "1", 
        "id": "48", 
        "parentId": -1
    }, 
    {
        "content": "Here is one hack that may work. It isn't clean, but it looks like it might work:  Essentially, you just try to update a column that doesn't exist. ", 
        "type": "2", 
        "id": "49", 
        "parentId": "24"
    }, 
    {
        "content": "Why don't you want to use triggers.  They are a good thing if you use them correctly.  If you use them as a way to enforce referential integrity that is when they go from good to bad.  But if you use them for monitoring, they are not really considered taboo.", 
        "type": "2", 
        "id": "51", 
        "parentId": "36"
    }, 
    {
        "content": "Have a look at this article    http://www.gskinner.com/blog/archives/2006/06/as3_resource_ma.html    IANA actionscript programmer, however the feeling I'm getting is that, because the garbage collector might not run when you want it to.    Hence  http://www.craftymind.com/2008/04/09/kick-starting-the-garbage-collector-in-actionscript-3-with-air/    So I'd recommend trying out their collection code and see if it helps    private var gcCount:int;private function startGCCycle():void{    gcCount = 0;    addEventListener(Event.ENTER_FRAME, doGC);}private function doGC(evt:Event):void{    flash.system.System.gc();    if(++gcCount > 1){        removeEventListener(Event.ENTER_FRAME, doGC);        setTimeout(lastGC, 40);    }}private function lastGC():void{    flash.system.System.gc();}", 
        "type": "2", 
        "id": "52", 
        "parentId": "34"
    }, 
    {
        "content": "(I'm not positive about this, but...)  AS3 uses a non-deterministic garbage collection. Which means that unreferenced memory will be freed up whenever the runtime feels like it (typically not unless there's a reason to run, since it's an expensive operation to execute). This is the same approach used by most modern garbage collected languages (like C# and Java as well).  Assuming there are no other references to the memory pointed to by byteArray or the items within the array itself, the memory will be freed at some point after you exit the scope where byteArray is declared.  You can force a garbage collection, though you really shouldn't. If you do, do it only for testing... if you do it in production, you'll hurt performance much more than help it.  To force a GC, try (yes, twice):  flash.system.System.gc(); flash.system.System.gc();   You can read more here. ", 
        "type": "2", 
        "id": "53", 
        "parentId": "34"
    }, 
    {
        "content": "Give your submit buttons same name like this:  <input type=\"submit\" name=\"submitButton\" value=\"Previous Page\" /> <input type=\"submit\" name=\"submitButton\" value=\"Next Page\" />   When the user presses enter and the Request goes to server, you can check the value for submitButton on your server-side code which contains a collection of form name/value pairs. For example in classic ASP:  If Request.Form(\"submitButton\") = \"Previous Page\" Then     ' Code for Previous Page ElseIf Request.Form(\"submitButton\") = \"Next Page\" Then     ' Code for Next Page End If   Reference: Using multiple submit buttons on a single form ", 
        "type": "2", 
        "id": "56", 
        "parentId": "48"
    }, 
    {
        "content": "Would it be possible for you to change the previous button type into a button like this:    <input type=\"button\" name=\"prev\" value=\"Previous Page\" />   Now the Next button would be the default, plus you could also add the default attribute to it so that your browser will highlight it like so:  <input type=\"submit\" name=\"next\" value=\"Next Page\" default />   Hope that helps. ", 
        "type": "2", 
        "id": "58", 
        "parentId": "48"
    }, 
    {
        "content": "Let's say I have a DataTable with a Name column. I want to have a collection of the unique names ordered alphabetically. The following query ignores the order by clause.  var names =     (from DataRow dr in dataTable.Rows     orderby (string)dr[\"Name\"]     select (string)dr[\"Name\"]).Distinct();   Why does the orderby not get enforced? ", 
        "type": "1", 
        "id": "59", 
        "parentId": -1
    }, 
    {
        "content": "Unfortunately when it comes to memory management in Flash/actionscript there isn't a whole lot you can do. ActionScript was designed to be easy to use (so they didn't want people to have to worry about memory management)  The following is a workaround, instead of creating a ByteArray variable try this.  var byteObject:Object = new Object();  byteObject.byteArray = new ByteArray();  ...  //Then when you are finished delete the variable from byteObject delete byteObject.byteArray;   Where byteArray is a dynamic property of byteObject, you can free the memory that was allocated for it. ", 
        "type": "2", 
        "id": "60", 
        "parentId": "34"
    }, 
    {
        "content": "Where can I find a list of the MIME types and identifying characters for Office 2007 files?  I have an upload form that is restricting uploads based on extension and identifying characters, but I cannot seem to find the Office 2007 MIME types. ", 
        "type": "1", 
        "id": "61", 
        "parentId": -1
    }, 
    {
        "content": "The problem is that the Distinct  operator does not grant that it will  maintain the original order of  values.  So your query will need to work like this  var names = (from DataRow dr in dataTable.Rows              select (string)dr[\"Name\"]).Distinct().OrderBy( name => name );  ", 
        "type": "2", 
        "id": "62", 
        "parentId": "59"
    }, 
    {
        "content": "Office 2007 MIME Types for IIS   .docm, application/vnd.ms-word.document.macroEnabled.12 .docx, application/vnd.openxmlformats-officedocument.wordprocessingml.document .dotm, application/vnd.ms-word.template.macroEnabled.12 .dotx, application/vnd.openxmlformats-officedocument.wordprocessingml.template .potm, application/vnd.ms-powerpoint.template.macroEnabled.12 .potx, application/vnd.openxmlformats-officedocument.presentationml.template .ppam, application/vnd.ms-powerpoint.addin.macroEnabled.12 .ppsm, application/vnd.ms-powerpoint.slideshow.macroEnabled.12 .ppsx, application/vnd.openxmlformats-officedocument.presentationml.slideshow .pptm, application/vnd.ms-powerpoint.presentation.macroEnabled.12 .pptx, application/vnd.openxmlformats-officedocument.presentationml.presentation .xlam, application/vnd.ms-excel.addin.macroEnabled.12 .xlsb, application/vnd.ms-excel.sheet.binary.macroEnabled.12 .xlsm, application/vnd.ms-excel.sheet.macroEnabled.12 .xlsx, application/vnd.openxmlformats-officedocument.spreadsheetml.sheet .xltm, application/vnd.ms-excel.template.macroEnabled.12 .xltx, application/vnd.openxmlformats-officedocument.spreadsheetml.template  ", 
        "type": "2", 
        "id": "65", 
        "parentId": "61"
    }, 
    {
        "content": "How do you page through a collection in LINQ given that you have a startIndex and a count? ", 
        "type": "1", 
        "id": "66", 
        "parentId": -1
    }, 
    {
        "content": "It is very simple with the Skip and Take extension methods.  var query = from i in ideas             select i;  var paggedCollection = query.Skip(startIndex).Take(count);  ", 
        "type": "2", 
        "id": "68", 
        "parentId": "66"
    }, 
    {
        "content": "Here's a general description of a technique for calculating pi that I learnt in high school.  I only share this because I think it is simple enough that anyone can remember it, indefinitely, plus it teaches you the concept of \"Monte-Carlo\" methods -- which are statistical methods of arriving at answers that don't immediately appear to be deducible through random processes.  Draw a square, and inscribe a quadrant (one quarter of a semi-circle) inside that square (a quadrant with radius equal to the side of the square, so it fills as much of the square as possible)  Now throw a dart at the square, and record where it lands -- that is, choose a random point anywhere inside the square. Of course, it landed inside the square, but is it inside the semi-circle? Record this fact.  Repeat this process many times -- and you will find there is a ratio of the number of points inside the semi-circle versus the total number thrown, call this ratio x.  Since the area of the square is r times r, you can deduce that the area of the semi circle is x times r times r (that is, x times r squared). Hence x times 4 will give you pi.   This is not a quick method to use. But it's a nice example of a Monte Carlo method. And if you look around, you may find that many problems otherwise outside your computational skills can be solved by such methods. ", 
        "type": "2", 
        "id": "71", 
        "parentId": "19"
    }, 
    {
        "content": "I've got all these comments that I want to make into 'RDoc comments', so they can be formatted appropriately and viewed using ri.  Can anyone get me started on understanding how to use RDoc? ", 
        "type": "1", 
        "id": "72", 
        "parentId": -1
    }, 
    {
        "content": "@Jax: The extern \"C\" thing matters, very very much. If a header file doesn't have one, then (unless it's a C++-only header file), you would have to enclose your #include with it:    extern \"C\" {#include <sys/socket.h>// include other similarly non-compliant header files}    Basically, anytime where a C++ program wants to link to C-based facilities, the extern \"C\" is vital. In practical terms, it means that the names used in external references will not be mangled, like normal C++ names would. Reference.", 
        "type": "2", 
        "id": "73", 
        "parentId": "25"
    }, 
    {
        "content": "I believe the easiest way would be to follow Jeff's own advice and have a look around existing code. Try looking at Wordpress, Drupal, Joomla and other well known PHP-based CMS's to see how their API hooks look and feel. This way you can even get ideas you may have not thought of previously to make things a little more rubust.    A more direct answer would be to write general files that they would \"include_once\" into their file that would provide the usability they would need. This would be broken up into categories and NOT provided in one MASSIVE \"hooks.php\" file. Be careful though, because what ends up happening is that files that they include end up having more and more dependencies and functionality improves. Try to keep API dependencies low. I.E fewer files for them to include.", 
        "type": "2", 
        "id": "76", 
        "parentId": "42"
    }, 
    {
        "content": "You could use an Observer pattern.  A simple functional way to accomplish this:    <?php/** Plugin system **/$listeners = array();/* Create an entry point for plugins */function hook(){  global $listeners;  $num_args = func_num_args();  $args = func_get_args();  if($num_args < 2)    trigger_error(\"Insufficient arguments\", E_USER_ERROR);  // Hook name should always be first argument  $hook_name = array_shift($args);  if(!isset($listeners[$hook_name]))    return; // No plugins have registered this hook  foreach($listeners[$hook_name] as $func){    $args = $func($args);   }  return $args;}/* Attach a function to a hook */function add_listener($hook, $function_name){  global $listeners;  $listeners[$hook][] = $function_name;}//////////////////////////** Sample Plugin **/add_listener('a_b', 'my_plugin_func1');add_listener('str', 'my_plugin_func2');function my_plugin_func1($args){  return array(4, 5);}function my_plugin_func2($args){  return str_replace('sample', 'CRAZY', $args[0]);}//////////////////////////** Sample Application **/$a = 1;$b = 2;list($a, $b) = hook('a_b', $a, $b);$str  = \"This is my sample application\\n\";$str .= \"$a + $b = \".($a+$b).\"\\n\";$str .= \"$a * $b = \".($a*$b).\"\\n\";$str = hook('str', $str);echo $str;?>    Output:    This is my CRAZY application4 + 5 = 94 * 5 = 20    Notes:    For this example source code, you must declare all your plugins before the actual source code that you want to be extendable.  I've included an example of how to handle single or multiple values being passed to the plugin.  The hardest part of this is writing the actual documentation which lists what arguments get passed to each hook.    This is just one method of accomplishing a plugin system in PHP.  There are better alternatives, I suggest you check out the WordPress Documentation for more information.    Sorry, it appears underscore characters are replaced by HTML entities by Markdown?  I can re-post this code when this bug gets fixed.    Edit: Nevermind, it only appears that way when you are editing", 
        "type": "2", 
        "id": "77", 
        "parentId": "42"
    }, 
    {
        "content": "It sounds like this.Opacity is a double value, and the compiler doesn't like you trying to cram a decimal value into it. ", 
        "type": "2", 
        "id": "78", 
        "parentId": "4"
    }, 
    {
        "content": "The version of Subclipse (1.2.4) currently available through Aptana's automatic Plugins Manager does not work with the newest version of Subversion.  I see on the Subclipse website however that they have 1.4.2 out for Eclipse. So I added a new remote update site to my Update manager. When I tried to install it, it told me I needed Mylyn 3.0.0. So after much searching I found Mylyn 3.0.0 and added another new remote update site to my update manager. Then when I tried to install that, it told me I needed org.eclipse.ui 3.3.0 or equivalent.  Looking at the configuration details for Aptana, it looks like it is built against eclipse 3.2.2.  Does anyone know if there is a way to upgrade the version of Eclipse Aptana that is built against to 3.3.0? Or if there is some other way to get Subclipse to work with the very newest version of Subversion?  I know this isn't necessarily a \"programming\" question, but I hope it's ok since it's highly relevant to the programming experience. ", 
        "type": "1", 
        "id": "79", 
        "parentId": -1
    }, 
    {
        "content": "I've written a database generation script in SQL and want to execute it in my Adobe AIR application:  Create Table tRole (       roleID integer Primary Key       ,roleName varchar(40) ); Create Table tFile (     fileID integer Primary Key     ,fileName varchar(50)     ,fileDescription varchar(500)     ,thumbnailID integer     ,fileFormatID integer     ,categoryID integer     ,isFavorite boolean     ,dateAdded date     ,globalAccessCount integer     ,lastAccessTime date     ,downloadComplete boolean     ,isNew boolean     ,isSpotlight boolean     ,duration varchar(30) ); Create Table tCategory (     categoryID integer Primary Key     ,categoryName varchar(50)     ,parent_categoryID integer ); ...   I execute this in Adobe AIR using the following methods:  public static function RunSqlFromFile(fileName:String):void {     var file:File = File.applicationDirectory.resolvePath(fileName);     var stream:FileStream = new FileStream();     stream.open(file, FileMode.READ)     var strSql:String = stream.readUTFBytes(stream.bytesAvailable);     NonQuery(strSql); }  public static function NonQuery(strSQL:String):void {     var sqlConnection:SQLConnection = new SQLConnection();     sqlConnection.open(File.applicationStorageDirectory.resolvePath(DBPATH);     var sqlStatement:SQLStatement = new SQLStatement();     sqlStatement.text = strSQL;     sqlStatement.sqlConnection = sqlConnection;     try     {         sqlStatement.execute();     }     catch (error:SQLError)     {         Alert.show(error.toString());     } }   No errors are generated, however only tRole exists. It seems that it only looks at the first query (up to the semicolon- if I remove it, the query fails). Is there a way to call multiple queries in one statement? ", 
        "type": "1", 
        "id": "80", 
        "parentId": -1
    }, 
    {
        "content": "I believe you have answered your own question...  System.totalMemory gives you the total amount of memory being \"used\", not allocated. It is accurate that your application may only be using 20mb, but it has 5mb that is free for future allocations.  I'm not sure if the Adobe docs would shed light on the way that it manages memory... ", 
        "type": "2", 
        "id": "81", 
        "parentId": "34"
    }, 
    {
        "content": "Have a DTS job (or a job that is started by a windows service) that runs at a given interval. Each time it is run, it gets information about the given table by using the system INFORMATION_SCHEMA tables, and records this data in the data repository. Compare the data returned regarding the structure of the table with the data returned the previous time. If it is different, then you know that the structure has changed.    Example query to return information regarding all of the columns in table ABC (ideally listing out just the columns from the INFORMATION_SCHEMA table that you want, instead of using select * like I do here):    select * from INFORMATION_SCHEMA.COLUMNS where TABLE_NAME = 'ABC'      You would monitor different columns and INFORMATION_SCHEMA views depending on how exactly you define \"changes to a table\".", 
        "type": "2", 
        "id": "82", 
        "parentId": "36"
    }, 
    {
        "content": "If you use a return type of IEnumerable, you can return your query variable directly. ", 
        "type": "2", 
        "id": "84", 
        "parentId": "16"
    }, 
    {
        "content": "What are your best practices around creating flat file database structures in PHP?  A lot of the more mature PHP flat file frameworks I see out there attempt to implement SQL-like query syntax, which is over the top for my purposes in most cases (I would just use a database at that point).    Are there any elegant tricks out there to get good performance and features with the small code overhead one would want by taking on this problem in the first place?", 
        "type": "1", 
        "id": "85", 
        "parentId": -1
    }, 
    {
        "content": "A more generic answer for the generic question \"Decimal vs Double?\": Decimal for monetary calculations to preserve the precision, Double for scientific calculations that do not get affected by small differences. Since Double is a type which is native to the CPU (internal representation is stored in base 2), calculations made with Double perform better then Decimal (which is represented in base 10 internally). ", 
        "type": "2", 
        "id": "86", 
        "parentId": "4"
    }, 
    {
        "content": "One framework I'm considering would be for a blogging platform. Since just about any possible view of data you would want would be sorted by date, I was thinking about this structure:  One directory per content node:  ./content/YYYYMMDDHHMMSS/   Subdirectories of each node including    /tags   /authors   /comments     As well as simple text files in the node directory for pre- and post-rendered content and the like.  This would allow a simple PHP glob() call (and probably a reversal of the result array) to query on just about anything within the content structure:  glob(\"content/*/tags/funny\");     Would return paths including all articles tagged \"funny\". ", 
        "type": "2", 
        "id": "87", 
        "parentId": "85"
    }, 
    {
        "content": "So I find myself porting a game, that was originally written for the Win32 API, to Linux (well, porting the OS X port of the Win32 port to Linux). I have implemented QueryPerformanceCounter by giving the uSeconds since the process start up:    BOOL QueryPerformanceCounter(LARGE_INTEGER* performanceCount) {     gettimeofday(&currentTimeVal, NULL);     performanceCount->QuadPart = (currentTimeVal.tv_sec - startTimeVal.tv_sec);     performanceCount->QuadPart *= (1000 * 1000);     performanceCount->QuadPart += (currentTimeVal.tv_usec - startTimeVal.tv_usec);      return true; }   This, coupled with QueryPerformanceFrequency() giving a constant 1000000 as the frequency, works well on my machine, giving me a 64 bit variable that contains uSeconds since the program's start up. So is this portable? I don't want to discover it works differently if the kernel was compiled in a certain way or anything like that. I am fine with it being non-portable to something other than Linux, however. ", 
        "type": "1", 
        "id": "88", 
        "parentId": -1
    }, 
    {
        "content": "I've had problems with JavaHL in Eclipse Ganymede, when it worked fine in Eclipse Europa.  I'm not sure how Aptana is different, but try either upgrading JavaHL or switching to the pure-java SVNKit implementation within the Subclipse config.", 
        "type": "2", 
        "id": "89", 
        "parentId": "79"
    }, 
    {
        "content": "Are there any really good tutorials explaining branching and merging with Apache Subversion?   All the better if it's specific to TortoiseSVN client. ", 
        "type": "1", 
        "id": "90", 
        "parentId": -1
    }, 
    {
        "content": "Version Control with Subversion    A very good resource for source control in general. Not really TortoiseSVN specific, though.", 
        "type": "2", 
        "id": "92", 
        "parentId": "90"
    }, 
    {
        "content": "From my experience, and from what I've read across the internet, the answer is \"No,\" it is not guaranteed.  It depends on CPU speed, operating system, flavor of Linux, etc.", 
        "type": "2", 
        "id": "93", 
        "parentId": "88"
    }, 
    {
        "content": "One way to store flat-file content would be to save literal arrays to php files.  For example:  $data = array();  if( $_POST ) {     $data = $_POST;      $content = \"<?php\\n\";     $content .= '$data=' . var_export($data, true) . \"\\n\";     $content .= \"?>\";      save_to_file($filename, $content); }  // echo form  ", 
        "type": "2", 
        "id": "97", 
        "parentId": "85"
    }, 
    {
        "content": "Maybe. But you have bigger problems. gettimeofday() can result in incorrect timings if there are processes on your system that change the timer (ie, ntpd). On a \"normal\" linux, though, I believe the resolution of gettimeofday() is 10us. It can jump forward and backward and time, consequently, based on the processes running on your system. This effectively makes the answer to your question no.  You should look into clock_gettime(CLOCK_MONOTONIC) for timing intervals. It suffers from several less issues due to things like multi-core systems and external clock settings.  Also, look into the clock_getres() function. ", 
        "type": "2", 
        "id": "98", 
        "parentId": "88"
    }, 
    {
        "content": "    The actual resolution of gettimeofday() depends on the hardware architecture. Intel processors as well as SPARC machines offer high resolution timers that measure microseconds. Other hardware architectures fall back to the system\u2019s timer, which is typically set to 100 Hz. In such cases, the time resolution will be less accurate.       I obtained this answer from High Resolution Time Measurement and Timers, Part I", 
        "type": "2", 
        "id": "99", 
        "parentId": "88"
    }, 
    {
        "content": "That's true.  serialize() can be pretty useful for that as well.  I think the trick to coming up with a viable system is finding some way to index the data nodes without killing yourself with complexity. ", 
        "type": "2", 
        "id": "100", 
        "parentId": "85"
    }, 
    {
        "content": "Javascript is the easiest way to get the client's local time.  I would suggest using an XMLHttpRequest to send back the local time, and if that fails, fall back to the timezone detected based on their IP address.  As far as geolocation, I've used MaxMind GeoIP on several projects and it works well, though I'm not sure if they provide timezone data.  It's a service you pay for and they provide monthly updates to your database.  They provide wrappers in several web languages. ", 
        "type": "2", 
        "id": "103", 
        "parentId": "13"
    }, 
    {
        "content": "In .NET perspective:   What is a Memory Leak? How can you determine whether your application leaks? What are the effects? How can you prevent a memory leak? If your application has memory leak, does it go away when the process exits or is killed? Or do memory leaks in your application affect other processes on the system even after process completion? And what about unmanaged code accessed via COM Interop and/or P/Invoke?   I have some answers for these questions myself, but they are incomplete. What do you think? ", 
        "type": "1", 
        "id": "104", 
        "parentId": -1
    }, 
    {
        "content": "I guess in a managed environment, a leak would be you keeping an unnecessary reference to a large chunk of memory around.   ", 
        "type": "2", 
        "id": "107", 
        "parentId": "104"
    }, 
    {
        "content": "I've been using TortoiseSVN  in a Windows environment for quite some time.  It seems very feature-complete and nicely integrated into the Windows shell, and more importantly, it's fairly painless to teach to colleagues with little or no experience with source control.  However, since we have moved to Windows Vista 64bit, Tortoise has been very buggy and has seemed to cause lots of explorer.exe abnormalities and crashes.  This has happened both with older versions of the software and the latest version (1.5.1 build 13563).  I was curious if anyone has suggestions for other Subversion clients that will run on Windows (specifically Vista 64bit).  Developers here use a variety of text editors so using Visual Studio or Dreamweaver for SVN is not ideal.  I have heard great things about Cornerstone, and would love something similar for Windows if it exists.    I'm correlating the Vista/explorer problems with Tortoise because they normally occur when I'm using the functionality in Tortoise.  Sometimes bringing up the \"merge\" screen will cause the GUI to start acting very strange and eventually hang or crash.  I did not see 1.5.2 -- I'm installing now, maybe that will fix some of my issues. ", 
        "type": "1", 
        "id": "108", 
        "parentId": -1
    }, 
    {
        "content": "Recently our site has been deluged with the resurgence of the Asprox botnet SQL injection attack. Without going into details, the attack attempts to execute SQL code by encoding the T-SQL commands in an ASCII encoded BINARY string. It looks something like this:  DECLARE%20@S%20NVARCHAR(4000);SET%20@S=CAST(0x44004500...06F007200%20AS%20NVARCHAR(4000));EXEC(@S);--   I was able to decode this in SQL, but I was a little wary of doing this since I didn't know exactly what was happening at the time.  I tried to write a simple decode tool, so I could decode this type of text without even touching SQL Server. The main part I need decoded is:  CAST(0x44004500...06F007200 AS NVARCHAR(4000))   I've tried all of the following commands with no luck:  txtDecodedText.Text =     System.Web.HttpUtility.UrlDecode(txtURLText.Text); txtDecodedText.Text =     Encoding.ASCII.GetString(Encoding.ASCII.GetBytes(txtURLText.Text)); txtDecodedText.Text =     Encoding.Unicode.GetString(Encoding.Unicode.GetBytes(txtURLText.Text)); txtDecodedText.Text =     Encoding.ASCII.GetString(Encoding.Unicode.GetBytes(txtURLText.Text)); txtDecodedText.Text =     Encoding.Unicode.GetString(Convert.FromBase64String(txtURLText.Text));   What is the proper way to translate this encoding without using SQL Server? Is it possible? I'll take VB.NET code since I'm familiar with that too.    Okay, I'm sure I'm missing something here, so here's where I'm at.  Since my input is a basic string, I started with just a snippet of the encoded portion - 4445434C41 (which translates to DECLA) - and the first attempt was to do this...  txtDecodedText.Text = Encoding.UTF8.GetString(Encoding.UTF8.GetBytes(txtURL.Text));   ...and all it did was return the exact same thing that I put in, since it converted each character into is byte.  I realized that I need to parse each two characters into a byte manually since I don't know of any methods yet that will do that, so now my little decoder looks something like this:  while (!boolIsDone) {     bytURLChar = byte.Parse(txtURLText.Text.Substring(intParseIndex, 2));     bytURL[intURLIndex] = bytURLChar;     intParseIndex += 2;     intURLIndex++;      if (txtURLText.Text.Length - intParseIndex < 2)     {         boolIsDone = true;     } }  txtDecodedText.Text = Encoding.UTF8.GetString(bytURL);   Things look good for the first couple of pairs, but then the loop balks when it gets to the \"4C\" pair and says that the string is in the incorrect format.  Interestingly enough, when I step through the debugger and to the GetString method on the byte array that I was able to parse up to that point, I get \",-+\" as the result.  How do I figure out what I'm missing - do I need to do a \"direct cast\" for each byte instead of attempting to parse it? ", 
        "type": "1", 
        "id": "109", 
        "parentId": -1
    }, 
    {
        "content": "I will concur with Bernard as to in .net what a mem leak would be.  You could profile your application to see its memory use, and determine that if its managing a lot of memory when it should not be you could say it has a leak.  In managed terms I will put my neck on the line to say it does go away once the process is killed/removed.  Unmanaged code is its own beast and if a leak exists within it, it will follow a standard mem. leak definition. ", 
        "type": "2", 
        "id": "110", 
        "parentId": "104"
    }, 
    {
        "content": "I have been using the 64Bit version of TortoiseSVN for ages and I have never had issues with it on Windows 64Bit or Vista 64Bit. I am currently not aware of any other similiar SVN clients that do work on Vista. Is it possible the problem could lie within the configuration of TortoiseSVN or even the installation of Vista? Is the problem occurring on Vista native or SP 1?", 
        "type": "2", 
        "id": "111", 
        "parentId": "108"
    }, 
    {
        "content": "The best explanation I've seen is in Chapter 7 of the free Foundations of Programming ebook.  Basically, in .NET a memory leak occurs when referenced objects are rooted and thus cannot be garbage collected. This occurs accidentally when you hold on to references beyond the intended scope.  You'll know that you have leaks when you start getting outofmemoryexceptions or your memory usage goes up beyond what you'd expect (perfmon has nice memory counters).   Understanding .NET's memory model is your best way of avoiding it. Specifically, understanding how the garbage collector works and how references work (again, I refer you to chapter 7 of the ebook). Also, be mindful of common pitfalls, probably the most common being events. If object A registered to an event on object B, then object A will stick around until object B disappears because B holds a reference to A. The solution is to unregister your events when you're done.   Of course, a good memory profile will let you see your object graphs and explore the nesting/referencing of your objects to see where references are coming from and what root object is responsible (red-gate ants profile, JetBrains dotMemory, memprofiler are really good choices, or you can use the text-only windbg and sos, but I'd strongly recommend a commercial/visual product unless you're a real guru).  I believe unmanaged code is subject to typical memory leaks of unamanged code, except that references shared between the two are managed by the garbage collector. Could be wrong about this last point. ", 
        "type": "2", 
        "id": "112", 
        "parentId": "104"
    }, 
    {
        "content": "I'll second Diago's answer.  I use TortoiseSVN on Vista x64 pretty heavily.    I did upgrade directly from an older version to 1.5.2 though, and never used 1.5.1.  Have you tried 1.5.2?", 
        "type": "2", 
        "id": "113", 
        "parentId": "108"
    }, 
    {
        "content": "TortoiseSVN in combination with VisualSVN for Visual Studio. ", 
        "type": "2", 
        "id": "114", 
        "parentId": "108"
    }, 
    {
        "content": "I too get explorer crashes in Vista (I'm not in the 64Bit version though). I'm using Vista Super Saijen (or whatever they are calling the most expensive version). I'm not having any bugs with Tortoise.    My explorer does, however, crash about every other day (sometimes multiple times a day if it's having an \"off\" day). I'm not positive it's being caused by TortoiseSVN though. From what I hear, the explorer just crashes a lot in Vista...    Have you tried uninstalling Tortoise and using Windows for a day or two and seeing if it still crashes? Do you restart your computer at least once a day (It seems the longer I go between restarts, the worse the crashes get)?", 
        "type": "2", 
        "id": "116", 
        "parentId": "108"
    }, 
    {
        "content": "Has anyone got experience creating SQL-based ASP.NET site-map providers?  I've got the default XML file web.sitemap working properly with my Menu and SiteMapPath controls, but I'll need a way for the users of my site to create and modify pages dynamically.  I need to tie page viewing permissions into the standard ASP.NET membership system as well. ", 
        "type": "1", 
        "id": "120", 
        "parentId": -1
    }, 
    {
        "content": "Is there an existing application or library in Java which will allow me to convert a CSV data file to XML file?    The XML tags would be provided through possibly the first row containing column headings. ", 
        "type": "1", 
        "id": "123", 
        "parentId": -1
    }, 
    {
        "content": "I wound up using this. It is a kind of a hack, but it actually works pretty well. The only thing is you have to be very careful with your semicolons. : D  var strSql:String = stream.readUTFBytes(stream.bytesAvailable);       var i:Number = 0; var strSqlSplit:Array = strSql.split(\";\"); for (i = 0; i < strSqlSplit.length; i++){     NonQuery(strSqlSplit[i].toString()); }  ", 
        "type": "2", 
        "id": "124", 
        "parentId": "80"
    }, 
    {
        "content": "What is the \"purist\" or \"correct\" way to access an object's properties from within an object method that is not a getter/setter method?  I know that from outside of the object you should use a getter/setter, but from within would you just do:  Java:  String property = this.property;   PHP:  $property = $this->property;   or would you do:  Java:  String property = this.getProperty();   PHP:  $property = $this->getProperty();   Forgive me if my Java is a little off, it's been a year since I programmed in Java...  EDIT:  It seems people are assuming I am talking about private or protected variables/properties only. When I learned OO I was taught to use getters/setters for every single property even if it was public (and actually I was told never to make any variable/property public). So, I may be starting off from a false assumption from the get go. It appears that people answering this question are maybe saying that you should have public properties and that those don't need getters and setters, which goes against what I was taught, and what I was talking about, although maybe that needs to be discussed as well. That's probably a good topic for a different question though... ", 
        "type": "1", 
        "id": "126", 
        "parentId": -1
    }, 
    {
        "content": "This has religious war potential, but it seems to me that if you're using a getter/setter, you should use it internally as well - using both will lead to maintenance problems down the road (e.g. somebody adds code to a setter that needs to run every time that property is set, and the property is being set internally w/o that setter being called).", 
        "type": "2", 
        "id": "127", 
        "parentId": "126"
    }, 
    {
        "content": "It depends on how the property is used. For example, say you have a student object that has a name property. You could use your Get method to pull the name from the database, if it hasn't been retrieved already. This way you are reducing unnecessary calls to the database.    Now let's say you have a private integer counter in your object that counts the number of times the name has been called. You may want to not use the Get method from inside the object because it would produce an invalid count.", 
        "type": "2", 
        "id": "128", 
        "parentId": "126"
    }, 
    {
        "content": "I've been banging my head against SQL Server 2005 trying to get a lot of data out.  I've been given a database with nearly 300 tables in it and I need to turn this into a MySQL database.  My first call was to use bcp but unfortunately it doesn't produce valid CSV - strings aren't encapsulated, so you can't deal with any row that has a string with a comma in it (or whatever you use as a delimiter) and I would still have to hand write all of the create table statements, as obviously CSV doesn't tell you anything about the data types.  What would be better is if there was some tool that could connect to both SQL Server and MySQL, then do a copy. You lose views, stored procedures, trigger, etc, but it isn't hard to copy a table that only uses base types from one DB to another... is it?  Does anybody know of such a tool?  I don't mind how many assumptions it makes or what simplifications occur, as long as it supports integer, float, datetime and string. I have to do a lot of pruning, normalising, etc. anyway so I don't care about keeping keys, relationships or anything like that, but I need the initial set of data in fast! ", 
        "type": "1", 
        "id": "129", 
        "parentId": -1
    }, 
    {
        "content": "This may be too basic or limited of a solution, but couldn't you do a String.split() on each line of the file, remembering the result array of the first line to generate the XML, and just spit each line's array data out with the proper XML elements padding each iteration of a loop? ", 
        "type": "2", 
        "id": "133", 
        "parentId": "123"
    }, 
    {
        "content": "I have a pretty standard table set-up in a current application using the .NET XSD DataSet and TableAdapter features. My contracts table consists of some standard contract information, with a column for the primary department. This column is a foreign key to my Departments table, where I store the basic department name, id, notes. This is all setup and functioning in my SQL Server.  When I use the XSD tool, I can drag both tables in at once and it auto detects/creates the foreign key I have between these two tables. This works great when I'm on my main page and am viewing contract data.  However, when I go to my administrative page to modify the department data. I typically do something like this:  Dim dtDepartment As New DepartmentDataTable() Dim taDepartment As New DepartmentTableAdapter()  taDepartment.Fill(dtDepartment)   However, at this point an exception is thrown saying to the effect that there is a foreign key reference broken here, I'm guessing since I don't have the Contract DataTable filled.   How can I fix this problem? I know I can simply remove the foreign key from the XSD to make things work fine, but having the additional integrity check there and having the XSD schema match the SQL schema in the database is nice. ", 
        "type": "1", 
        "id": "134", 
        "parentId": -1
    }, 
    {
        "content": "Rolling your own PHP solution will certainly work though I'm not sure if there is a good way to automatically duplicate the schema from one DB to the other (maybe this was your question).    If you are just copying data, and/or you need custom code anyway to convert between modified schemas between the two DB's, I would recommend using PHP 5.2+ and the PDO libraries.  You'll be able to connect using PDO ODBC (and use MSSQL drivers).  I had a lot of problems getting large text fields and multi-byte characters from MSSQL into PHP using other libraries.", 
        "type": "2", 
        "id": "135", 
        "parentId": "129"
    }, 
    {
        "content": "    Am I just going overboard here?      Perhaps ;)    Another approach would be to utilize a private/protected method to actually do the getting (caching/db/etc), and a public wrapper for it that increments the count:    PHP:    public function getName() {    $this->incrementNameCalled();    return $this->_getName();}protected function _getName() {    return $this->name;}    and then from within the object itself:    PHP:    $name = $this->_getName();    This way you can still use that first argument for something else (like sending a flag for whether or not to used cached data here perhaps). ", 
        "type": "2", 
        "id": "139", 
        "parentId": "126"
    }, 
    {
        "content": "Another tool to try would be the SQLMaestro suite - http://www.sqlmaestro.com It is a little tricky nailing down the precise tool, but they have a variety of tools, both free and for purchase that handle a wide variety of tasks for multiple database platforms. I'd suggest trying the Data Wizard tool first for MySQL, since I believe that will have the proper \"import\" tool you need.", 
        "type": "2", 
        "id": "141", 
        "parentId": "129"
    }, 
    {
        "content": "Well, it seems with C# 3.0 properties' default implementation, the decision is taken for you; you HAVE to set the property using the (possibly private) property setter.  I personally only use the private member-behind when not doing so would cause the object to fall in an less than desirable state, such as when initializing or when caching/lazy loading is involved.", 
        "type": "2", 
        "id": "142", 
        "parentId": "126"
    }, 
    {
        "content": "As stated in some of the comments: Sometimes you should, sometimes you shouldn't. The great part about private variables is that you are able to see all the places they are used when you change something. If your getter/setter does something you need, use it. If it doesn't matter you decide.    The opposite case could be made that if you use the getter/setter and somebody changes the getter/setter they have to analyze all the places the getter and setter is used internally to see if it messes something up. ", 
        "type": "2", 
        "id": "143", 
        "parentId": "126"
    }, 
    {
        "content": "Does anyone know of a good way to compress or decompress files and folders in C# quickly? Handling large files might be necessary.   ", 
        "type": "1", 
        "id": "145", 
        "parentId": -1
    }, 
    {
        "content": "I have a website that plays mp3s in a flash player. If a user clicks 'play' the flash player automatically downloads an mp3 and starts playing it.   Is there an easy way to track how many times a particular song clip (or any binary file) has been downloaded?       Is the play link a link to the actual   mp3 file or to some javascript code   that pops up a player?      If the latter, you can easily add your   own logging code in there to track the   number of hits to it.      If the former, you'll need something   that can track the web server log   itself and make that distinction. My   hosting plan comes with webalizer,   which does this nicely.   It's javascript code, so that answers that.   However, it would be nice to know how to track downloads using the other method (without switching hosts). ", 
        "type": "1", 
        "id": "146", 
        "parentId": -1
    }, 
    {
        "content": "The hook and listener method is the most commonly used, but there are other things you can do.  Depending on the size of your app, and who your going to allow see the code (is this going to be a FOSS script, or something in house) will influence greatly how you want to allow plugins.    kdeloach has a nice example, but his implementation and hook function is a little unsafe.  I would ask for you to give more information of the nature of php app your writing, And how you see plugins fitting in.      +1 to kdeloach from me.", 
        "type": "2", 
        "id": "147", 
        "parentId": "42"
    }, 
    {
        "content": "Is the play link a link to the actual mp3 file or to some javascript code that pops up a player?     If the latter, you can easily add your own logging code in there to track the number of hits to it.    If the former, you'll need something that can track the web server log itself and make that distinction. My hosting plan comes with webalizer, which does this nicely.", 
        "type": "2", 
        "id": "148", 
        "parentId": "146"
    }, 
    {
        "content": "As of .Net 1.1 the only available method is reaching into the java libraries.  Using the Zip Classes in the J# Class Libraries to Compress Files and Data with C#  Not sure if this has changed in recent versions.", 
        "type": "2", 
        "id": "149", 
        "parentId": "145"
    }, 
    {
        "content": "I've always used the SharpZip Library.  Here's a link ", 
        "type": "2", 
        "id": "151", 
        "parentId": "145"
    }, 
    {
        "content": "The funny thing is i wrote a php media gallery for all my music 2 days ago. I had a similar problem.  Im using http://musicplayer.sourceforge.net/ for the player. and the playlis are built via php.  all music request go there a script called xfer.php?file=WHATEVER  $filename = base64_url_decode($_REQUEST['file']); header(\"Cache-Control: public\"); header(\"Content-Description: File Transfer\"); header('Content-disposition: attachment; filename='.basename($filename)); header(\"Content-Transfer-Encoding: binary\"); header('Content-Length: '. filesize($filename));  //  Put either file counting code here. either a db or static files  //  readfile($filename);  //and spit the user the file   function base64_url_decode($input) {     return base64_decode(strtr($input, '-_,', '+/=')); }   And when you call files use something like   function base64_url_encode($input) {      return strtr(base64_encode($input), '+/=', '-_,'); }   http://us.php.net/manual/en/function.base64-encode.php  If you are using some javascript or a flash player (JW player for example) that requires the actual link to be an mp3 file or whatever, you can append the text \"&type=.mp3\" so the final linke becomes something like \"www.example.com/xfer.php?file=34842ffjfjxfh&type=.mp3\". That way it looks like it ends with an mp3 extension without affecting the file link. ", 
        "type": "2", 
        "id": "152", 
        "parentId": "146"
    }, 
    {
        "content": "You could even set up an Apache .htaccess directive that converts *.mp3 requests into the querystring dubayou is working with. It might be an elegant way to keep the direct request and still be able to slipstream log function into the response.", 
        "type": "2", 
        "id": "153", 
        "parentId": "146"
    }, 
    {
        "content": "Well, what is the nature of the flat databases.  Are they large or small.  Is it simple arrays with arrays in them?  if its something simple say userprofiles built as such:  $user = array(\"name\" => \"dubayou\",                \"age\" => 20,               \"websites\" => array(\"dubayou.com\",\"willwharton.com\",\"codecream.com\"),               \"and_one\" => \"more\");   and to save or update the db record for that user.  $dir = \"../userdata/\";  //make sure to put it bellow what the server can reach. file_put_contents($dir.$user['name'],serialize($user));   and to load the record for the user  function &get_user($name){     return unserialize(file_get_contents(\"../userdata/\".$name)); }   but again this implementation will vary on the application and nature of the database you need. ", 
        "type": "2", 
        "id": "154", 
        "parentId": "85"
    }, 
    {
        "content": "I used to have lots of Explorer crashes (on 32-bit) caused by Tortoise. They seem to have gone away since I used the Include/Exclude path settings in the \"Icon Overlays\" configuration of TSVN. Constraining icon overlays to specific directories where I keep my source made this much more stable.", 
        "type": "2", 
        "id": "155", 
        "parentId": "108"
    }, 
    {
        "content": "Use your httpd log files. Install http://awstats.sourceforge.net/ ", 
        "type": "2", 
        "id": "158", 
        "parentId": "146"
    }, 
    {
        "content": "Strictly speaking, a memory leak is consuming memory that is \"no longer used\" by the program.  \"No longer used\" has more than one meaning, it could mean \"no more reference to it\", that is, totally unrecoverable, or it could mean, referenced, recoverable, unused but the program keeps the references anyway. Only the later applies to .Net for perfectly managed objects. However, not all classes are perfect and at some point an underlying unmanaged implementation could leak resources permanently for that process.  In all cases, the application consumes more memory than strictly needed. The sides effects, depending on the ammount leaked, could go from none, to slowdown caused by excessive collection, to a series of memory exceptions and finally a fatal error followed by forced process termination.  You know an application has a memory problem when monitoring shows that more and more memory is allocated to your process after each garbage collection cycle. In such case, you are either keeping too much in memory, or some underlying unmanaged implementation is leaking.  For most leaks, resources are recovered when the process is terminated, however some resources are not always recovered in some precise cases, GDI cursor handles are notorious for that. Of course, if you have an interprocess communication mechanism, memory allocated in the other process would not be freed until that process frees it or terminates.", 
        "type": "2", 
        "id": "159", 
        "parentId": "104"
    }, 
    {
        "content": "The best way that I have found is the MySQL Migration Toolkit provided by MySQL.  I have used it successfully for some large migration projects.", 
        "type": "2", 
        "id": "160", 
        "parentId": "129"
    }, 
    {
        "content": "I would define memory leaks as an object not freeing up all the memory allocated after it has completed. I have found this can happen in your application if you are using Windows API and COM (i.e. unmanaged code that has a bug in it or is not being managed correctly), in the framework and in third party components. I have also found not tiding up after using certain objects like pens can cause the issue.    I personally have suffered Out of Memory Exceptions which can be caused but are not exclusive to memory leaks in dot net applications. (OOM can also come from pinning see Pinning Artical). If you are not getting OOM errors or need to confirm if it is a memory leak causing it then the only way is to profile your application.    I would also try and ensure the following:    a) Everything that implements Idisposable is disposed either using a finally block or the using statement these include brushes, pens etc.(some people argue to set everything to nothing in addition)     b)Anything that has a close method is closed again using finally or the using statement (although I have found using does not always close depending if you declared the object outside the using statement)    c)If you are using unmanaged code/windows API's that these are dealt with correctly after. (some have clean up methods to release resources)    Hope this helps.", 
        "type": "2", 
        "id": "161", 
        "parentId": "104"
    }, 
    {
        "content": "Stack Overflow has a subversion version number at the bottom:     svn revision: 679   I want to use such automatic versioning with my .NET Web Site/Application, Windows Forms, WPD projects/solutions.  How do I implement this? ", 
        "type": "1", 
        "id": "163", 
        "parentId": -1
    }, 
    {
        "content": "We are using WMV videos on an internal site, and we are embedding them into web sites. Now, this works quite well on Internet Explorer, but not on Firefox. I've found ways to make it work in Firefox, but then it stops working in Internet Explorer.  We do not want to use Silverlight just yet, especially since we cannot be sure that all clients will be running Windows XP with Windows Media Player installed.   Is there some sort of Universal Code that embeds WMP into both Internet Explorer and Firefox, or do we need to implement some user-agent-detection and deliver different HTML for different browsers? ", 
        "type": "1", 
        "id": "164", 
        "parentId": -1
    }, 
    {
        "content": "You can use a 3rd-party library such as SharpZip as Tom pointed out.  Another way (without going 3rd-party) is to use the Windows Shell API. You'll need to set a reference to the Microsoft Shell Controls and Automation COM library in your C# project. Gerald Gibson has an example at:  http://geraldgibson.net/dnn/Home/CZipFileCompression/tabid/148/Default.aspx   Internet Archive's copy of the dead page ", 
        "type": "2", 
        "id": "165", 
        "parentId": "145"
    }, 
    {
        "content": "You can do it by adding the following anywhere in your code   $Id:$   So for example @Jeff did:  <div id=\"svnrevision\">svn revision: $Id:$</div>   and when checked in the server replaced $Id:$ with the current revision number.  I also found this reference.  There is also $Date:$, $Rev:$, $Revision:$ ", 
        "type": "2", 
        "id": "166", 
        "parentId": "163"
    }, 
    {
        "content": "You could use conditional comments to get IE and Firefox to do different things    <![if !IE]><p> Firefox only code</p><![endif]><!--[if IE]><p>Internet Explorer only code</p><![endif]-->    The browsers themselves will ignore code that isn't meant for them to read.", 
        "type": "2", 
        "id": "167", 
        "parentId": "164"
    }, 
    {
        "content": "Personally, I feel like it's important to remain consistent.  If you have getters and setters, use them.  The only time I would access a field directly is when the accessor has a lot of overhead.  It may feel like you're bloating your code unnecessarily, but it can certainly save a whole lot of headache in the future.  The classic example:    Later on, you may desire to change the way that field works.  Maybe it should be calculated on-the-fly or maybe you would like to use a different type for the backing store.  If you are accessing properties directly, a change like that can break an awful lot of code in one swell foop.", 
        "type": "2", 
        "id": "169", 
        "parentId": "126"
    }, 
    {
        "content": "Looks like Jeff is using CruiseControl.NET based on some leafing through the podcast transcripts.  This seems to have automated deployment capabilities from source control to production. Might this be where the insertion is happening? ", 
        "type": "2", 
        "id": "170", 
        "parentId": "163"
    }, 
    {
        "content": "I want to get my databases under version control.  Does anyone have any advice or recommended articles to get me started?  I'll always want to have at least some data in there (as alumb mentions: user types and administrators).  I'll also often want a large collection of generated test data for performance measurement. ", 
        "type": "1", 
        "id": "173", 
        "parentId": -1
    }, 
    {
        "content": "I want to print HTML from a C# web service.  The Web Browser control is overkill, and does not function well in a service environment, nor does it function well on a system with very tight security constraints.  Is there any sort of free .NET library that will support the printing of a basic HTML page?  Here is the code I have so far, which does not run properly.  public void PrintThing(string document) {     if (Thread.CurrentThread.GetApartmentState() != ApartmentState.STA)     {         Thread thread =             new Thread((ThreadStart) delegate { PrintDocument(document); });         thread.SetApartmentState(ApartmentState.STA);         thread.Start();     }     else     {         PrintDocument(document);     } }  protected void PrintDocument(string document) {     WebBrowser browser = new WebBrowser();     browser.DocumentText = document;     while (browser.ReadyState != WebBrowserReadyState.Complete)     {         Application.DoEvents();     }     browser.Print(); }   This works fine when called from UI-type threads, but nothing happens when called from a service-type thread.  Changing Print() to ShowPrintPreviewDialog() yields the following IE script error:     Error: 'dialogArguments.___IE_PrintType' is null or not an object   URL: res://ieframe.dll/preview.dlg   And a small empty print preview dialog appears. ", 
        "type": "1", 
        "id": "174", 
        "parentId": -1
    }, 
    {
        "content": "I want to be able to display a normal YouTube video with overlaid annotations, consisting of coloured rectangles for each frame. The only requirement is that this should be done programmatically. YouTube has annotations now, but require you to use their front end to create them by hand. I want to be able to generate them. What's the best way of doing this?  Some ideas:        Build your own Flash player (ew?)   Somehow draw over the YouTube Flash player. Will this work?   Reverse engineer & hijack YouTube's annotation system. Either messing with the local files or redirecting its attempt to download   the annotations. (using Greasemonkey? Firefox plugin?)      Idea that doesn't count:      download the video  ", 
        "type": "1", 
        "id": "175", 
        "parentId": -1
    }, 
    {
        "content": "On one Linux Server running Apache and PHP 5, we got multiple Virtual Hosts with separate logfiles and everything. The only thing we cannot seem to separate between virtual hosts is the php error_log.   Overriding this setting in the <Location> of the httpd.conf does not seem to do anything.  Did I overlook something? Is there a way to have separate php error_logs for each Virtual Host? ", 
        "type": "1", 
        "id": "176", 
        "parentId": -1
    }, 
    {
        "content": "This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter. ", 
        "type": "1", 
        "id": "180", 
        "parentId": -1
    }, 
    {
        "content": "Maybe this might help: JSefa  You can read CSV file with this tool and serialize it to XML. ", 
        "type": "2", 
        "id": "183", 
        "parentId": "123"
    }, 
    {
        "content": "I don't understand why you would want to do this. It sounds almost like cargo cult coding.    Converting a CSV file to XML doesn't add any value. Your program is already reading the CSV file, so arguing that you need XML doesn't work.    On the other hand, reading the CSV file, doing something with the values, and then serializing to XML does make sense (well, as much as using XML can make sense... ;)) but you would supposedly already have a means of serializing to XML.", 
        "type": "2", 
        "id": "190", 
        "parentId": "123"
    }, 
    {
        "content": "One of the fun parts of multi-cultural programming is number formats.   Americans use 10,000.50 Germans use 10.000,50 French use 10 000,50   My first approach would be to take the string, parse it backwards, until I encounter a separator and use this as my decimal separator. There is an obvious flaw with that: 10.000 would be interpreted as 10.  Another approach: if the string contains 2 different non-numeric characters, use the last one as the decimal separator and discard the others. If I only have one, check if it occurs more than once and discard it if it does. If it only appears once, check if it has 3 digits after it. If yes, discard it, otherwise use it as decimal separator.  The obvious \"best solution\" would be to detect the User's culture or Browser, but that does not work if you have a Frenchman using an en-US Windows/Browser.  Does the .net Framework contain some mythical black magic floating point parser that is better than Double.(Try)Parse() in trying to auto-detect the number format? ", 
        "type": "1", 
        "id": "192", 
        "parentId": -1
    }, 
    {
        "content": "Yes, I know.  The existence of a running copy of SQL Server 6.5 in 2008 is absurd.  That stipulated, what is the best way to migrate from 6.5 to 2005?  Is there any direct path?  Most of the documentation I've found deals with upgrading 6.5 to 7.  Should I forget about the native SQL Server upgrade utilities, script out all of the objects and data, and try to recreate from scratch?  I was going to attempt the upgrade this weekend, but server issues pushed it back till next.  So, any ideas would be welcomed during the course of the week.  Update.  This is how I ended up doing it:   Back up the database in question and Master on 6.5. Execute SQL Server 2000's instcat.sql against 6.5's Master.  This allows SQL Server 2000's OLEDB provider to connect to 6.5. Use SQL Server 2000's standalone \"Import and Export Data\" to create a DTS package, using OLEDB to connect to 6.5.  This successfully copied all 6.5's tables to a new 2005 database (also using OLEDB). Use 6.5's Enterprise Manager to script out all of the database's indexes and triggers to a .sql file. Execute that .sql file against the new copy of the database, in 2005's Management Studio. Use 6.5's Enterprise Manager to script out all of the stored procedures. Execute that .sql file against the 2005 database.  Several dozen sprocs had issues making them incompatible with 2005.  Mainly non-ANSI joins and quoted identifier issues. Corrected all of those issues and re-executed the .sql file. Recreated the 6.5's logins in 2005 and gave them appropriate permissions.   There was a bit of rinse/repeat when correcting the stored procedures (there were hundreds of them to correct), but the upgrade went great otherwise.  Being able to use Management Studio instead of Query Analyzer and Enterprise Manager 6.5 is such an amazing difference.  A few report queries that took 20-30 seconds on the 6.5 database are now running in 1-2 seconds, without any modification, new indexes, or anything.  I didn't expect that kind of immediate improvement. ", 
        "type": "1", 
        "id": "194", 
        "parentId": -1
    }, 
    {
        "content": "This is one of the \"hard problems\" surrounding development. As far as I know there are no perfect solutions.     If you only need to store the database structure and not the data you can export the database as SQL queries. (in Enterprise Manager: Right click on database -> Generate SQL script. I recommend setting the \"create one file per object\" on the options tab) You can then commit these text files to svn and make use of svn's diff and logging functions.     I have this tied together with a Batch script that takes a couple parameters and sets up the database. I also added some additional queries that enter default data like user types and the admin user. (If you want more info on this, post something and I can put the script somewhere accessible)    If you need to keep all of the data as well, I recommend keeping a back up of the database and using Redgate (http://www.red-gate.com/) products to do the comparisons. They don't come cheap, but they are worth every penny. ", 
        "type": "2", 
        "id": "195", 
        "parentId": "173"
    }, 
    {
        "content": "Hey, I'm still stuck in that camp too. The third party application we have to support is FINALLY going to 2K5, so we're almost out of the wood. But I feel your pain 8^D    That said, from everything I heard from our DBA, the key is to convert the database to 8.0 format first, and then go to 2005. I believe they used the built in migration/upgrade tools for this. There are some big steps between 6.5 and 8.0 that are better solved there than going from 6.5 to 2005 directly.    Your BIGGEST pain, if you didn't know already, is that DTS is gone in favor of SSIS. There is a shell type module that will run your existing DTS packages, but you're going to want to manually recreate them all in SSIS. Ease of this will depend on the complexity of the packages themselves, but I've done a few at work so far and they've been pretty smooth.", 
        "type": "2", 
        "id": "197", 
        "parentId": "194"
    }, 
    {
        "content": "I've read somewhere the human eye can't distinguish between less than 4 values apart. so This is something to keep in mind. The following algorithm does not compensate for this.    I'm not sure this is exactly what you want, but this is one way to randomly generate non-repeating color values:    (beware, inconsistent pseudo-code ahead)    //colors entered as 0-255 [R, G, B]colors = []; //holds final colors to be usedrand = new Random();//assumes n is less than 16,777,216randomGen(int n){   while (len(colors) < n){      //generate a random number between 0,255 for each color      newRed = rand.next(256);      newGreen = rand.next(256);      newBlue = rand.next(256);      temp = [newRed, newGreen, newBlue];      //only adds new colors to the array      if temp not in colors {         colors.append(temp);      }   }}    One way you could optimize this for better visibility would be to compare the distance between each new color and all the colors in the array:    for item in color{   itemSq = (item[0]^2 + item[1]^2 + item[2]^2])^(.5);   tempSq = (temp[0]^2 + temp[1]^2 + temp[2]^2])^(.5);   dist = itemSq - tempSq;   dist = abs(dist);}//NUMBER can be your chosen distance apart.if dist < NUMBER and temp not in colors {   colors.append(temp);}    But this approach would significantly slow down your algorithm.    Another way would be to scrap the randomness and systematically go through every 4 values and add a color to an array in the above example.", 
        "type": "2", 
        "id": "199", 
        "parentId": "180"
    }, 
    {
        "content": "You can try turning Check-constraints off on the DataSet (it's in its properties), or altering the properties of that relationship, and change the key to a simple reference - up to you. ", 
        "type": "2", 
        "id": "206", 
        "parentId": "134"
    }, 
    {
        "content": "To set the Apache (not the PHP) log, the easiest way to do this would be to do:  <VirtualHost IP:Port>    # Stuff,    # More Stuff,    ErrorLog /path/where/you/want/the/error.log </VirtualHost>   If there is no leading \"/\" it is assumed to be relative.  Apache Error Log Page ", 
        "type": "2", 
        "id": "207", 
        "parentId": "176"
    }, 
    {
        "content": "I don't know the ASP.NET side of the problem but .NET has a pretty powerful class: System.Globalization.CultureInfo. You can use the following code to parse a string containing a double value:    double d = double.Parse(\"100.20\", CultureInfo.CurrentCulture);//  -- OR --double d = double.Parse(\"100.20\", CultureInfo.CurrentUICulture);    If ASP.NET somehow (i.e. using HTTP Request headers) passes current user's CultureInfo to either CultureInfo.CurrentCulture or CultureInfo.CurrentUICulture, these will work fine.", 
        "type": "2", 
        "id": "210", 
        "parentId": "192"
    }, 
    {
        "content": "You can't please everyone.  If I enter ten as 10.000, and someone enters ten thousand as 10.000, you cannot handle that without some knowledge of the culture of the input.  Detect the culture somehow (browser, system setting - what is the use case?  ASP?  Internal app, or open to the world?), or provide an example of the expected formatting, and use the most lenient parser you can.  Probably something like:    double d = Double.Parse(\"5,000.00\", NumberStyles.Any, CultureInfo.InvariantCulture);", 
        "type": "2", 
        "id": "212", 
        "parentId": "192"
    }, 
    {
        "content": "I have the following arrays:  $artist = array(\"the roots\", \"michael jackson\", \"billy idol\", \"more\", \"and more\", \"and_YET_MORE\"); $count = array(5, 3, 9, 1, 1, 3);   I want to generate a tag cloud that will have artists with a higher number in $count enclosed in h6 tags and the lowest enclosed h1 tags. ", 
        "type": "1", 
        "id": "227", 
        "parentId": -1
    }, 
    {
        "content": "Another function, not my me but found on the web and a bit refined:  public static int GetAge(DateTime birthDate) {     DateTime n = DateTime.Now; // To avoid a race condition around midnight     int age = n.Year - birthDate.Year;      if (n.Month < birthDate.Month || (n.Month == birthDate.Month && n.Day < birthDate.Day))         age--;      return age; }   Just two things that come into my mind: What about people from countries that do not use the gregorian calendar? DateTime.Now is in the server-specific culture i think. I have absolutely 0 knowledge about actually working with Asian calendars and I do not know if there is an easy way to convert dates between calendars, but just in case you're wondering about those chinese guys from the year 4660 :-) ", 
        "type": "2", 
        "id": "229", 
        "parentId": "9"
    }, 
    {
        "content": "How do I make it so mailto: links will be registered with my program?  How would I then handle that event in my program?  Most of the solutions I found from a quick Google search are how to do this manually, but I need to do this automatically for users of my program if they click a button, such as \"set as default email client\".  Edit: Removed reference to Delphi, because the answer is independent of your language. ", 
        "type": "1", 
        "id": "231", 
        "parentId": -1
    }, 
    {
        "content": "From what I've seen, there are a few registry keys that set the default mail client. One of them being:  System Key: [HKEY_CLASSES_ROOT\\mailto\\shell\\open\\command]  Value Name: (Default)  Data Type: REG_SZ (String Value)  Value Data: Mail program command-line.   I'm not familar with Delphi 7, but I'm sure there are some registry editing libraries in there that you could use to modify this value.  Some places list more than this key, others just this key, so you may need to test a little bit to find the proper one(s). ", 
        "type": "2", 
        "id": "233", 
        "parentId": "231"
    }, 
    {
        "content": "MySQL has this incredibly useful yet properitary REPLACE INTO SQL Command.   I wonder: Can this easily be emulated in SQL Server 2005?  Starting a new Transaction, doing a Select() and then either UPDATE or INSERT and COMMIT is always a little bit of a pain, especially when doing it in the application and therefore always keeping 2 versions of the statement.  I wonder if there is an easy and universal way to implement such a function into SQL Server 2005? ", 
        "type": "1", 
        "id": "234", 
        "parentId": -1
    }, 
    {
        "content": "Here is the official Microsoft Solution to programmatically change the default mail client. It's Visual Basic, but I hope the concept is clear from this:  http://support.microsoft.com/kb/299853 ", 
        "type": "2", 
        "id": "235", 
        "parentId": "231"
    }, 
    {
        "content": "The default behaviour is for error_log() to output to the Apache error log.  If this isn't happening check your php.ini settings for the error_log directive - leave it unset to use the Apache log file for the current vhost.", 
        "type": "2", 
        "id": "236", 
        "parentId": "176"
    }, 
    {
        "content": "The functionality you're looking for is traditionally called an UPSERT. Atleast knowing what it's called might help you find what you're looking for.    I don't think SQL Server 2005 has any great ways of doing this. 2008 introduces the MERGE statement that can be used to accomplish this as shown in: http://www.databasejournal.com/features/mssql/article.php/3739131 or http://blogs.conchango.com/davidportas/archive/2007/11/14/SQL-Server-2008-MERGE.aspx    Merge was available in the beta of 2005, but they removed it out in the final release.", 
        "type": "2", 
        "id": "238", 
        "parentId": "234"
    }, 
    {
        "content": "What the upsert/merge is doing is something to the effect of...    IF EXISTS (SELECT * FROM [Table] WHERE Id = X)     UPDATE [Table] SET...  ELSE     INSERT INTO [Table]      So hopefully the combination of those articles and this pseudo code can get things moving.", 
        "type": "2", 
        "id": "243", 
        "parentId": "234"
    }, 
    {
        "content": "Does anybody know if there is a way to create a SQLite database based on an XSD DataSet? In the past I've just used a basic SQLite manager, but want to fuse things a bit more with my .NET development if possible. ", 
        "type": "1", 
        "id": "246", 
        "parentId": -1
    }, 
    {
        "content": "Off the top of my head...    $artist = array(\"the roots\",\"michael jackson\",\"billy idol\",\"more\",\"and more\",\"and_YET_MORE\");$count = array(5,3,9,1,1,3);$highest = max($count);for (int $x = 0; x < count($artist); $x++){    $normalized = $count[$x] / $highest;    $heading = ceil($normalized * 6); // 6 heading types    echo \"<h\".$heading.\">\".$artist[$x].\"</h\".$heading.\">\";}", 
        "type": "2", 
        "id": "253", 
        "parentId": "227"
    }, 
    {
        "content": "I think the best you can do in this case is to take their input and then show them what you think they meant. If they disagree, show them the format you're expecting and get them to enter it again.", 
        "type": "2", 
        "id": "258", 
        "parentId": "192"
    }, 
    {
        "content": "I have a little game written in C#. It uses a database as back-end. It's  a trading card game, and I wanted to implement the function of the cards as a script.  What I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.  Now, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).  Is that possible? Register a class from a source file and then instantiate it, etc.  ICard Cards[current] = new MyGame.CardLibrary.Card056(); Cards[current].OnEnterPlay(ref currentGameState);   The language is C#, but extra bonus if it's possible to write the script in any .NET language. ", 
        "type": "1", 
        "id": "260", 
        "parentId": -1
    }, 
    {
        "content": "I have been trying to implement Win32's MessageBox using GTK. The app using SDL/OpenGL, so this isn't a GTK app.   I handle the initialisation (gtk_init) sort of stuff inside the MessageBox function as follows:  int MessageBox(HWND hwnd, const char* text, const char* caption, UINT type) {     GtkWidget *window = NULL;     GtkWidget *dialog = NULL;      gtk_init(&gtkArgc, &gtkArgv);     window = gtk_window_new(GTK_WINDOW_TOPLEVEL);     g_signal_connect(G_OBJECT(window), \"delete_event\", G_CALLBACK(delete_event), NULL);     g_signal_connect(G_OBJECT(window), \"destroy\", G_CALLBACK(destroy), NULL);     // gcallback calls gtk_main_quit()     gtk_init_add((GtkFunction)gcallback, NULL);      if (type & MB_YESNO) {         dialog = gtk_message_dialog_new(GTK_WINDOW(window), GTK_DIALOG_DESTROY_WITH_PARENT, GTK_MESSAGE_QUESTION, GTK_BUTTONS_YES_NO, text);     } else {         dialog = gtk_message_dialog_new(GTK_WINDOW(window), GTK_DIALOG_DESTROY_WITH_PARENT, GTK_MESSAGE_INFO, GTK_BUTTONS_OK, text);     }      gtk_window_set_title(GTK_WINDOW(dialog), caption);     gint result = gtk_dialog_run(GTK_DIALOG(dialog));      gtk_main();      gtk_widget_destroy(dialog);      if (type & MB_YESNO) {         switch (result) {         default:         case GTK_RESPONSE_DELETE_EVENT:         case GTK_RESPONSE_NO:             return IDNO;             break;         case GTK_RESPONSE_YES:             return IDYES;             break;         }     }      return IDOK; }    Now, I am by no means an experienced GTK programmer, and I realise that I'm probably doing something(s) horribly wrong.  However, my problem is that the last dialog popped up with this function stays around until the process exits. Any ideas? ", 
        "type": "1", 
        "id": "263", 
        "parentId": -1
    }, 
    {
        "content": " What's the optimal level of concurrency that the C++ implementation of BerkeleyDB can reasonably support? How many threads can I have hammering away at the DB before throughput starts to suffer because of resource contention?   I've read the manual and know how to set the number of locks, lockers, database page size, etc., but I'd just like some advice from someone who has real-world experience with BDB concurrency.  My application is pretty simple, I'll be doing gets and puts of records that are about 1KB each. No cursors, no deleting. ", 
        "type": "1", 
        "id": "264", 
        "parentId": -1
    }, 
    {
        "content": "What are the best practices for checking in BIN directories in a collaborative development environment using SVN?  Should project level references be excluded from checkin?  Is it easier to just add all bin directories?  I develop a lot of DotNetNuke sites and it seems that in a multi-developer environment, it's always a huge task to get the environment setup correctly.  The ultimate goal (of course) is to have a new developer checkout the trunk from SVN, restore the DNN database and have it all just 'work'... ", 
        "type": "1", 
        "id": "265", 
        "parentId": -1
    }, 
    {
        "content": "Any assemblies that are expected to be in the GAC should stay in the GAC. This includes System.web.dll or any other 3rd party dll that you'll deploy to the GAC in production. This means a new developer would have to install these assemblies.    All other 3rd party assemblies should be references through a relative path. My typical structure is:    -Project--Project.sln--References---StructureMap.dll---NUnit.dll---System.Web.Mvc.dll--Project.Web---Project.Web.Proj---Project.Web.Proj files--Project---Project.Proj---Project.Proj files    Project.Web and Project reference the assemblies in the root/References folder relatively. These .dlls are checked into subversion.    Aside from that, */bin  */bin/* obj  should be in your global ignore path.    With this setup, all references to assemblies are either through the GAC (so should work across all computers), or relative to each project within your solution.", 
        "type": "2", 
        "id": "266", 
        "parentId": "265"
    }, 
    {
        "content": "Is this a .Net specific question?    Generally the best practice is to not check in anything which is built automatically from files that are already in SCM.  All of that is ideally created as part of your automatic build process.    If the bin directory you're referring to contains third-party binaries, rather than a build of your project, ignore (downvote?) this advice.", 
        "type": "2", 
        "id": "268", 
        "parentId": "265"
    }, 
    {
        "content": "Yes, I thought about that, but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much.  Essentially, they need to interact with my gamestate in possibly unpredictable ways. For example, a card could have a rule \"When this cards enter play, all your undead minions gain +3 attack against flying enemies, except when the enemy is blessed\". As trading card games are turn based, the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs.  If I try to create a DSL, I have to implement a rather large feature set and possibly constantly update it, which shifts the maintenance work to another part without actually removing it.  That's why I wanted to stay with a \"real\" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security). ", 
        "type": "2", 
        "id": "269", 
        "parentId": "260"
    }, 
    {
        "content": "@Ryan    That's correct but it actually makes the tags with the least number, larger.  This code has been tested:    $artist = array(\"the roots\",\"michael jackson\",\"billy idol\",\"more\",\"and more\",\"and_YET_MORE\");$count = array(5,3,9,1,1,3);$highest = max($count);for ($x = 0; $x < count($artist); $x++) {    $normalized =  ($highest - $count[$x]+1) / $highest;    $heading = ceil($normalized * 6); // 6 heading types    echo \"<h$heading>{$artist[$x]}</h$heading>\";}", 
        "type": "2", 
        "id": "274", 
        "parentId": "227"
    }, 
    {
        "content": "    kevind wrote:              @Ryan            That's correct but it actually makes the tags with the least number, larger. This code has been tested:          I actually meant to mention this in my answer- the original poster specified higher frequencies in higher-number tags, but HTML uses lower numbers for more significant headings.    I wrote my code to spec. ;P", 
        "type": "2", 
        "id": "276", 
        "parentId": "227"
    }, 
    {
        "content": "I often have to sort a dictionary, consisting of keys & values, by value. For example, I have a hash of words and respective frequencies, that I want to order by frequency.  There is a SortedList which is good for a single value (say frequency), that I want to map it back to the word.  SortedDictionary orders by key, not value. Some resort to a custom class, but is there a cleaner way? ", 
        "type": "1", 
        "id": "289", 
        "parentId": -1
    }, 
    {
        "content": "I know that Visual Studio itself (at least in 2003 version) references the IE dll directly to render the \"Design View\".    It may be worth looking into that.    Otherwise, I can't think of anything beyond the Web Browser control.", 
        "type": "2", 
        "id": "290", 
        "parentId": "174"
    }, 
    {
        "content": "Looking around, and using some C# 3.0 features we can do this:  foreach (KeyValuePair<string,int> item in keywordCounts.OrderBy(key=> key.Value)) {      // do something with item.Key and item.Value }   This is the cleanest way I've seen and is similar to the Ruby way of handling hashes. ", 
        "type": "2", 
        "id": "291", 
        "parentId": "289"
    }, 
    {
        "content": "On a high level, you have no other choice then to walk through the whole Dictionary and look at each value.  Maybe this helps: http://bytes.com/forum/thread563638.html Copy/Pasting from John Timney:  Dictionary<string, string> s = new Dictionary<string, string>(); s.Add(\"1\", \"a Item\"); s.Add(\"2\", \"c Item\"); s.Add(\"3\", \"b Item\");  List<KeyValuePair<string, string>> myList = new List<KeyValuePair<string, string>>(s); myList.Sort(     delegate(KeyValuePair<string, string> firstPair,     KeyValuePair<string, string> nextPair)     {         return firstPair.Value.CompareTo(nextPair.Value);     } );  ", 
        "type": "2", 
        "id": "292", 
        "parentId": "289"
    }, 
    {
        "content": "I usually just specify this in an .htaccess file or the vhost.conf on the domain I'm working on. Add this to one of these files:  php_admin_value error_log \"/var/www/vhosts/example.com/error_log\"  ", 
        "type": "2", 
        "id": "297", 
        "parentId": "176"
    }, 
    {
        "content": "using System.Linq.Enumerable; ... List<KeyValuePair<string, string>> myList = aDictionary.ToList();  myList.Sort(     delegate(KeyValuePair<string, string> pair1,     KeyValuePair<string, string> pair2)     {         return pair1.Value.CompareTo(pair2.Value);     } );   Since you're targeting .net 2.0 or above, you can simplify this into lambda syntax -- it's equivalent but shorter. If you're targeting .net 2.0 you can only use this syntax if you're using the compiler from vs2008 (or above).  var myList = aDictionary.ToList();  myList.Sort((pair1,pair2) => pair1.Value.CompareTo(pair2.Value));  ", 
        "type": "2", 
        "id": "298", 
        "parentId": "289"
    }, 
    {
        "content": "Try removing the 0x first and then call Encoding.UTF8.GetString. I think that may work.  Essentially: 0x44004500  Remove the 0x, and then always two bytes are one character:  44 00 = D  45 00 = E  6F 00 = o  72 00 = r   So it's definitely a Unicode/UTF format with two bytes/character. ", 
        "type": "2", 
        "id": "304", 
        "parentId": "109"
    }, 
    {
        "content": "Oleg Shilo's C# Script solution (at The Code Project) really is a great introduction to providing script abilities in your application.  A different approach would be to consider a language that is specifically built for scripting, such as IronRuby, IronPython, or Lua.  IronPython and IronRuby are both available today.  For a guide to embedding IronPython read How to embed IronPython script support in your existing app in 10 easy steps.  Lua is a scripting language commonly used in games. There is a Lua compiler for .NET, available from CodePlex -- http://www.codeplex.com/Nua  That codebase is a great read if you want to learn about building a compiler in .NET.  A different angle altogether is to try PowerShell. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic:  Powershell Tunnel ", 
        "type": "2", 
        "id": "307", 
        "parentId": "260"
    }, 
    {
        "content": "I often run into the following problem.  I work on some changes to a project that require new tables or columns in the database. I make the database modifications and continue my work. Usually, I remember to write down the changes so that they can be replicated on the live system. However, I don't always remember what I've changed and I don't always remember to write it down.  So, I make a push to the live system and get a big, obvious error that there is no NewColumnX, ugh.  Regardless of the fact that this may not be the best practice for this situation, is there a version control system for databases? I don't care about the specific database technology. I just want to know if one exists. If it happens to work with MS SQL Server, then great. ", 
        "type": "1", 
        "id": "308", 
        "parentId": -1
    }, 
    {
        "content": "Most database engines should support dumping your database into a file. I know MySQL does, anyway. This will just be a text file, so you could submit that to Subversion, or whatever you use. It'd be easy to run a diff on the files too.", 
        "type": "2", 
        "id": "310", 
        "parentId": "308"
    }, 
    {
        "content": "What are some guidelines for maintaining responsible session security with PHP?  There's information all over the web and it's about time it all landed in one place! ", 
        "type": "1", 
        "id": "328", 
        "parentId": -1
    }, 
    {
        "content": "One guideline is to call session_regenerate_id every time a session's security level changes.  This helps prevent session hijacking.", 
        "type": "2", 
        "id": "329", 
        "parentId": "328"
    }, 
    {
        "content": "I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like play(), stop(), pause(), record() etc... Then I have workhorse classes which do the video decoding and video encoding.   I just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.  The book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue. ", 
        "type": "1", 
        "id": "330", 
        "parentId": -1
    }, 
    {
        "content": "I think one of the major problems (which is being addressed in PHP 6) is register_globals. Right now one of the standard methods used to avoid register_globals is to use the $_REQUEST, $_GET or $_POST arrays.  The \"correct\" way to do it (as of 5.2, although it's a little buggy there, but stable as of 6, which is coming soon) is through filters.  So instead of:  $username = $_POST[\"username\"];   you would do:  $username = filter_input(INPUT_POST, 'username', FILTER_SANITIZE_STRING);   or even just:  $username = filter_input(INPUT_POST, 'username');  ", 
        "type": "2", 
        "id": "331", 
        "parentId": "328"
    }, 
    {
        "content": "I would be a bit reluctant to use nested classes here.  What if you created an abstract base class for a \"multimedia driver\" to handle the back-end stuff (workhorse), and a separate class for the front-end work?  The front-end class could take a pointer/reference to an implemented driver class (for the appropriate media type and situation) and perform the abstract operations on the workhorse structure.  My philosophy would be to go ahead and make both structures accessible to the client in a polished way, just under the assumption they would be used in tandem.  I would reference something like a QTextDocument in Qt.  You provide a direct interface to the bare metal data handling, but pass the authority along to an object like a QTextEdit to do the manipulation. ", 
        "type": "2", 
        "id": "332", 
        "parentId": "330"
    }, 
    {
        "content": "This is pretty trivial and obvious, but be sure to session_destroy after every use. This can be difficult to implement if the user does not log out explicitly, so a timer can be set to do this.    Here is a good tutorial on setTimer() and clearTimer().", 
        "type": "2", 
        "id": "335", 
        "parentId": "328"
    }, 
    {
        "content": "When is it appropriate to use an unsigned variable over a signed one? What about in a for loop?  I hear a lot of opinions about this and I wanted to see if there was anything resembling a consensus.   for (unsigned int i = 0; i < someThing.length(); i++) {       SomeThing var = someThing.at(i);       // You get the idea.   }   I know Java doesn't have unsigned values, and that must have been a concious decision on Sun Microsystems' part.  ", 
        "type": "1", 
        "id": "336", 
        "parentId": -1
    }, 
    {
        "content": "I'm about to build a piece of a project that will need to construct and post an XML document to a web service and I'd like to do it in Python, as a means to expand my skills in it.    Unfortunately, whilst I know the XML model fairly well in .NET, I'm uncertain what the pros and cons are of the XML models in Python.    Anyone have experience doing XML processing in Python? Where would you suggest I start? The XML files I'll be building will be fairly simple. ", 
        "type": "1", 
        "id": "337", 
        "parentId": -1
    }, 
    {
        "content": "Dive Into Python has a chapter. Can't vouch for how good it would be though. ", 
        "type": "2", 
        "id": "338", 
        "parentId": "337"
    }, 
    {
        "content": "I was glad to find a good conversation on this subject, as I hadn't really given it much thought before.    In summary, signed is a good general choice - even when you're dead sure all the numbers are positive - if you're going to do arithmetic on the variable (like in a typical for loop case).      If you're going to do bitwise things like masks, unsigned starts to make more sense.  Or, if you're desperate to get that extra positive range by taking advantage of the sign bit.    Personally, I like signed because I don't trust myself to stay consistent and avoid mixing the two types (like the article warns against).", 
        "type": "2", 
        "id": "339", 
        "parentId": "336"
    }, 
    {
        "content": "Personally, I've played with several of the built-in options on an XML-heavy project and have settled on pulldom as the best choice for less complex documents.    Especially for small simple stuff, I like the event-driven theory of parsing rather than setting up a whole slew of callbacks for a relatively simple structure.  Here is a good quick discussion of how to use the API.    What I like: you can handle the parsing in a for loop rather than using callbacks.  You also delay full parsing (the \"pull\" part) and only get additional detail when you call expandNode().  This satisfies my general requirement for \"responsible\" efficiency without sacrificing ease of use and simplicity.", 
        "type": "2", 
        "id": "342", 
        "parentId": "337"
    }, 
    {
        "content": "You might be able to use IronRuby for that.     Otherwise I'd suggest you have a directory where you place precompiled assemblies. Then you could have a reference in the DB to the assembly and class, and use reflection to load the proper assemblies at runtime.    If you really want to compile at run-time you could use the CodeDOM, then you could use reflection to load the dynamic assembly. MSDN article which might help.", 
        "type": "2", 
        "id": "344", 
        "parentId": "260"
    }, 
    {
        "content": "In your example above, when 'i' will always be positive and a higher range would be beneficial, unsigned would be useful. Like if you're using 'declare' statements, such as:     #declare BIT1 (unsigned int 1)#declare BIT32 (unsigned int reallybignumber)    Especially when these values will never change.    However, if you're doing an accounting program where the people are irresponsible with their money and are constantly in the red, you will most definitely want to use 'signed'.    I do agree with saint though that a good rule of thumb is to use signed, which C actually defaults to, so you're covered.", 
        "type": "2", 
        "id": "347", 
        "parentId": "336"
    }, 
    {
        "content": "Take a look at the CHECKSUM command:  SELECT CHECKSUM_AGG(BINARY_CHECKSUM(*)) FROM sample_table WITH (NOLOCK);   That will return the same number each time it's run as long as the table contents haven't changed. See my post on this for more information:  CHECKSUM  Here's how I used it to rebuild cache dependencies when tables changed: ASP.NET 1.1 database cache dependency (without triggers) ", 
        "type": "2", 
        "id": "352", 
        "parentId": "36"
    }, 
    {
        "content": "size_t is often a good choice for this, or size_type if you're using an STL class. ", 
        "type": "2", 
        "id": "354", 
        "parentId": "336"
    }, 
    {
        "content": "For Oracle, I use Toad, which can dump a schema to a number of discrete files (e.g., one file per table).  I have some scripts that manage this collection in Perforce, but I think it should be easily doable in just about any revision control system. ", 
        "type": "2", 
        "id": "356", 
        "parentId": "308"
    }, 
    {
        "content": "timezone.js:  function ajaxpage() {     var url = \"timezone.php\";     var visitortime = new Date();     var time = visitortime.getTimezoneOffset()/60;     var page_request = false;      if (window.XMLHttpRequest) {         page_request = new XMLHttpRequest();     }     else if (window.ActiveXObject) {          try {             page_request = new ActiveXObject(\"Msxml2.XMLHTTP\");         }         catch (e) {             try{                 page_request = new ActiveXObject(\"Microsoft.XMLHTTP\");             }              catch (e) {             }         }     }     else {         return false;     }      page_request.onreadystatechange = function() {             loadpage(page_request, containerid);     }      if (bustcachevar) {         bustcacheparameter=(url.indexOf(\"?\")!=-1) ? \"&\"+new Date().getTime() : \"?\"+new Date().getTime();     }      page_request.open('GET', url+bustcacheparameter+\"&time=\"+time, true);     page_request.send(null); }  function loadpage(page_request, containerid) {     if (page_request.readyState == 4 && (page_request.status==200 || window.location.href.indexOf(\"http\")==-1)) {         document.write('<meta http-equiv=\"refresh\" content=\"0;url=http://example.com/\"/>');     } }     timezone.php:  <?php session_start(); $_SESSION['time'] = $_GET['time']; ?>     When you want to use it add onLoad=\"ajaxpage(); to the body tag and it should cause the timezone to be stored in the PHP session variable $_SESSION['time']  Edit: P.S. This is untested. ", 
        "type": "2", 
        "id": "357", 
        "parentId": "13"
    }, 
    {
        "content": "You could use any of the DLR languages, which provide a way to really easily host your own scripting platform. However, you don't have to use a scripting language for this. You could use C# and compile it with the C# code provider. As long as you load it in its own AppDomain, you can load and unload it to your heart's content.", 
        "type": "2", 
        "id": "359", 
        "parentId": "260"
    }, 
    {
        "content": "In Ruby on Rails, there's a concept of a migration -- a quick script to change the database.    You generate a migration file, which has rules to increase the db version (such as adding a column) and rules to downgrade the version (such as removing a column). Each migration is numbered, and a table keeps track of your current db version.    To _migrate up_, you run a command called \"db:migrate\" which looks at your version and applies the needed scripts. You can migrate down in a similar way.    The migration scripts themselves are kept in a version control system -- whenever you change the database you check in a new script, and any developer can apply it to bring their local db to the latest version.", 
        "type": "2", 
        "id": "360", 
        "parentId": "308"
    }, 
    {
        "content": "How would I go about generating a list of all possible permutations of a string between x and y characters in length, containing a variable list of characters.  Any language would work, but it should be portable. ", 
        "type": "1", 
        "id": "361", 
        "parentId": -1
    }, 
    {
        "content": "There are several ways to do this. Common methods use recursion, memoization, or dynamic programming. The basic idea is that you produce a list of all strings of length 1, then in each iteration, for all strings produced in the last iteration, add that string concatenated with each character in the string individually. (the variable index in the code below keeps track of the start of the last and the next iteration)  Some pseudocode:  list = originalString.split('') index = (0,0) list = [\"\"] for iteration n in 1 to y:   index = (index[1], len(list))   for string s in list.subset(index[0] to end):     for character c in originalString:       list.add(s + c)   you'd then need to remove all strings less than x in length, they'll be the first (x-1) * len(originalString) entries in the list. ", 
        "type": "2", 
        "id": "362", 
        "parentId": "361"
    }, 
    {
        "content": "There's a PHP5 \"database migration framework\" called Ruckusing. I haven't used it, but the examples show the idea, if you use the language to create the database as and when needed, you only have to track source files.", 
        "type": "2", 
        "id": "363", 
        "parentId": "308"
    }, 
    {
        "content": "I just whipped this up quick in Ruby:    def perms(x, y, possible_characters)  all = [\"\"]  current_array = all.clone  1.upto(y) { |iteration|    next_array = []    current_array.each { |string|      possible_characters.each { |c|        value = string + c        next_array.insert next_array.length, value        all.insert all.length, value      }    }    current_array = next_array  }  all.delete_if { |string| string.length < x }end    You might look into language API for built in permutation type functions, and you might be able to write more optimized code, but if the numbers are all that high, I'm not sure there is much of a way around having a lot of results.    Anyways, the idea behind the code is start with string of length 0, then keep track of all the strings of length Z where Z is the current size in the iteration.  Then, go through each string and append each character onto each string.  Finally at the end, remove any that were below the x threshold and return the result.    I didn't test it with potentially meaningless input (null character list, weird values of x and y, etc).", 
        "type": "2", 
        "id": "364", 
        "parentId": "361"
    }, 
    {
        "content": "High Resolution, Low Overhead Timing for Intel Processors  If you're on Intel hardware, here's how to read the CPU real-time instruction counter.  It will tell you the number of CPU cycles executed since the processor was booted.  This is probably the finest-grained counter you can get for performance measurement.  Note that this is the number of CPU cycles.  On linux you can get the CPU speed from /proc/cpuinfo and divide to get the number of seconds.  Converting this to a double is quite handy.  When I run this on my box, I get  11867927879484732 11867927879692217 it took this long to call printf: 207485   Here's the Intel developer's guide that  gives tons of detail.  #include <stdio.h> #include <stdint.h>  inline uint64_t rdtsc() {     uint32_t lo, hi;     __asm__ __volatile__ (       \"xorl %%eax, %%eax\\n\"       \"cpuid\\n\"       \"rdtsc\\n\"       : \"=a\" (lo), \"=d\" (hi)       :       : \"%ebx\", \"%ecx\");     return (uint64_t)hi << 32 | lo; }  main() {     unsigned long long x;     unsigned long long y;     x = rdtsc();     printf(\"%lld\\n\",x);     y = rdtsc();     printf(\"%lld\\n\",y);     printf(\"it took this long to call printf: %lld\\n\",y-x); }  ", 
        "type": "2", 
        "id": "367", 
        "parentId": "88"
    }, 
    {
        "content": "Personally I would do something like this:  <?php     $data = array($rating[0] => array('word0', 'word1', 'word2'), $rating[1] => array('word3', 'word4', 'word8',...));     //assums that $rating is an array with the weight of each word so the more popular words would have a higher value in rating     usort($data); //sort the $data variable, this should give us the most popular words first     $size = '1';     foreach($data as $rank)     {         $i=0;         while($i<$count($rank))         {             echo \"<h\" . $size . \">\" . $rank[$i] . \"</h\" . $size . \">\";             $i++;         }          $size++;     } ?>   Assuming I'm not a complete idiot this should work. But it is untested. ", 
        "type": "2", 
        "id": "368", 
        "parentId": "227"
    }, 
    {
        "content": "This is a tricky one and I've always relied on techniques, such as permission-based emails (i.e. only sending to people you have permission to send to) and not using blatantly spamish terminology.  Of late, some of the emails I send out programmatically have started being shuffled into people's spam folder automatically and I'm wondering what I can do about it.  This is despite the fact that these particular emails are not ones that humans would mark as spam, specifically, they are emails that contain license keys that people have paid good money for, so I don't think they're going to consider them spam  I figure this is a big topic in which I am essentially an ignorant simpleton. ", 
        "type": "1", 
        "id": "371", 
        "parentId": -1
    }, 
    {
        "content": "You can tell your users to add your From address to their contacts when they complete their order, which, if they do so, will help a lot.    Otherwise, I would try to get a log from some of your users. Sometimes they have details about why it was flagged as spam in the headers of the message, which you could use to tweak the text.    Other things you can try:      Put your site name or address in the subject  Keep all links in the message pointing to your domain (and not email.com)  Put an address or other contact information in the email  ", 
        "type": "2", 
        "id": "375", 
        "parentId": "371"
    }, 
    {
        "content": "What is the meaning of the Java warning?     Type safety: The cast from Object to List is actually checking against the erased type List   I get this warning when I try to cast an Object to a type with generic information, such as in the following code:  Object object = getMyList(); List<Integer> list = (List<Integer>) object;  ", 
        "type": "1", 
        "id": "382", 
        "parentId": -1
    }, 
    {
        "content": "This warning is there because Java is not actually storing type information at run-time in an object that uses generics.  Thus, if object is actually a List<String>, there will be no ClassCastException at run-time except until an item is accessed from the list that doesn't match the generic type defined in the variable.    This can cause further complications if items are added to the list, with this incorrect generic type information.  Any code still holding a reference to the list but with the correct generic type information will now have an inconsistent list.    To remove the warning, try:  List<?> list = (List<?>) object;   However, note that you will not be able to use certain methods such as add because the compiler doesn't know if you are trying to add an object of incorrect type.  The above will work in a lot of situations, but if you have to use add, or some similarly restricted method, you will just have to suffer the yellow underline in Eclipse (or a SuppressWarning annotation). ", 
        "type": "2", 
        "id": "384", 
        "parentId": "382"
    }, 
    {
        "content": "In Lucene if you had multiple indexes that covered only one partition each. Why does the same search on different indexes return results with different scores? The results from different servers match exactly. I.e. if i searched for:   Name - John Smith DOB - 11/11/1934   Partition 0 would return a score of 0.345  Partition 1 would return a score of 0.337  Both match exactly on name and DOB. ", 
        "type": "1", 
        "id": "387", 
        "parentId": -1
    }, 
    {
        "content": "I'm not sure why you would want to do this in the first place. The resulting set for any moderately large values of x and y will be huge, and will grow exponentially as x and/or y get bigger.     Lets say your set of possible characters is the 26 lowercase letters of the alphabet, and you ask your application to generate all permutations where length = 5. Assuming you don't run out of memory you'll get 11,881,376 (i.e. 26 to the power of 5) strings back. Bump that length up to 6, and you'll get 308,915,776 strings back. These numbers get painfully large, very quickly.    Here's a solution I put together in Java. You'll need to provide two runtime arguments (corresponding to x and y). Have fun.    public class GeneratePermutations {    public static void main(String[] args) {        int lower = Integer.parseInt(args[0]);        int upper = Integer.parseInt(args[1]);        if (upper < lower || upper == 0 || lower == 0) {            System.exit(0);        }        for (int length = lower; length <= upper; length++) {            generate(length, \"\");        }    }    private static void generate(int length, String partial) {        if (length <= 0) {            System.out.println(partial);        } else {            for (char c = 'a'; c <= 'z'; c++) {                generate(length - 1, partial + c);            }        }    }}", 
        "type": "2", 
        "id": "388", 
        "parentId": "361"
    }, 
    {
        "content": "The scoring contains the Inverse Document Frequency(IDF). If the term \"John Smith\" is in one partition, 0, 100 times and in partition 1, once. The score for searching for John Smith would be higher search in partition 1 as the term is more scarce.  To get round this you would wither have to have your index being over all partitions, or you would need to override the IDF. ", 
        "type": "2", 
        "id": "391", 
        "parentId": "387"
    }, 
    {
        "content": "Because the score is determined on the Index if I am not completely mistaken. If you have different indexes (more/less or different data that was indexed), the score will differ:  http://lucene.apache.org/core/3_6_0/scoring.html  (Warning: Contains Math :-)) ", 
        "type": "2", 
        "id": "392", 
        "parentId": "387"
    }, 
    {
        "content": "Use email authentication methods, such as SPF, and DKIM to prove that your emails and your domain name belong together, and to prevent spoofing of your domain name. The SPF website includes a wizard to generate the DNS information for your site.  Check your reverse DNS to make sure the IP address of your mail server points to the domain name that you use for sending mail.  Make sure that the IP-address that you're using is not on a blacklist  Make sure that the reply-to address is a valid, existing address.  Use the full, real name of the addressee in the To field, not just the email-address (e.g. \"John Smith\" <john@blacksmiths-international.com> ).  Monitor your abuse accounts, such as abuse@yourdomain.com and postmaster@yourdomain.com. That means - make sure that these accounts exist, read what's sent to them, and act on complaints.  Finally, make it really easy to unsubscribe. Otherwise, your users will unsubscribe by pressing the spam button, and that will affect your reputation.  That said, getting Hotmail to accept your emails remains a black art. ", 
        "type": "2", 
        "id": "396", 
        "parentId": "371"
    }, 
    {
        "content": "RDoc uses SimpleMarkup so it's fairly simple to create lists, etc. using *, - or a number. It also treats lines that are indented at the same column number as part of the same paragraph until there is an empty line which signifies a new paragraph. Do you have a few examples of comments you want RDoc'ed so we could show you how to do them and then you could extrapolate that for the rest of your comments?", 
        "type": "2", 
        "id": "397", 
        "parentId": "72"
    }, 
    {
        "content": "Note: this question is from 2008 and now is of only historic interest.    What's the best way to create an iPhone application that runs in landscape mode from the start, regardless of the position of the device?  Both programmatically and using the Interface Builder. ", 
        "type": "1", 
        "id": "402", 
        "parentId": -1
    }, 
    {
        "content": "The best way to deploy video on the web is using Flash - it's much easier to embed cleanly into a web page and will play on more or less any browser and platform combination. The only reason to use Windows Media Player is if you're streaming content and you need extraordinarily strong digital rights management, and even then providers are now starting to use Flash even for these. See BBC's iPlayer for a superb example.  I would suggest that you switch to Flash even for internal use. You never know who is going to need to access it in the future, and this will give you the best possible future compatibility.  EDIT - March 20 2013.  Interesting how these old questions resurface from time to time! How different the world is today and how dated this all seems. I would not recommend a Flash only route today by any means - best practice these days would probably be to use HTML 5 to embed H264 encoded video, with a Flash fallback as described here: http://diveintohtml5.info/video.html ", 
        "type": "2", 
        "id": "407", 
        "parentId": "164"
    }, 
    {
        "content": "If the fact that the first button is used by default is consistent across browsers, why not put them the right way round in the source code, then use CSS to switch their apparent positions? float them left and right to switch them around visually, for example. ", 
        "type": "2", 
        "id": "411", 
        "parentId": "48"
    }, 
    {
        "content": "Tortoise SVN with Ankhsvn for VS 2005   ", 
        "type": "2", 
        "id": "412", 
        "parentId": "108"
    }, 
    {
        "content": "Part of my everyday work is maintaining and extending legacy VB6 applications. A common engine is written in C/C++ and VB6 uses these functions in order to improve performance.   When it comes to asynchronous programming, a C interface is not enough and we rely on COM controls to fire events to VB6.  My problem is that when I register the control in VB6, VB loads this control in memory and does not unload it until I quit the VB6 IDE. As the control is loaded the whole time, I am unable to recompile it in VC6, because the DLL file is locked.  A solution I found is not to enable the control in VB but use the CreateObject() with the full name of my control. The problem then is that I must declare my control as an Object because VB6 knows nothing of the interface I am using and I do not have access to IntelliSense, which is a pain.  Any idea how I can tell VB6 to unload controls after quitting the application? Or directly in the IDE? ", 
        "type": "1", 
        "id": "419", 
        "parentId": -1
    }, 
    {
        "content": "Is there any way to launch IE Mobile's \"Favorites\" screen directly by specifying any command line parameter? ", 
        "type": "1", 
        "id": "427", 
        "parentId": -1
    }, 
    {
        "content": "The difference between 12.345 in French and English is a factor of 1000. If you supply an expected range where max < 1000*min, you can easily guess.     Take for example the height of a person (including babies and children) in mm.    By using a range of 200-3000, an input of 1.800 or 1,800 can unambiguously be interpreted as 1 meter and 80 centimeters, whereas an input of 912.300 or 912,300 can unambiguously be interpreted as 91 centimeters and 2.3 millimeters.", 
        "type": "2", 
        "id": "430", 
        "parentId": "192"
    }, 
    {
        "content": "My Rails-app has a sign in box with a \"remember me\" checkbox. Users who check that box should remain logged in even after closing their browser. I'm keeping track of whether users are logged in by storing their id in the user's session.     But sessions are implemented in Rails as session cookies, which are not persistent. I can make them persistent:        class ApplicationController < ActionController::Base      before_filter :update_session_expiration_date      private      def update_session_expiration_date        options = ActionController::Base.session_options        unless options[:session_expires]          options[:session_expires] = 1.year.from_now        end      end    end    But that seems like a hack, which is surprising for such common functionality. Is there a better way?    Edit    Gareth's answer is pretty good, but I would still like an answer from someone familiar with Rails 2 (because of its unique CookieSessionStore).", 
        "type": "1", 
        "id": "438", 
        "parentId": -1
    }, 
    {
        "content": "Yahoo uses a method called Sender ID, which can be configured at The SPF Setup Wizard and entered in to your DNS.  Also one of the important ones for Exchange, Hotmail, AOL, Yahoo, and others is to have a Reverse DNS for your domain.  Those will knock out most of the issues.  However you can never prevent a person intentionally blocking your or custom rules.", 
        "type": "2", 
        "id": "451", 
        "parentId": "371"
    }, 
    {
        "content": "While you haven't said what you're storing, and you may have a great reason for doing so, often the answer is 'as a filesystem reference' and the actual data is on the filesystem somewhere.    http://www.onlamp.com/pub/a/onlamp/2002/07/11/MySQLtips.html", 
        "type": "2", 
        "id": "467", 
        "parentId": "17"
    }, 
    {
        "content": "I am using the Photoshop's javascript API to find the fonts in a given PSD.  Given a font name returned by the API, I want to find the actual physical font file that that font name corresponds to on the disc.  This is all happening in a python program running on OSX so I guess I'm looking for one of:   Some Photoshop javascript A Python function An OSX API that I can call from python  ", 
        "type": "1", 
        "id": "469", 
        "parentId": -1
    }, 
    {
        "content": "I've been writing a few web services for a .net app, now I'm ready to consume them. I've seen numerous examples where there is homegrown code for consuming the service as opposed to using the auto generated methods Visual Studio creates when adding the web reference.   Is there some advantage to this? ", 
        "type": "1", 
        "id": "470", 
        "parentId": -1
    }, 
    {
        "content": "ElementTree has a nice pythony API.  I think it's even shipped as part of python 2.5    It's in pure python and as I say, pretty nice, but if you wind up needing more performance, then lxml exposes the same API and uses libxml2 under the hood.  You can theoretically just swap it in when you discover you need it.", 
        "type": "2", 
        "id": "471", 
        "parentId": "337"
    }, 
    {
        "content": "No, what you're doing is fine. Don't let those people confuse you.    If you've written the web services with .net then the reference proxies generated by .net are going to be quite suitable. The situation you describe (where you are both producer and consumer) is the ideal situation.    If you need to connect to a web services that is unknown at compile time, then you would want a more dynamic approach, where you deduce the 'shape' of the web service.     But start by using the auto generated proxy class, and don't worry about it until you hit a limitation. And when you do -- come back to stack overflow ;-)", 
        "type": "2", 
        "id": "473", 
        "parentId": "470"
    }, 
    {
        "content": "Ok, I'm a web developer, but I find myself dabbling in windows forms projects every now and then. One thing that confounds me to this day is the following.  Assume you are doing something like the following  List<string> myitems = new List<string> {     \"Item 1\",     \"Item 2\",     \"Item 3\" };  ComboBox box = new ComboBox(); box.DataSource = myitems;  ComboBox box2 = new ComboBox(); box2.DataSource = myitems   So now we have 2 combo boxes bound to that array, and everything works fine. But when you change the value of one combo box, it changes BOTH combo boxes to the one you just selected.  Now, I know that Arrays are always passed by reference (learned that when i learned C :D), but why on earth would the combo boxes change together? I don't believe the combo box control is modifying the collection at all.   As a work around, don't this would achieve the funcionality that is expected / desired  ComboBox box = new ComboBox(); box.DataSource = myitems.ToArray();  ", 
        "type": "1", 
        "id": "482", 
        "parentId": -1
    }, 
    {
        "content": "You should almost certainly not be extending the session cookie to be long lived.    Although not dealing specifically with rails this article goes to some length to explain 'remember me' best practices.    In summary though you should:      Add an extra column to the user table to accept a large random value  Set a long lived cookie on the client which combines the user id and the random value  When a new session starts, check for the existence of the id/value cookie and authenticate the new user if they match.      The author also recommends invalidating the random value and resetting the cookie at every login.  Personally I don't like that as you then can't stay logged into a site on two computers.  I would tend to make sure my password changing function also reset the random value thus locking out sessions on other machines.     As a final note, the advice he gives on making certain functions (password change/email change etc) unavailable to auto authenticated sessions is well worth following but rarely seen in the real world.", 
        "type": "2", 
        "id": "483", 
        "parentId": "438"
    }, 
    {
        "content": "open up a terminal (Applications->Utilities->Terminal) and type this in:    locate InsertFontHere    This will spit out every file that has the name you want.    Warning: there may be alot to wade through.", 
        "type": "2", 
        "id": "497", 
        "parentId": "469"
    }, 
    {
        "content": "I have a cross-platform (Python) application which needs to generate a JPEG preview of the first page of a PDF.  On the Mac I am spawning sips.  Is there something similarly simple I can do on Windows? ", 
        "type": "1", 
        "id": "502", 
        "parentId": -1
    }, 
    {
        "content": "This has to do with how data bindings are set up in the dotnet framework, especially the BindingContext. On a high level it means that if you haven't specified otherwise each form and all the controls of the form share the same BindingContext. When you are setting the DataSource property the ComboBox will use the BindingContext to get a ConcurrenyMangager that wraps the list. The ConcurrenyManager keeps track of such things as the current selected position in the list.   When you set the DataSource of the second ComboBox it will use the same BindingContext (the forms) which will yield a reference to the same ConcurrencyManager as above used to set up the data bindings.  To get a more detailed explanation see BindingContext. ", 
        "type": "2", 
        "id": "509", 
        "parentId": "482"
    }, 
    {
        "content": "I have a Ruby on Rails Website that makes HTTP calls to an external Web Service.  About once a day I get a SystemExit (stacktrace below) error email where a call to the service has failed.  If I then try the exact same query on my site moments later it works fine. It's been happening since the site went live and I've had no luck tracking down what causes it.  Ruby is version 1.8.6 and rails is version 1.2.6.  Anyone else have this problem?  This is the error and stacktrace.   A SystemExit occurred /usr/local/lib/ruby/gems/1.8/gems/rails-1.2.6/lib/fcgi_handler.rb:116:in `exit' /usr/local/lib/ruby/gems/1.8/gems/rails-1.2.6/lib/fcgi_handler.rb:116:in `exit_now_handler' /usr/local/lib/ruby/gems/1.8/gems/activesupport-1.4.4/lib/active_support/inflector.rb:250:in `to_proc' /usr/local/lib/ruby/1.8/net/protocol.rb:133:in `call' /usr/local/lib/ruby/1.8/net/protocol.rb:133:in `sysread' /usr/local/lib/ruby/1.8/net/protocol.rb:133:in `rbuf_fill' /usr/local/lib/ruby/1.8/timeout.rb:56:in `timeout' /usr/local/lib/ruby/1.8/timeout.rb:76:in `timeout' /usr/local/lib/ruby/1.8/net/protocol.rb:132:in `rbuf_fill' /usr/local/lib/ruby/1.8/net/protocol.rb:116:in `readuntil' /usr/local/lib/ruby/1.8/net/protocol.rb:126:in `readline' /usr/local/lib/ruby/1.8/net/http.rb:2017:in `read_status_line' /usr/local/lib/ruby/1.8/net/http.rb:2006:in `read_new' /usr/local/lib/ruby/1.8/net/http.rb:1047:in `request' /usr/local/lib/ruby/1.8/net/http.rb:945:in `request_get' /usr/local/lib/ruby/1.8/net/http.rb:380:in `get_response' /usr/local/lib/ruby/1.8/net/http.rb:543:in `start' /usr/local/lib/ruby/1.8/net/http.rb:379:in `get_response'  ", 
        "type": "1", 
        "id": "514", 
        "parentId": -1
    }, 
    {
        "content": "Martin Fowler wrote my favorite article on the subject, http://martinfowler.com/articles/evodb.html.  I choose not to put schema dumps in under version control as alumb and others suggest because I want an easy way to upgrade my production database.    For a web application where I'll have a single production database instance, I use two techniques:    Database Upgrade Scripts    A sequence database upgrade scripts that contain the DDL necessary to move the schema from version N to N+1.  (These go in your version control system.)  A version_history table, something like    create table VersionHistory (    Version int primary key,    UpgradeStart datetime not null,    UpgradeEnd datetime    );    gets a new entry every time an upgrade script runs which corresponds to the new version.    This ensures that it's easy to see what version of the database schema exists and that database upgrade scripts are run only once.  Again, these are not database dumps.  Rather, each script represents the changes necessary to move from one version to the next.  They're the script that you apply to your production database to \"upgrade\" it.    Developer Sandbox Synchronization      A script to backup, sanitize, and shrink a production database.  Run this after each upgrade to the production DB.  A script to restore (and tweak, if necessary) the backup on a developer's workstation.  Each developer runs this script after each upgrade to the production DB.      A caveat: My automated tests run against a schema-correct but empty database, so this advice will not perfectly suit your needs.", 
        "type": "2", 
        "id": "516", 
        "parentId": "173"
    }, 
    {
        "content": "I haven't been able to find anything that does this directly.  I think you'll have to iterate through the various font folders on the system: /System/Library/Fonts, /Library/Fonts, and there can probably be a user-level directory as well ~/Library/Fonts. ", 
        "type": "2", 
        "id": "518", 
        "parentId": "469"
    }, 
    {
        "content": "Using fcgi with Ruby is known to be very buggy.     Practically everybody has moved to Mongrel for this reason, and I recommend you do the same.", 
        "type": "2", 
        "id": "519", 
        "parentId": "514"
    }, 
    {
        "content": "You didn't mention any specifics about your target environment or constraints, so this may not be entirely applicable... but if you're looking for a way to effectively track an evolving DB schema and aren't adverse to the idea of using Ruby, ActiveRecord's migrations are right up your alley.    Migrations programatically define database transformations using a Ruby DSL; each transformation can be applied or (usually) rolled back, allowing you to jump to a different version of your DB schema at any given point in time. The file defining these transformations can be checked into version control like any other piece of source code.    Because migrations are a part of ActiveRecord, they typically find use in full-stack Rails apps; however, you can use ActiveRecord independent of Rails with minimal effort. See here for a more detailed treatment of using AR's migrations outside of Rails.", 
        "type": "2", 
        "id": "521", 
        "parentId": "173"
    }, 
    {
        "content": "   So it says microseconds explicitly, but says the resolution of the system clock is unspecified. I suppose resolution in this context means how the smallest amount it will ever be incremented?   The data structure is defined as having microseconds as a unit of measurement, but that doesn't mean that the clock or operating system is actually capable of measuring that finely.  Like other people have suggested, gettimeofday() is bad because setting the time can cause clock skew and throw off your calculation.  clock_gettime(CLOCK_MONOTONIC) is what you want, and clock_getres() will tell you the precision of your clock. ", 
        "type": "2", 
        "id": "522", 
        "parentId": "88"
    }, 
    {
        "content": "Since you mentioned that you'll be building \"fairly simple\" XML, the minidom module (part of the Python Standard Library) will likely suit your needs. If you have any experience with the DOM representation of XML, you should find the API quite straight forward.", 
        "type": "2", 
        "id": "525", 
        "parentId": "337"
    }, 
    {
        "content": "Isn't it also a factor which order you set up the colors?    Like if you use Dillie-Os idea you need to mix the colors as much as possible.   0 64 128 256 is from one to the next. but 0 256 64 128 in a wheel would be more \"apart\"    Does this make sense?", 
        "type": "2", 
        "id": "529", 
        "parentId": "180"
    }, 
    {
        "content": "Doesn't this depend on the hardware as well as number of threads and stuff?    I would make a simple test and run it with increasing amounts of threads hammering and see what seems best.", 
        "type": "2", 
        "id": "530", 
        "parentId": "264"
    }, 
    {
        "content": "The Monte Carlo method, as mentioned, applies some great concepts but it is, clearly, not the fastest --not by a long shot, not by any reasonable usefulness. Also, it all depends on what kind of accuracy you are looking for. The fastest pi I know of is the digits hard coded. Looking at Pi and Pi[PDF], there are a lot of formulas.  Here is a method that converges quickly (~14digits per iteration). The current fastest application, PiFast, uses this formula with the FFT. I'll just write the formula, since the code is straight forward. This formula was almost found by Ramanujan and discovered by Chudnovsky. It is actually how he calculated several billion digits of the number --so it isn't a method to disregard. The formula will overflow quickly since we are dividing factorials, it would be advantageous then to delay such calculating to remove terms.      where,    Below is the Brent\u2013Salamin algorithm. Wikipedia mentions that when a and b are 'close enough' then (a+b)^2/4t will be an approximation of pi. I'm not sure what 'close enough' means, but from my tests, one iteration got 2digits, two got 7, and three had 15, of course this is with doubles, so it might have error based on its representation and the 'true' calculation could be more accurate.  let pi_2 iters =     let rec loop_ a b t p i =         if i = 0 then a,b,t,p         else             let a_n = (a +. b) /. 2.0              and b_n = sqrt (a*.b)             and p_n = 2.0 *. p in             let t_n = t -. (p *. (a -. a_n) *. (a -. a_n)) in             loop_ a_n b_n t_n p_n (i - 1)     in      let a,b,t,p = loop_ (1.0) (1.0 /. (sqrt 2.0)) (1.0/.4.0) (1.0) iters in     (a +. b) *. (a +. b) /. (4.0 *. t)   Lastly, how about some pi golf (800 digits)? 160 characters!  int a=10000,b,c=2800,d,e,f[2801],g;main(){for(;b-c;)f[b++]=a/5;for(;d=0,g=c*2;c-=14,printf(\"%.4d\",e+d/a),e=d%a)for(b=c;d+=f[b]*a,f[b]=d%--g,d/=g--,--b;d*=b);}  ", 
        "type": "2", 
        "id": "531", 
        "parentId": "19"
    }, 
    {
        "content": "Maven helps quite a lot with this problem when I'm coding java. We commit the pom.xml to the scs and the maven repository contains all our dependencies.  For me that seems like a nice way to do it.", 
        "type": "2", 
        "id": "532", 
        "parentId": "265"
    }, 
    {
        "content": "I'm starting work on a hobby project with a python codebase and would like to set up some form of continuous integration (i.e. running a battery of test-cases each time a check-in is made and sending nag e-mails to responsible persons when the tests fail) similar to CruiseControl or TeamCity.  I realize I could do this with hooks in most VCSes, but that requires that the tests run on the same machine as the version control server, which isn't as elegant as I would like. Does anyone have any suggestions for a small, user-friendly, open-source continuous integration system suitable for a Python codebase? ", 
        "type": "1", 
        "id": "535", 
        "parentId": -1
    }, 
    {
        "content": "You can use ImageMagick's convert utility for this, see some examples in http://studio.imagemagick.org/pipermail/magick-users/2002-May/002636.html :   Convert taxes.pdf taxes.jpg        Will convert a two page PDF file into [2] jpeg files: taxes.jpg.0,   taxes.jpg.1      I can also convert these JPEGS to a thumbnail as follows:  convert -size 120x120 taxes.jpg.0 -geometry 120x120 +profile '*' thumbnail.jpg       I can even convert the PDF directly to a jpeg thumbnail as follows:  convert -size 120x120 taxes.pdf -geometry 120x120 +profile '*' thumbnail.jpg       This will result in a thumbnail.jpg.0 and thumbnail.jpg.1 for the two   pages.  ", 
        "type": "2", 
        "id": "536", 
        "parentId": "502"
    }, 
    {
        "content": "A few things:    You are creating (and not using) an unnecessary toplevel window, named window.  You can just delete these lines:    window = gtk_window_new(GTK_WINDOW_TOPLEVEL);g_signal_connect(G_OBJECT(window), \"delete_event\", G_CALLBACK(delete_event), NULL);g_signal_connect(G_OBJECT(window), \"destroy\", G_CALLBACK(destroy), NULL);    Also, the flow doesn't seem quite right.  gtk_main() starts the GTK main loop, which blocks until something exits it.  gtk_dialog_run() also starts a main loop, but it exits as soon as one of the buttons is clicked.    I think it might be enough for you to remove the gtk_init_add() and gtk_main() calls, and simply deal with the return value.  Also the gtk_widget_destroy() call is unnecessary, as the dialog window is automatically destroyed when gtk_dialog_run() returns.", 
        "type": "2", 
        "id": "537", 
        "parentId": "263"
    }, 
    {
        "content": "One possibility is Hudson.  It's written in Java, but there's integration with Python projects:     Hudson embraces Python   I've never tried it myself, however.  (Update, Sept. 2011: After a trademark dispute Hudson has been renamed to Jenkins.) ", 
        "type": "2", 
        "id": "538", 
        "parentId": "535"
    }, 
    {
        "content": "My first thought on this is \"how generate N vectors in a space that maximize distance from each other.\" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at Random Point Picking. Hope this is a good start for you! Once you have a set of vectors that are maximized a part, you can save them in a hash table or something for later, and just perform random rotations on them to get all the colors you desire that are maximally apart from each other!  Edit: Thinking about this problem more, it would be better to map the colors in a linear manor, possibly (0,0,0) --> (255,255,255) lexicographically, and then distribute them evenly. I really don't know how well this will work, but it should since, lets say:  n = 10 we know we have 16777216 colors (256^3). We can use buckles algorithm 515 to find the lexicographically indexed color.. You'll probably have to edit the algorithm to avoid overflow and probably add some minor speed improvements. ", 
        "type": "2", 
        "id": "539", 
        "parentId": "180"
    }, 
    {
        "content": "As far as I know, there's no ready-made library to do this for you, but producing a tool capable of translating from CSV to XML should only require you to write a crude CSV parser and hook up JDOM (or your XML Java library of choice) with some glue code. ", 
        "type": "2", 
        "id": "540", 
        "parentId": "123"
    }, 
    {
        "content": "We run Buildbot - Trac at work, I haven't used it too much since my code base isn't part of the release cycle yet. But we run the tests on different environments (OSX/Linux/Win) and it sends emails --and it's written in python.", 
        "type": "2", 
        "id": "541", 
        "parentId": "535"
    }, 
    {
        "content": "Form-based authentication for websites  We believe that Stack Overflow should not just be a resource for very specific technical questions, but also for general guidelines on how to solve variations on common problems. \"Form based authentication for websites\" should be a fine topic for such an experiment.  It should include topics such as:   How to log in How to remain logged in Managing cookies (including recommended settings) SSL/HTTPS encryption How to store passwords Using secret questions Forgotten username/password functionality Use of nonces to prevent cross-site request forgeries (CSRF) OpenID \"Remember me\" checkbox Browser autocompletion of usernames and passwords Secret URLs (public URL protected by digest) Checking password strength E-mail validation and much more about form based authentication...   It should not include things like:   Roles and authorization HTTP basic authentication   Please help us by:   Suggesting subtopics Submitting good articles about this subject Editing the official answer  ", 
        "type": "1", 
        "id": "549", 
        "parentId": -1
    }, 
    {
        "content": "You may also be interested in the output of the explain() method, and the resulting Explanation object, which will give you an idea of how things are scored the way they are. ", 
        "type": "2", 
        "id": "551", 
        "parentId": "387"
    }, 
    {
        "content": "Definitive Article  Sending credentials  The only practical way to send credentials 100% securely is by using SSL. Using JavaScript to hash the password is not safe. Common pitfalls for client-side password hashing:   If the connection between the client and server is unencrypted, everything you do is vulnerable to man-in-the-middle attacks. An attacker could replace the incoming javascript to break the hashing or send all credentials to their server, they could listen to client responses and impersonate the users perfectly, etc. etc. SSL with trusted Certificate Authorities is designed to prevent MitM attacks. The hashed password received by the server is less secure if you don't do additional, redundant work on the server.   There's another secure method called SRP, but it's patented (although it is freely licensed) and there are few good implementations available.  Storing passwords  Don't ever store passwords as plaintext in the database. Not even if you don't care about the security of your own site. Assume that some of your users will reuse the password of their online bank account. So, store the hashed password, and throw away the original. And make sure the password doesn't show up in access logs or application logs. The best hashing function seems to be bcrypt.   Hashes by themselves are also insecure. For instance, identical passwords mean identical hashes--this makes hash lookup tables an effective way of cracking lots of passwords at once. Instead, store the salted hash. A salt is a string appended to the password prior to hashing - use a different (random) salt per user. The salt is a public value, so you can store them with the hash in the database. See here for more on this.  This means that you can't send the user their forgotten passwords (because you only have the hash). Don't reset the user's password unless you have authenticated the user (users must prove that they are able to read emails sent to the stored (and validated) email address.)  Security questions  Security questions are insecure - avoid using them. Why? Anything a security question does, a password does better. Read PART III: Using Secret Questions in @Jens Roland answer here in this wiki.  Session cookies  After the user logs in, the server sends the user a session cookie. The server can retrieve the username or id from the cookie, but nobody else can generate such a cookie (TODO explain mechanisms).  Cookies can be hijacked: they are only as secure as the rest of the client's machine and other communications. They can be read from disk, sniffed in network traffic, lifted by a cross-site scripting attack, phished from a poisoned DNS so the client sends their cookies to the wrong servers. Don't send persistent cookies. Cookies should expire at the end of the client session (browser close or leaving your domain).  If you want to autologin your users, you can set a persistent cookie, but it should be distinct from a full-session cookie. You can set an additional flag that the user has auto-logged in, and needs to login for real for sensitive operations. This is popular with shopping sites that want to provide you with a seamless, personalized shopping experience but still protect your financial details. For example, when you return to visit Amazon, they show you a page that looks like you're logged in, but when you go to place an order (or change your shipping address, credit card etc.), they ask you to confirm your password.  Financial web sites such as banks and credit cards, on the other hand, only have sensitive data and should not allow auto-login or a low-security mode.  List of external resources   Dos and Don'ts of Client Authentication on the Web (PDF) 21 page academic article with many great tips.   Ask YC: Best Practices for User Authentication Forum discussion on the subject   You're Probably Storing Passwords Incorrectly Introductory article about storing passwords Discussion: Coding Horror: You're Probably Storing Passwords Incorrectly Forum discussion about a Coding Horror article. Never store passwords in a database! Another warning about storing passwords in the database. Password cracking Wikipedia article on weaknesses of several password hashing schemes. Enough With The Rainbow Tables: What You Need To Know About Secure Password Schemes Discussion about rainbow tables and how to defend against them, and against other threads. Includes extensive discussion.  ", 
        "type": "2", 
        "id": "555", 
        "parentId": "549"
    }, 
    {
        "content": "I would like to test a function with a tuple from a set of fringe cases and normal values. For example, while testing a function which returns true whenever given three lengths that form a valid triangle, I would have specific cases, negative / small / large numbers, values close-to being overflowed, etc.; what is more, main aim is to generate combinations of these values, with or without repetition, in order to get a set of test data.  (inf,0,-1), (5,10,1000), (10,5,5), (0,-1,5), (1000,inf,inf), ...   As a note: I actually know the answer to this, but it might be helpful for others, and a challenge for people here! --will post my answer later on. ", 
        "type": "1", 
        "id": "561", 
        "parentId": -1
    }, 
    {
        "content": "Uploading my first decently sized web app to my shared host provided me with a fresh set of challenges, by which I mean, sleepless nights. The issue was that I had most certainly not developed my application for medium trust (or had any clue what that was.)   I mitigated all of the issues, save one.   I had written an installer for the admin to be able to specify their connectionstring and other preferences, but I cannot find a way to write to a web.config in medium trust. Does anyone have a solution, or should I just be putting preferences in another file? ", 
        "type": "1", 
        "id": "562", 
        "parentId": -1
    }, 
    {
        "content": "I was just sitting at my local Borders sipping coffee and reading More Joel on Software (for free) when I came across Joel Spolsky saying something about a particular type of programmer knowing the difference between an int and an Integer in Java/C# (Object Oriented Programming Languages).  After a quick 'brain check,' I realized, to my dismay, that I didn't know the answer. ", 
        "type": "1", 
        "id": "564", 
        "parentId": -1
    }, 
    {
        "content": "In Java, the 'int' type is a primitive , whereas the 'Integer' type is an object.  In C#, the 'int' type is the same as System.Int32 and is a value type (ie more like the java 'int'). An integer (just like any other value types) can be boxed (\"wrapped\") into an object.     The differences between objects and primitives are somewhat beyond the scope of this question, but to summarize:   Objects provide facilities for polymorphism, are passed by reference (or more accurately have references passed by value), and are allocated from the heap. Conversely, primitives are immutable types that are passed by value and are often allocated from the stack. ", 
        "type": "2", 
        "id": "566", 
        "parentId": "564"
    }, 
    {
        "content": "Well, in Java an int is a primitive while an Integer is an Object. Meaning, if you made a new Integer:  Integer i = new Integer(6);   You could call some method on i:  String s = i.toString();//sets s the string representation of i   Whereas with an int:  int i = 6;   You cannot call any methods on it, because it is simply a primitive. So:  String s = i.toString();//will not work!!!   would produce an error, because int is not an object.  int is one of the few primitives in Java (along with char and some others). I'm not 100% sure, but I'm thinking that the Integer object more or less just has an int property and a whole bunch of methods to interact with that property (like the toString() method for example). So Integer is a fancy way to work with an int (Just as perhaps String is a fancy way to work with a group of chars).  I know that Java isn't C, but since I've never programmed in C this is the closest I could come to the answer. Hope this helps!  Integer object javadoc  Integer Ojbect vs. int primitive comparison ", 
        "type": "2", 
        "id": "568", 
        "parentId": "564"
    }, 
    {
        "content": "Sign up for an account on as many major email providers as possible (gmail/yahoo/hotmail/aol/etc). If you make changes to your emails, either major rewording, changes to the code that sends the emails, changes to your email servers, etc, make sure to send test messages to all your accounts and verify that they are not being marked as spam.", 
        "type": "2", 
        "id": "576", 
        "parentId": "371"
    }, 
    {
        "content": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005. Now, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.  Would you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).  Or - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).  And lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.  Now, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.  So, what are you using to automatically deploy SQL Server Databases from Test to Live? ", 
        "type": "1", 
        "id": "580", 
        "parentId": -1
    }, 
    {
        "content": "That actually sounds like IIS's Low level. If it is, then you won't be able to write to any file, not just the web.config.  Here are the levels from IIS's help file:      Full (internal) - Specifies unrestricted permissions. Grants the ASP.NET application permissions to access any resource that is subject to operating system security. All privileged operations are supported.   High (web_hightrust.config) - Specifies a high level of code access security, which means that the application cannot do any one of the following things by default:    Call unmanaged code.   Call serviced components.   Write to the event log.   Access Message Queuing service queues.   Access ODBC, OleDb, or Oracle data sources.   Medium (web_mediumtrust.config) - Specifies a medium level of code access security, which means that, in addition to High Trust Level restrictions, the ASP.NET application cannot do any of the following things by default:  Access files outside the application directory. Access the registry. Make network or Web service calls.   Low (web_lowtrust.config) - Specifies a low level of code access security, which means that, in addition to Medium Trust Level restrictions, the application cannot do any of the following things by default:  Write to the file system. Call the Assert method.   Minimal (web_minimaltrust.config) - Specifies a minimal level of code access security, which means that the application has only execute permissions.     I would suggest that if you are dead set on having an installer, have it create a web.config in memory that the user can save locally and FTP up afterward. ", 
        "type": "2", 
        "id": "582", 
        "parentId": "562"
    }, 
    {
        "content": "In C#, int is just an alias for System.Int32, string for System.String, double for System.Double etc...  Personally I prefer int, string, double, etc. because they don't require a using System; statement :) A silly reason, I know... ", 
        "type": "2", 
        "id": "583", 
        "parentId": "564"
    }, 
    {
        "content": "For my projects I alternate between SQL Compare from REd Gate and the Database Publishing Wizard from Microsoft which you can download free  here.    The Wizard isn't as slick as SQL Compare or SQL Data Compare but it does the trick. One issue is that the scripts it generates may need some rearranging and/or editing to flow in one shot.    On the up side, it can move your schema and data which isn't bad for a free tool.", 
        "type": "2", 
        "id": "585", 
        "parentId": "580"
    }, 
    {
        "content": "I've taken to hand-coding all of my DDL (creates/alter/delete) statements, adding them to my .sln as text files, and using normal versioning (using subversion, but any revision control should work). This way, I not only get the benefit of versioning, but updating live from dev/stage is the same process for code and database - tags, branches and so on work all the same.    Otherwise, I agree redgate is expensive if you don't have a company buying it for you. If you can get a company to buy it for you though, it really is worth it!", 
        "type": "2", 
        "id": "586", 
        "parentId": "580"
    }, 
    {
        "content": "I'm writing a CMS application in PHP and one of the requirements is that it must be able to interface with the customer's Exchange server.  I've written up this functionality a few times before and have always used WebDAV to do it, but now I'm leaning away from that.  I will be running the site on IIS OR Apache (no preference) on Windows server 2008.  A few things I would need to do include adding contacts to a given user's address book, sending emails as a given user and running reports on contacts for a user.  All of this is pretty easy to do with WebDAV, but if there is a better way that doesn't require any functionality that is likely to be deprecated any time soon.  Any ideas?  Update:  Justin, I love the idea of using com objects, I just worry about maintaining a 3rd product to make everything work...  John, I can write a web service in C# to interface with for these functions and access it with my PHP app, but it's also a little bit out of the way.  So far, I'm not 100% convinced that either of these is better than WebDAV...   Can anyone show me where I'm being silly? ", 
        "type": "1", 
        "id": "588", 
        "parentId": -1
    }, 
    {
        "content": "Interesting question!  I would do this by picking combinations, something like the following in python.  The hardest part is probably first pass verification, i.e. if f(1,2,3) returns true, is that a correct result?  Once you have verified that, then this is a good basis for regression testing.  Probably it's a good idea to make a set of test cases that you know will be all true (e.g. 3,4,5 for this triangle case), and a set of test cases that you know will be all false (e.g. 0,1,inf).  Then you can more easily verify the tests are correct.   # xpermutations from http://code.activestate.com/recipes/190465 from xpermutations import *  lengths=[-1,0,1,5,10,0,1000,'inf'] for c in xselections(lengths,3):        # or xuniqueselections     print c    (-1,-1,-1); (-1,-1,0); (-1,-1,1); (-1,-1,5); (-1,-1,10); (-1,-1,0); (-1,-1,1000); (-1,-1,inf); (-1,0,-1); (-1,0,0); ...  ", 
        "type": "2", 
        "id": "589", 
        "parentId": "561"
    }, 
    {
        "content": "If you have a company buying it, Toad from Quest Software has this kind of management functionality built in.  It's basically a two-click operation to compare two schemas and generate a sync script from one to the other.    They have editions for most of the popular databases, including of course Sql Server.", 
        "type": "2", 
        "id": "590", 
        "parentId": "580"
    }, 
    {
        "content": "I work the same way Karl does, by keeping all of my SQL scripts for creating and altering tables in a text file that I keep in source control.  In fact, to avoid the problem of having to have a script examine the live database to determine what ALTERs to run, I usually work like this:      On the first version, I place everything during testing into one SQL script, and treat all tables as a CREATE.  This means I end up dropping and readding tables a lot during testing, but that's not a big deal early into the project (since I'm usually hacking the data I'm using at that point anyway).  On all subsequent versions, I do two things: I make a new text file to hold the upgrade SQL scripts, that contain just the ALTERs for that version.  And I make the changes to the original, create a fresh database script as well.  This way an upgrade just runs the upgrade script, but if we have to recreate the DB we don't need to run 100 scripts to get there.  Depending on how I'm deploying the DB changes, I'll also usually put a version table in the DB that holds the version of the DB.  Then, rather than make any human decisions about which scripts to run, whatever code I have running the create/upgrade scripts uses the version to determine what to run.      The one thing this will not do is help if part of what you're moving from test to production is data, but if you want to manage structure and not pay for a nice, but expensive DB management package, is really not very difficult.  I've also found it's a pretty good way of keeping mental track of your DB.", 
        "type": "2", 
        "id": "591", 
        "parentId": "580"
    }, 
    {
        "content": "There are several ways to iterate over a result set, which way is the best? ", 
        "type": "1", 
        "id": "594", 
        "parentId": -1
    }, 
    {
        "content": "There are three ways to iterate over a result set.  The best way in terms of both  readability and performance is usually to use the built-in cursor iterator.    curs.execute('select * from people')  for row in curs:      print row      You can fetch all the rows into a list, but this can have some bad  side effects if the result set is large.      You have to wait for the entire result set to be returned to  your client process.  You may eat up a lot of memory in your client to hold  the built-up list.  It may take a while for Python to construct and deconstruct the  list which you are going to immediately discard anyways.      for row in curs.fetchall():      print row      Finally, you can loop over the result set fetching one row at   a time.  In general, there's no particular advantage in doing this over  using the iterator.  If there is something in your programming logic  that seems to indicate there is an advantage in doing this, perhaps  you should reconsider your programming logic.    row = curs.fetchone()  while row:      print row      row = curs.fetchone()", 
        "type": "2", 
        "id": "595", 
        "parentId": "594"
    }, 
    {
        "content": "I agree that scripting everything is the best way to go and is what I advocate at work.  You should script everything from DB and object creation to populating your lookup tables.    Anything you do in UI only won't translate (especially for changes... not so much for first deployments) and will end up requiring a tools like what Redgate offers.", 
        "type": "2", 
        "id": "597", 
        "parentId": "580"
    }, 
    {
        "content": "Confirm that you have the correct email address before sending out emails. If someone gives the wrong email address on sign-up, beat them over the head about it ASAP.    Always include clear \"how to unsubscribe\" information in EVERY email. Do not require the user to login to unsubscribe, it should be a unique url for 1-click unsubscribe.    This will prevent people from marking your mails as spam because \"unsubscribing\" is too hard.", 
        "type": "2", 
        "id": "598", 
        "parentId": "371"
    }, 
    {
        "content": "The typical solution is to dump the database as necessary and backup those files.    Depending on your development platform, there may be opensource plugins available. Rolling your own code to do it is usually fairly trivial.    Note: You may want to backup the database dump instead of putting it into version control.  The files can get huge fast in version control, and cause your entire source control system to become slow (I'm recalling a CVS horror story at the moment).", 
        "type": "2", 
        "id": "599", 
        "parentId": "173"
    }, 
    {
        "content": "This is a pretty good write-up of one guys experience of creating 30-day persistent sessions.  WARNING: blog post is from 2006  http://grahamglass.blogs.com/main/2006/05/rails_sessionsr.html ", 
        "type": "2", 
        "id": "600", 
        "parentId": "438"
    }, 
    {
        "content": "I'm looking for a performant, reasonably robust RNG using no special hardware. It can use mathematical methods (Mersenne Twister, etc), it can \"collect entropy\" from the machine, whatever. On Linux/etc we have a drand48() which generates 48 random bits. I'd like a similar function/class for C++ or C# which can generate more than 32 bits of randomness and which low-order bits are equally as random as high-order bits.  It doesn't have to be cryptographically secure but it must not use or be based on the C-language rand() or .NET System.Random.  Any source code, links to source, etc. would be appreciated! Failing that, what TYPE of RNG should I be looking for? ", 
        "type": "1", 
        "id": "601", 
        "parentId": -1
    }, 
    {
        "content": "For C++, Boost.Random is probably what you're looking for. It has support for MT (among many other algorithms), and can collect entropy via the nondet_random class. Check it out! :-)", 
        "type": "2", 
        "id": "602", 
        "parentId": "601"
    }, 
    {
        "content": "The Gnu Scientific Library (GSL) has a pretty extensive set of RN generators, test harness, etc.  If you're on linux, it's probably already available on your system.", 
        "type": "2", 
        "id": "605", 
        "parentId": "601"
    }, 
    {
        "content": "Hmm, ok.  I'd suggest code like this, then:    typedef struct {    int type;    int result;} DialogData;static gbooleandisplay_dialog(gpointer user_data){    DialogData *dialog_data = user_data;    GtkWidget *dialog;    if (dialog_data->type & MB_YESNO)        dialog = gtk_message_dialog_new(...);    else        dialog = gtk_message_dialog_new(...);    // Set title, etc.    dialog_data->result = gtk_dialog_run(...);    gtk_main_quit();  // Quits the main loop run in MessageBox()    return FALSE;}int MessageBox(...){    DialogData dialog_data;    dialog_data.type = type;    gtk_idle_add(display_dialog, &dialog_data);    gtk_main();    // Do stuff based on dialog_data.result}    The struct is because you need to pass around a couple pieces of data.  The gtk_idle_add() call adds a method to be run when the main loop is running and idle, and the FALSE return value from the display_dialog() call means that it's only run once.  After we get the result from the dialog, we quit the main loop.  That'll cause the gtk_main() in your main MessageBox() method to return, and you'll be able to access the result from there.    Hope this helps!", 
        "type": "2", 
        "id": "607", 
        "parentId": "263"
    }, 
    {
        "content": "I'll add to the excellent answers given above, and talk about boxing and unboxing, and how this applies to Java (although C# has it too). I'll use just Java terminology, because I am more au fait with that.    As the answers mentioned, int is just a number (called the unboxed type), whereas Integer is an object (which contains the number, hence a boxed type). In Java terms, that means (apart from not being able to call methods on int), you cannot store int or other non-object types in collections (List, Map, etc.). In order to store them, you must first box them up in its corresponding boxed type.    Java 5 onwards have something called auto-boxing and auto-unboxing which allow the boxing/unboxing to be done behind the scenes. Compare and contrast: Java 5 version:    Deque<Integer> queue;void add(int n) {    queue.add(n);}int remove() {    return queue.remove();}    Java 1.4 or earlier (no generics either):    Deque queue;void add(int n) {    queue.add(Integer.valueOf(n));}int remove() {    return ((Integer) queue.remove()).intValue();}    It must be noted that despite the brevity in the Java 5 version, both versions generate identical bytecode. Thus, although auto-boxing and auto-unboxing is very convenient because you write less code, these operations do happen behind the scenes, with the same runtime costs, so you still have to be aware of their existence.    Hope this helps!", 
        "type": "2", 
        "id": "608", 
        "parentId": "564"
    }, 
    {
        "content": "An MFC application that I'm trying to migrate uses afxext.h, which causes _AFXDLL to get set, which causes this error if I set /MT:     Please use the /MD switch for _AFXDLL builds   My research to date indicates that it is impossible to build an application for execution on Windows NT 4.0 using Visual Studio (C++, in this case) 2005.  Is this really true? Are there any workaround available? ", 
        "type": "1", 
        "id": "609", 
        "parentId": -1
    }, 
    {
        "content": "I'm not a PHP dev but Google says that PHP 5+ can instantiate COM components. If you can install Outlook on a box you could write a PHP web service around the COM component to handle the requests you need.     $outlook = COM(\"Outlook.Application\")    Outlook API referance", 
        "type": "2", 
        "id": "611", 
        "parentId": "588"
    }, 
    {
        "content": "It's been awhile since I used FCGI but I think a FCGI process could throw a SystemExit if the thread was taking too long.  This could be the web service not responding or even a slow DNS query.  Some google results show a similar error with Python and FCGI so moving to mongrel would be a good idea.  This post is my reference I used to setup mongrel and I still refer back to it. ", 
        "type": "2", 
        "id": "619", 
        "parentId": "514"
    }, 
    {
        "content": "I want to print the first 10000 prime numbers.  Can anyone give me the most efficient code for this?  Clarifications:      It does not matter if your code is inefficient for n >10000.  The size of the code does not matter.  You cannot just hard code the values in any manner.  ", 
        "type": "1", 
        "id": "622", 
        "parentId": -1
    }, 
    {
        "content": "The Sieve of Atkin is probably what you're looking for, its upper bound running time is O(N/log log N).  If you only run the numbers 1 more and 1 less than the multiples of 6, it could be even faster, as all prime numbers above 3 are 1 away from some multiple of six.  Resource for my statement ", 
        "type": "2", 
        "id": "623", 
        "parentId": "622"
    }, 
    {
        "content": "In Ruby 1.8, there are subtle differences between proc/lambda on the one hand, and Proc.new on the other.    What are those differences? Can you give guidelines on how to decide which one to choose? In Ruby 1.9, proc and lambda are different. What's the deal?  ", 
        "type": "1", 
        "id": "626", 
        "parentId": -1
    }, 
    {
        "content": "I found this page which shows what the difference between Proc.new and lambda are.  According to the page, the only difference is that a lambda is strict about the number of arguments it accepts, whereas Proc.new converts missing arguments to nil.  Here is an example IRB session illustrating the difference:  irb(main):001:0> l = lambda { |x, y| x + y } => #<Proc:0x00007fc605ec0748@(irb):1> irb(main):002:0> p = Proc.new { |x, y| x + y } => #<Proc:0x00007fc605ea8698@(irb):2> irb(main):003:0> l.call \"hello\", \"world\" => \"helloworld\" irb(main):004:0> p.call \"hello\", \"world\" => \"helloworld\" irb(main):005:0> l.call \"hello\" ArgumentError: wrong number of arguments (1 for 2)     from (irb):1     from (irb):5:in `call'     from (irb):5     from :0 irb(main):006:0> p.call \"hello\" TypeError: can't convert nil into String     from (irb):2:in `+'     from (irb):2     from (irb):6:in `call'     from (irb):6     from :0  The page also recommends using lambda unless you specifically want the error tolerant behavior.  I agree with this sentiment.  Using a lambda seems a tad more concise, and with such an insignificant difference, it seems the better choice in the average situation.  As for Ruby 1.9, sorry, I haven't looked into 1.9 yet, but I don't imagine they would change it all that much (don't take my word for it though, it seems you have heard of some changes, so I am probably wrong there). ", 
        "type": "2", 
        "id": "629", 
        "parentId": "626"
    }, 
    {
        "content": "I have not used PHP to do this but have experience in using C# to achieve the same thing.  The Outlook API is a way of automating Outlook rather than connecting to Exchange directly. I have previously taken this approach in a C# application and it does work although can be buggy.  If you wish to connect directly to the Exchange server you will need to research extended MAPI.  In the past I used this wrapper MAPIEx: Extended MAPI Wrapper.  It is a C# project but I believe you can use some .NET code on a PHP5 Windows server. Alternatively it has a C++ core DLL that you may be a able to use. I have found it to be very good and there are some good example applications.  Update:  Sorry for the delay no current way to keep track of posts yet.  I do agree adding more layer on to your application and relying on 3rd party code can be scary (and rightfully so.)  Today I read another interesting post tagged up as MAPI that is on a different subject. The key thing here though is that it has linked to this important MS article. I have been unaware of the issues until now on using managed code to interface to MAPI although the C++ code in the component should be unaffected by this error as it is unmanaged.   This blog entry also suggests other ways to connect to MAPI/Exchange server. In this case due to these new facts http://us3.php.net/imap may be the answer as suggested by the other user. ", 
        "type": "2", 
        "id": "633", 
        "parentId": "588"
    }, 
    {
        "content": "I write a SOAP server that receives XML requests, and creates XML responses.  (Unfortunately, it's not my project, so it's closed source, but that's another problem).    It turned out for me that creating (SOAP) XML documents is fairly simple, if you have a data structure that \"fits\" the schema.    I keep the envelope, since the response envelope is (almost) the same as the request envelope.  Then, since my data structure is a (possibly nested) dictionary, I create a string that turns this dictionary into <key>value</key> items.      This is a task that recursion makes simple, and I end up with the right structure.  This is all done in python code, and is currently fast enough for production use.    You can also (relatively) easily build lists as well, although depending upon your client, you may hit problems unless you give length hints.    For me, this was much simpler, since a dictionary is a much easier way of working than some custom class.  For the books, generating XML is much easier than parsing!", 
        "type": "2", 
        "id": "635", 
        "parentId": "337"
    }, 
    {
        "content": "I have a database table and one of the fields (not the primary key) is having a unique index on it. Now I want to swap values under this column for two rows. How could this be done? Two hacks I know are:   Delete both rows and re-insert them Update rows with some other value and swap and then update to actual value.   But I don't want to go for these as they do not seem to be the appropriate solution to the problem. Could anyone help me out? ", 
        "type": "1", 
        "id": "644", 
        "parentId": -1
    }, 
    {
        "content": "I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want.     I'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory.     I would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.    A short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?", 
        "type": "1", 
        "id": "650", 
        "parentId": -1
    }, 
    {
        "content": "I've been having trouble getting my ASP.NET application to automatically log users into the Intranet site I'm building.  No matter the googling or the experimentation I applied, there is always a login box displayed by IE7.  I've got Windows authentication mode set in the Web.config, disabled anonymous access and configured the correct default domain in IIS, but it's still asking the user to log in and, more annoyingly, the user is required to provide the domain too (DOMAIN\\auser), which is causing problems with non-technical visitors.  Thank Zeus for password remembering functionality.  I'm not the network administrator so it's possible that something about Active Directory is set up incorrectly, or it could just be me missing something very simple.  Please note that I don't want to impersonate the user, I just need to know that the IPrincipal.Name property matches that of a valid record in my user database, hence authenticating the user to my application.  To this end, it would be very useful to have a checklist of all configuration requirements for AD, ASP.NET and IIS to work together in this manner as a reference for debugging and hopefully reducing some user friction. ", 
        "type": "1", 
        "id": "651", 
        "parentId": -1
    }, 
    {
        "content": "With the \"Built in\" stuff, you can't, as using 1.0.* or 1.0.0.* will replace the revision and build numbers with a coded date/timestamp, which is usually also a good way.   For more info, see the Assembly Linker Documentation in the /v tag.  As for automatically incrementing numbers, use the AssemblyInfo Task:  AssemblyInfo Task  This can be configured to automatically increment the build number.  There are 2 Gotchas:   Each of the 4 numbers in the Version string is limited to 65535. This is a Windows Limitation and unlikely to get fixed.  Why are build numbers limited to 65535?  Using with with Subversion requires a small change:  Using MSBuild to generate assembly version info at build time (including SubVersion fix)    Retrieving the Version number is then quite easy:  Version v = Assembly.GetExecutingAssembly().GetName().Version; string About = string.Format(CultureInfo.InvariantCulture, @\"YourApp Version {0}.{1}.{2} (r{3})\", v.Major, v.Minor, v.Build, v.Revision);     And, to clarify: In .net or at least in C#, the build is actually the THIRD number, not the fourth one as some people (for example Delphi Developers who are used to Major.Minor.Release.Build) might expect.  In .net, it's Major.Minor.Build.Revision. ", 
        "type": "2", 
        "id": "655", 
        "parentId": "650"
    }, 
    {
        "content": "What is the fastest, yet secure way to encrypt passwords in (PHP preferred), and for which ever method you choose is it portable?  In other words if I later migrate my website to a different server will my passwords continue to work?  The method I am using now as I was told is dependent on the exact versions of the libraries installed on the server. ", 
        "type": "1", 
        "id": "657", 
        "parentId": -1
    }, 
    {
        "content": "Second the Buildbot - Trac integration. You can find more information about the integration on the Buildbot website. At my previous job, we wrote and used the plugin they mention (tracbb).  What the plugin does is rewriting all of the Buildbot urls so you can use Buildbot from within Trac. (http://example.com/tracbb).    The really nice thing about Buildbot is that the configuration is written in Python. You can integrate your own Python code directly to the configuration. It's also very easy to write your own BuildSteps to execute specific tasks.    We used BuildSteps to get the source from SVN, pull the dependencies, publish test results to WebDAV, etcetera.    I wrote an X10 interface so we could send signals with build results. When the build failed, we switched on a red lava lamp. When the build succeeded, a green lava lamp switched on. Good times :-)", 
        "type": "2", 
        "id": "660", 
        "parentId": "535"
    }, 
    {
        "content": "I think you should go for solution 2. There is no 'swap' function in any SQL variant I know of.    If you need to do this regularly, I suggest solution 1, depending on how other parts of the software are using this data. You can have locking issues if you're not careful.    But in short: there is no other solution than the ones you provided.", 
        "type": "2", 
        "id": "665", 
        "parentId": "644"
    }, 
    {
        "content": "It depends on what kind of application you are building. Create a representative test scenario, and start hammering away. Then you will know the definitive answer.    Besides your use case, it also depends on CPU, memory, front-side bus, operating system, cache settings, etcetera.    Seriously, just test your own scenario.    If you need some numbers (that actually may mean nothing in your scenario):      Oracle Berkeley DB:   Performance Metrics and   Benchmarks  Performance Metrics   & Benchmarks:   Berkeley DB  ", 
        "type": "2", 
        "id": "667", 
        "parentId": "264"
    }, 
    {
        "content": "If you are choosing an encryption method for your login system then speed is not your friend, Jeff had a to-and-frow with Thomas Ptacek about passwords and the conclusion was that you should use the slowest, most secure encryption method you can afford to.      From Thomas Ptacek's blog:   Speed is exactly what you don\u2019t want in a password hash function.      Modern password schemes are attacked with incremental password crackers.      Incremental crackers don\u2019t precalculate all possible cracked passwords. They consider each password hash individually, and they feed their dictionary through the password hash function the same way your PHP login page would. Rainbow table crackers like Ophcrack use space to attack passwords; incremental crackers like John the Ripper, Crack, and LC5 work with time: statistics and compute.      The password attack game is scored in time taken to crack password X. With rainbow tables, that time depends on how big your table needs to be and how fast you can search it. With incremental crackers, the time depends on how fast you can make the password hash function run.      The better you can optimize your password hash function, the faster your password hash function gets, the weaker your scheme is. MD5 and SHA1, even conventional block ciphers like DES, are designed to be fast. MD5, SHA1, and DES are weak password hashes. On modern CPUs, raw crypto building blocks like DES and MD5 can be bitsliced, vectorized, and parallelized to make password searches lightning fast. Game-over FPGA implementations cost only hundreds of dollars.   ", 
        "type": "2", 
        "id": "669", 
        "parentId": "657"
    }, 
    {
        "content": "Perhaps this is a little academic and off topic but hX tags are probably not the best choice for a tag cloud for reasons of document structure and all that sort of thing.  Maybe spans or an ol with appropriate class attributes (plus some CSS)? ", 
        "type": "2", 
        "id": "676", 
        "parentId": "227"
    }, 
    {
        "content": "I would use Javascript to submit the form. The function would be triggered by the OnKeyPress event of the form element, and would detect whether the Enter key was selected. If this is the case, it will submit the form.    Here are two pages that give techniques on how to do this: 1, 2. Based on these, here is an example of usage (based on here):    <SCRIPT TYPE=\"text/javascript\"><!--function submitenter(myfield,e) {  var keycode;  if (window.event) {    keycode = window.event.keyCode;  } else if (e) {     keycode = e.which;  } else {    return true;  }  if (keycode == 13) {    myfield.form.submit();    return false;  } else {    return true;  }}//--></SCRIPT><INPUT NAME=\"MyText\" TYPE=\"Text\" onKeyPress=\"return submitenter(this,event)\" />", 
        "type": "2", 
        "id": "679", 
        "parentId": "48"
    }, 
    {
        "content": "The main problem with PHP sessions and security (besides session hijacking) comes with what environment you are in. By default PHP stores the session data in a file in the OS's temp directory. Without any special thought or planning this is a world readable directory so all of your session information is public to anyone with access to the server.    As for maintaining sessions over multiple servers. At that point it would be better to switch PHP to user handled sessions where it calls your provided functions to CRUD (create, read, update, delete) the session data. At that point you could store the session information in a database or memcache like solution so that all application servers have access to the data.    Storing your own sessions may also be advantageous if you are on a shared server because it will let you store it in the database which you often times have more control over then the filesystem.", 
        "type": "2", 
        "id": "681", 
        "parentId": "328"
    }, 
    {
        "content": "I don't remember whether I was dreaming or not but I seem to recall there being a function which allowed something like,    foo in iter_attr(array of python objects, attribute name)    I've looked over the docs but this kind of thing doesn't fall under any obvious listed headers", 
        "type": "1", 
        "id": "683", 
        "parentId": -1
    }, 
    {
        "content": "I also think that #2 is the best bet, though I would be sure to wrap it in a transaction in case something goes wrong mid-update.    An alternative (since you asked) to updating the Unique Index values with different values would be to update all of the other values in the rows to that of the other row. Doing this means that you could leave the Unique Index values alone, and in the end, you end up with the data that you want. Be careful though, in case some other table references this table in a Foreign Key relationship, that all of the relationships in the DB remain intact.", 
        "type": "2", 
        "id": "684", 
        "parentId": "644"
    }, 
    {
        "content": "I'm with Peter. Developer don't seem to understand passwords. We all pick (and I'm guilty of this too) MD5 or SHA1 because they are fast. Thinking about it ('cuz someone recently pointed it out to me) that doesn't make any sense. We should be picking a hashing algorithm that's stupid slow. I mean, on the scale of things, a busy site will hash passwords what? every 1/2 minute? Who cares if it take 0.8 seconds vs 0.03 seconds server wise? But that extra slowness is huge to prevent all types of common brute-forcish attacks.    From my reading, bcrypt is specifically designed for secure password hashing. It's based on blowfish, and there are many implementation.    For PHP, check out PHPPass http://www.openwall.com/phpass/    For anyone doing .NET, check out BCrypt.NET http://derekslager.com/blog/posts/2007/10/bcrypt-dotnet-strong-password-hashing-for-dotnet-and-mono.ashx", 
        "type": "2", 
        "id": "691", 
        "parentId": "657"
    }, 
    {
        "content": "I've found that using the recipients real first and last name in the body is a sure fire way of getting through a spam filter.", 
        "type": "2", 
        "id": "693", 
        "parentId": "371"
    }, 
    {
        "content": "How often do you need to check for changes and how large (in terms of row size) are the tables in the database?  If you use the CHECKSUM_AGG(BINARY_CHECKSUM(*)) method suggested by John, it will scan every row of the specified table.  The NOLOCK hint helps, but on a large database, you are still hitting every row.  You will also need to store the checksum for every row so that you tell one has changed.  Have you considered going at this from a different angle?  If you do not want to modify the schema to add triggers, (which makes a sense, it's not your database), have you considered working with the application vendor that does make the database?    They could implement an API that provides a mechanism for notifying accessory apps that data has changed.  It could be as simple as writing to a notification table that lists what table and which row were modified.  That could be implemented through triggers or application code.  From your side, ti wouldn't matter, your only concern would be scanning the notification table on a periodic basis.  The performance hit on the database would be far less than scanning every row for changes.  The hard part would be convincing the application vendor to implement this feature.  Since this can be handles entirely through SQL via triggers, you could do the bulk of the work for them by writing and testing the triggers and then bringing the code to the application vendor.  By having the vendor support the triggers, it prevent the situation where your adding a trigger inadvertently replaces a trigger supplied by the vendor. ", 
        "type": "2", 
        "id": "695", 
        "parentId": "36"
    }, 
    {
        "content": "I've got an upcoming project wherein I will need to connect our website (PHP5/Apache 1.3/OpenBSD 4.1) to our back-end system running on a iSeries with OS400 V5R3 so that I can access some tables stored there. I've done some checking around but am running into some roadblocks.  From what I've seen the DB2 extensions and DB2 software from IBM only run under Linux. I've tried compiling the extensions with all the software from IBM and even tried their precompiled ibm_db2 extension with no luck. IBM only supports Linux so I turned on the Linux emulation in the kernel but that didn't seem to help anything.  If anyone has run across getting everything to run natively under OpenBSD that would be great, but what I think I may have to do is setting up a second server running CentOS with DB2 installed (most likely via ZendCore for IBM since it seems to do all this for me) and the driver so that I can set up a small transaction server that I can post against and get a JSON representation of the DB2 data that I need.  Does the second option seem overkill or does anyone else have any better ideas? ", 
        "type": "1", 
        "id": "696", 
        "parentId": -1
    }, 
    {
        "content": "The following works for me in Firefox and Internet Explorer:  <object id=\"mediaplayer\" classid=\"clsid:22d6f312-b0f6-11d0-94ab-0080c74c7e95\" codebase=\"http://activex.microsoft.com/activex/controls/mplayer/en/nsmp2inf.cab#version=5,1,52,701\" standby=\"loading microsoft windows media player components...\" type=\"application/x-oleobject\" width=\"320\" height=\"310\"> <param name=\"filename\" value=\"./test.wmv\">      <param name=\"animationatstart\" value=\"true\">      <param name=\"transparentatstart\" value=\"true\">      <param name=\"autostart\" value=\"true\">      <param name=\"showcontrols\" value=\"true\">      <param name=\"ShowStatusBar\" value=\"true\">      <param name=\"windowlessvideo\" value=\"true\">      <embed src=\"./test.wmv\" autostart=\"true\" showcontrols=\"true\" showstatusbar=\"1\" bgcolor=\"white\" width=\"320\" height=\"310\"> </object>  ", 
        "type": "2", 
        "id": "699", 
        "parentId": "164"
    }, 
    {
        "content": "No, you were not dreaming.  Python has a pretty excellent list comprehension system that lets you manipulate lists pretty elegantly, and depending on exactly what you want to accomplish, this can be done a couple of ways.  In essence, what you're doing is saying \"For item in list if criteria.matches\", and from that you can just iterate through the results or dump the results into a new list.  I'm going to crib an example from Dive Into Python here, because it's pretty elegant and they're smarter than I am.  Here they're getting a list of files in a directory, then filtering the list for all files that match a regular expression criteria.       files = os.listdir(path)                                    test = re.compile(\"test\\.py$\", re.IGNORECASE)               files = [f for f in files if test.search(f)]    You could do this without regular expressions, for your example, for anything where your expression at the end returns true for a match.  There are other options like using the filter() function, but if I were going to choose, I'd go with this.  Eric Sipple ", 
        "type": "2", 
        "id": "701", 
        "parentId": "683"
    }, 
    {
        "content": "Have you looked at connecting to the server using unixODBC? If I remember correctly it has support for IBM DB2 and compiles on OpenBSD. Check out http://www.php.net/odbc for more information regarding the PHP side.  If you can't get that to work, the option to setup a web service on a Linux server may be all you can do. ", 
        "type": "2", 
        "id": "704", 
        "parentId": "696"
    }, 
    {
        "content": "I was (and still am) looking for an embedded database to be used in a .net (c#) application. The caveat: The Application (or at least the database) is stored on a Network drive, but only used by 1 user at a time.    Now, my first idea was SQL Server Compact edition. That is really nicely integreated, but it can not run off a network.    Firebird seems to have the same issue, but the .net Integration seems to be not really first-class and is largely undocumented.    Blackfish SQL looks interesting, but there is no trial of the .net Version. Pricing is also OK.    Any other suggestions of something that works well with .net and runs off a network without the need of actually installing a server software?", 
        "type": "1", 
        "id": "705", 
        "parentId": -1
    }, 
    {
        "content": "SQLite came to my mind while reading your question, and I'm quite sure that it's possible to access it from a network drive if you keep yourself to the constraint of 1 user at a time.  SQLite on .NET - Get up and running in 3 minutes ", 
        "type": "2", 
        "id": "707", 
        "parentId": "705"
    }, 
    {
        "content": "I'm looking to introduce a unit testing framework into the mix at my job.  We're using Visual Studio 2005 (though we may be moving to 2008 within the next 6 months) and work primarily in C#.  If the framework has some kind of IDE integration that would be best, but I'm open to frameworks that don't have integration but are still relatively simple to get set up.  I'm going to get resistance to it one way or another, so if I can make sure what I'm pushing isn't a pain in the neck, that would help my case.  The obvious choice from the research I've done so far points to nUnit, but I'd like to get the impressions of someone who's actually used it before recommending it to my team.  Has anyone out there used nUnit?  If so, are there any pitfalls or limitations of which I should be aware?  Are there other good options out there?  If so, if you've used both nUnit at that, I'd greatly appreciate an idea of the strengths and weaknesses of them. ", 
        "type": "1", 
        "id": "709", 
        "parentId": -1
    }, 
    {
        "content": "Check out VistaDB. They have a very good product, the server version (3.4) is in Beta and is very close to release.", 
        "type": "2", 
        "id": "710", 
        "parentId": "705"
    }, 
    {
        "content": "Scott Hanselman had a good Podcast about this, entitled:     \"The Past, Present and Future of .NET Unit Testing Frameworks\"   :  Hanselminutes #112 ", 
        "type": "2", 
        "id": "712", 
        "parentId": "709"
    }, 
    {
        "content": "I think NUnit is your best bet. With TestDriven.NET, you get great integration within VS.NET. (Resharper also has a unit test runner if you're using it).  NUnit it simple to use and follows an established paradigm. You'll also find plenty of projects/tutorials/guides using it which always helps.  Your other main choice is probably MBUnit, which is more and more position itself as the BDD framework of choice (in conjunction with Gallio http://www.gallio.org). ", 
        "type": "2", 
        "id": "713", 
        "parentId": "709"
    }, 
    {
        "content": "I wrote a windows service using VB that read some legacy data from Visual Foxpro Databases to be inserted in SQL 2005. The problem is this use to run fine in Windows server 2003 32-Bits, but the client recently moved to Windows 2003 64-Bits and now the service won't work. I'm getting a message the the VFP .NET OLEdb provider is not found. I researched and everything seems to point out that there is no solution. Any Help, please...", 
        "type": "1", 
        "id": "717", 
        "parentId": -1
    }, 
    {
        "content": "Visual Studio 2008 has a built in test project type that works in a similar way to NUnit, but obviously has much tighter integration with Visual Studio (can run on every build and shows the results in a similar way to the conversion results page when upgrading solution files), but it is obviously not as mature as NUnit as it's pretty new and I'm not sure about how it handles mocking.  But it would be worth looking into when your team moves to VS2008 ", 
        "type": "2", 
        "id": "718", 
        "parentId": "709"
    }, 
    {
        "content": "Another important but subtle difference is in the way procs created with lambda and procs created with Proc.new handle the return statement:      In a lambda-created proc, the return statement returns only from the proc itself  In a Proc.new-created proc, the return statement is a little more surprising: it returns control not just from the proc, but also from the method enclosing the proc!      Here's lambda-created proc's return in action. It behaves in a way that you probably expect:    def whowouldwin  mylambda = lambda {return \"Freddy\"}  mylambda.call  # mylambda gets called and returns \"Freddy\", and execution  # continues on the next line  return \"Jason\"endwhowouldwin=> \"Jason\"    Now here's a Proc.new-created proc's return doing the same thing. You're about to see one of those cases where Ruby breaks the much-vaunted Principle of Least Surprise:    def whowouldwin2  myproc = Proc.new {return \"Freddy\"}  myproc.call  # myproc gets called and returns \"Freddy\",   # but also returns control from whowhouldwin2!  # The line below *never* gets executed.  return \"Jason\"endwhowouldwin2         => \"Freddy\"    Thanks to this surprising behaviour (as well as less typing), I tend to favour using lambda over Proc.new when making procs. ", 
        "type": "2", 
        "id": "723", 
        "parentId": "626"
    }, 
    {
        "content": "It sounds like you've covered all the server-side bases--maybe it's a client issue? I assume your users have integrated authentication enabled in IE7? (Tools -> Internet Options -> Advanced -> Security). This is enabled by default.  Also, is your site correctly recognized by IE7 as being in the Local Intranet zone? The IE7 default is to allow automatic logon only in that zone, so users would be prompted if IE thinks your site is on the internet. I believe using a hostname with a dot in it causes IE to place the site into the Internet zone.", 
        "type": "2", 
        "id": "725", 
        "parentId": "651"
    }, 
    {
        "content": "Why not use SQL Server 2005 Express edition?   It really depends on what you mean by \"embedded\" - but you can redistribute SQLServer2005E with your applications and the user never has to know it's there.  Embedding SQL Server Express in Applications  Embedding SQL Server Express into Custom Applications ", 
        "type": "2", 
        "id": "730", 
        "parentId": "705"
    }, 
    {
        "content": "I think:    #!/bin/pythonbar in dict(Foo)    Is what you are thinking of.  When trying to see if a certain key exists within a dictionary in python (python's version of a hash table) there are two ways to check.  First is the has_key() method attached to the dictionary and second is the example given above.  It will return a boolean value.    That should answer your question.    And now a little off topic to tie this in to the list comprehension answer previously given (for a bit more clarity).  List Comprehensions construct a list from a basic for loop with modifiers.  As an example (to clarify slightly), a way to use the in dict language construct in a _list comprehension_:    Say you have a two dimensional dictionary foo and you only want the second dimension dictionaries which contain the key bar.  A relatively straightforward way to do so would be to use a list comprehension with a conditional as follows:    #!/bin/pythonbaz = dict([(key, value) for key, value in foo if bar in value])    Note the if bar in value at the end of the statement, this is a modifying clause which tells the list comprehension to only keep those key-value pairs which meet the conditional.  In this case baz is a new dictionary which contains only the dictionaries from foo which contain bar (Hopefully I didn't miss anything in that code example... you may have to take a look at the list comprehension documentation found in docs.python.org tutorials and at secnetix.de, both sites are good references if you have questions in the future.).", 
        "type": "2", 
        "id": "735", 
        "parentId": "683"
    }, 
    {
        "content": "It sounds like ADO/Access is perfect for your needs. It's baked into the MS stack, well seasoned, and multi-user.    You can programatically create a DB like so:    Dim catalog as New ADOX.CatalogCatalog.Create(\"Provider=Microsoft.Jet.OLEDB.4.0;Data Source=\\\\server\\path\\to\\db.mdb\")    You can then use standard ADO.NET methods to interact with the database.", 
        "type": "2", 
        "id": "737", 
        "parentId": "705"
    }, 
    {
        "content": "Django view points to a function, which can be a problem if you want to change only a bit of functionality. Yes, I could have million keyword arguments and even more if statements in the function, but I was thinking more of an object oriented approach.    For example, I have a page that displays a user. This page is very similar to page that displays a group, but it's still not so similar to just use another data model. Group also has members etc...    One way would be to point views to class methods and then extend that class. Has anyone tried this approach or has any other idea? ", 
        "type": "1", 
        "id": "742", 
        "parentId": -1
    }, 
    {
        "content": "Are you looking to get a list of objects that have a certain attribute? If so, a list comprehension is the right way to do this.    result = [obj for obj in listOfObjs if hasattr(obj, 'attributeName')]", 
        "type": "2", 
        "id": "745", 
        "parentId": "683"
    }, 
    {
        "content": "How do I format a string to title case? ", 
        "type": "1", 
        "id": "746", 
        "parentId": -1
    }, 
    {
        "content": "Here is a simple static method to do this in C#:    public static string ToTitleCaseInvariant(string targetString){    return System.Threading.Thread.CurrentThread.CurrentCulture.TextInfo.ToTitleCase(targetString);}", 
        "type": "2", 
        "id": "747", 
        "parentId": "746"
    }, 
    {
        "content": "In what language?  In PHP it is:  ucwords()  example:  $HelloWorld = ucwords('hello world');  ", 
        "type": "2", 
        "id": "749", 
        "parentId": "746"
    }, 
    {
        "content": "What I was thinking of can be achieved using list comprehensions, but I thought that there was a function that did this in a slightly neater way.    i.e. 'bar' is a list of objects, all of which have the attribute 'id'    The mythical functional way:    foo = 12foo in iter_attr(bar, 'id')    The list comprehension way:    foo = 12foo in [obj.id for obj in bar]    In retrospect the list comprehension way is pretty neat anyway.", 
        "type": "2", 
        "id": "750", 
        "parentId": "683"
    }, 
    {
        "content": "Without using a ready-made function, a super-simple low-level algorithm to convert a string to title case:    convert first character to uppercase.for each character in string,    if the previous character is whitespace,        convert character to uppercase.    This asssumes the \"convert character to uppercase\" will do that correctly regardless of whether or not the character is case-sensitive (e.g., '+').", 
        "type": "2", 
        "id": "751", 
        "parentId": "746"
    }, 
    {
        "content": "One may not always know the Type of an object at compile-time, but may need to create an instance of the Type.  How do you get a new object instance from a Type?", 
        "type": "1", 
        "id": "752", 
        "parentId": -1
    }, 
    {
        "content": "One implementation of this problem is to attempt to call the parameter-less constructor of the Type:  public static object GetNewObject(Type t) {     try     {         return t.GetConstructor(new Type[] { }).Invoke(new object[] { });     }     catch     {         return null;     } }   Here is the same approach, contained in a generic method:  public static T GetNewObject<T>() {     try     {         return (T)typeof(T).GetConstructor(new Type[] { }).Invoke(new object[] { });     }     catch     {         return default(T);     } }  ", 
        "type": "2", 
        "id": "753", 
        "parentId": "752"
    }, 
    {
        "content": "If the language you are using has a supported method/function then just use that (as in the C# ToTitleCase method)  If it does not, then you will want to do something like the following:     Read in the string   Take the first word   Capitalize the first letter of that word 1 Go forward and find the next word   Go to 3 if not at the end of the string, otherwise exit     1 To capitalize it in, say, C - use the ascii codes to find the integer value of the char and subtract 32 from it.  There would need to be much more error checking in the code (ensuring valid letters etc.), and the \"Capitalize\" function will need to impose some sort of \"title-case scheme\" on the letters to check for words that do not need to be capatilised ('and', 'but' etc. Here is a good scheme) ", 
        "type": "2", 
        "id": "754", 
        "parentId": "746"
    }, 
    {
        "content": "The Activator class within the root System namespace is pretty powerful.  There are a lot of overloads for passing parameters to the constructor and such. Check out the documentation at:      http://msdn.microsoft.com/en-us/library/system.activator.createinstance.aspx   Here are some simple examples:  ObjectType instance = (ObjectType)Activator.CreateInstance(objectType);  ObjectType instance = (ObjectType)Activator.CreateInstance(\"MyAssembly\",\"MyNamespace.ObjectType\");  ", 
        "type": "2", 
        "id": "755", 
        "parentId": "752"
    }, 
    {
        "content": "No, there are many applications built with VS2005 that have to support Windows XP, 2000, NT, the whole stack. The issue is that (by default) VS2005 wants to use libraries/exports not present on NT.  See this thread for some background.  Then start limiting your dependencies via preprocessor macros, and avoiding APIs which aren't supported on NT.", 
        "type": "2", 
        "id": "759", 
        "parentId": "609"
    }, 
    {
        "content": "What is the best way to localise a date format descriptor?  As anyone from a culture which does not use the mm/dd/yyyy format knows, it is annoying to have to enter dates in this format. The .NET framework provides some very good localisation support, so it's trivial to parse dates according to the users culture, but you often want to also display a helpful hint as to the format required (especially to distinguish between yy and yyyy which is interchangeable in most cultures).  What is the best way to do this in a way that make sense to most users (e.g. dd/M/yyy is confusing because of the change in case and the switching between one and two letters). ", 
        "type": "1", 
        "id": "761", 
        "parentId": -1
    }, 
    {
        "content": "Here is my current method. Any suggestions?    Regex singleMToDoubleRegex = new Regex(\"(?<!m)m(?!m)\");Regex singleDToDoubleRegex = new Regex(\"(?<!d)d(?!d)\");CultureInfo currentCulture = CultureInfo.CurrentUICulture;// If the culture is netural there is no date pattern to use, so use the default.if (currentCulture.IsNeutralCulture){    currentCulture = CultureInfo.InvariantCulture;}// Massage the format into a more general user friendly form.string shortDatePattern = CultureInfo.CurrentUICulture.DateTimeFormat.ShortDatePattern.ToLower();shortDatePattern = singleMToDoubleRegex.Replace(shortDatePattern, \"mm\");shortDatePattern = singleDToDoubleRegex.Replace(shortDatePattern, \"dd\");", 
        "type": "2", 
        "id": "762", 
        "parentId": "761"
    }, 
    {
        "content": "How about giving the format (mm/dd/yyyy or dd/mm/yyyy) followed by a printout of today's date in the user's culture. MSDN has an article on formatting a DateTime for the person's culture, using the CultureInfo object that might be helpful in doing this. A combination of the format (which most people are familiar with) combined with the current date represented in that format should be enough of a clue to the person on how they should enter the date. (Also include a calendar control for those who still cant figure it out).", 
        "type": "2", 
        "id": "763", 
        "parentId": "761"
    }, 
    {
        "content": "Sounds to me like you're trying to combine things that shouldn't be combined.  If you need to do different processing in your view depending on if it's a User or Group object you're trying to look at then you should use two different view functions.    On the other hand there can be common idioms you'd want to extract out of your object_detail type views... perhaps you could use a decorator or just helper functions?    -Dan", 
        "type": "2", 
        "id": "764", 
        "parentId": "742"
    }, 
    {
        "content": "I can get Python to work with Postgresql but I cannot get it to work with MySQL. The main problem is that on the shared hosting account I have I do not have the ability to install things such as Django or PySQL, I generally fail when installing them on my computer so maybe it's good I can't install on the host.    I found bpgsql really good because it does not require an install, it's a single file that I can look at, read and then call the functions of. Does anybody know of something like this for MySQL?", 
        "type": "1", 
        "id": "766", 
        "parentId": -1
    }, 
    {
        "content": "You can print from the command line using the following:        rundll32.exe    %WINDIR%\\System32\\mshtml.dll,PrintHTML    \"%1\"      Where %1 is the file path of the html file to be printed.    If you don't need to print from memory (or can afford to write to the disk in a temp file) you can use:    using (Process printProcess = new Process()){    string systemPath = Environment.GetFolderPath(Environment.SpecialFolder.System);    printProcess.StartInfo.FileName = systemPath + @\"\\rundll32.exe\";    printProcess.StartInfo.Arguments = systemPath + @\"\\mshtml.dll,PrintHTML \"\"\" + fileToPrint + @\"\"\"\";    printProcess.Start();}    N.B. This only works on Windows 2000 and above I think.", 
        "type": "2", 
        "id": "768", 
        "parentId": "174"
    }, 
    {
        "content": "I need to programmatically solve a system of linear equations in C, Objective C, or (if needed) C++.  Here's an example of the equations:  -44.3940 = a * 50.0 + b * 37.0 + tx -45.3049 = a * 43.0 + b * 39.0 + tx -44.9594 = a * 52.0 + b * 41.0 + tx   From this, I'd like to get the best approximation for a, b, and tx. ", 
        "type": "1", 
        "id": "769", 
        "parentId": -1
    }, 
    {
        "content": "Just use ISO-8601. It's an international standard.  Date and time (current at page generation) expressed according to ISO 8601: Date:                           2014-07-05 Combined date and time in UTC:  2014-07-05T04:00:25+00:00                                 2014-07-05T04:00:25Z Week:                           2014-W27 Date with week number:          2014-W27-6 Ordinal date:                   2014-186  ", 
        "type": "2", 
        "id": "770", 
        "parentId": "761"
    }, 
    {
        "content": "Here's a Perl solution http://daringfireball.net/2008/05/title_case  Here's a Ruby solution http://frankschmitt.org/projects/title-case  Here's a Ruby one-liner solution: http://snippets.dzone.com/posts/show/4702  'some string here'.gsub(/\\b\\w/){$&.upcase}   What the one-liner is doing is using a regular expression substitution of the first character of each word with the uppercase version of it. ", 
        "type": "2", 
        "id": "771", 
        "parentId": "746"
    }, 
    {
        "content": "I haven't been able to find an understandable explanation of how to actually use Python's itertools.groupby() function.  What I'm trying to do is this:   Take a list - in this case, the children of an objectified lxml element Divide it into groups based on some criteria Then later iterate over each of these groups separately.   I've reviewed the documentation, and the examples, but I've had trouble trying to apply them beyond a simple list of numbers.   So, how do I use of itertools.groupby()?  Is there another technique I should be using?  Pointers to good \"prerequisite\" reading would also be appreciated. ", 
        "type": "1", 
        "id": "773", 
        "parentId": -1
    }, 
    {
        "content": "Are you looking for a software package that'll do the work or actually doing the matrix operations and such and do each step?    The the first, a coworker of mine just used Ocaml GLPK. It is just a wrapper for the GLPK, but it removes a lot of the steps of setting things up. It looks like you're going to have to stick with the GLPK, in C, though. For the latter, thanks to delicious for saving an old article I used to learn LP awhile back, PDF. If you need specific help setting up further, let us know and I'm sure, me or someone will wander back in and help, but, I think it's fairly straight forward from here. Good Luck! ", 
        "type": "2", 
        "id": "774", 
        "parentId": "769"
    }, 
    {
        "content": "I don't have any experience with http://www.SiteGround.com as a web host personally.      This is just a guess, but it's common for a shared host to support Python and MySQL with the MySQLdb module (e.g., GoDaddy does this).  Try the following CGI script to see if MySQLdb is installed.    #!/usr/bin/pythonmodule_name = 'MySQLdb'head = '''Content-Type: text/html%s is ''' % module_nametry:    __import__(module_name)    print head + 'installed'except ImportError:    print head + 'not installed'", 
        "type": "2", 
        "id": "777", 
        "parentId": "766"
    }, 
    {
        "content": "Cramer's Rule  and  Gaussian Elimination  are two good, general-purpose algorithms (also see Simultaneous Linear Equations). If you're looking for code, check out GiNaC, Maxima, and SymbolicC++ (depending on your licensing requirements, of course).    EDIT: I know you're working in C land, but I also have to put in a good word for SymPy (a  computer algebra system in Python). You can learn a lot from its algorithms (if you can read a bit of python). Also, it's under the new BSD license, while most of the free math packages are GPL.", 
        "type": "2", 
        "id": "781", 
        "parentId": "769"
    }, 
    {
        "content": "Can you show us your code?  The example on the Python docs is quite straightforward:  groups = [] uniquekeys = [] for k, g in groupby(data, keyfunc):     groups.append(list(g))      # Store group iterator as a list     uniquekeys.append(k)   So in your case, data is a list of nodes, keyfunc is where the logic of your criteria function goes and then groupby() groups the data.  You must be careful to sort the data by the criteria before you call groupby or it won't work. groupby method actually just iterates through a list and whenever the key changes it creates a new group. ", 
        "type": "2", 
        "id": "783", 
        "parentId": "773"
    }, 
    {
        "content": "What source control system are you using?     Almost all of them have some form of $ Id $ tag that gets expanded when the file is checked in.    I usually use some form of hackery to display this as the version number.    The other alternative is use to use the date as the build number: 080803-1448", 
        "type": "2", 
        "id": "787", 
        "parentId": "650"
    }, 
    {
        "content": "Not efficient at all, but you can use a regular expression to test for prime numbers.  /^1?$|^(11+?)\\1+$/   This tests if, for a string consisting of k \u201c1\u201ds, k is not prime (i.e. whether the string consists of one \u201c1\u201d or any number of \u201c1\u201ds that can be expressed as an n-ary product). ", 
        "type": "2", 
        "id": "791", 
        "parentId": "622"
    }, 
    {
        "content": "Absolutely, especially dealing with lots of these permutations/combinations I can definitely see that the first pass would be an issue.    Interesting implementation in python, though I wrote a nice one in C and Ocaml based on \"Algorithm 515\" (see below). He wrote his in Fortran as it was common back then for all the \"Algorithm XX\" papers, well, that assembly or c. I had to re-write it and make some small improvements to work with arrays not ranges of numbers. This one does random access, I'm still working on getting some nice implementations of the ones mentioned in Knuth 4th volume fascicle 2. I'll an explanation of how this works to the reader. Though if someone is curious, I wouldn't object to writing something up.    /** [combination c n p x] * get the [x]th lexicographically ordered set of [p] elements in [n] * output is in [c], and should be sizeof(int)*[p] */void combination(int* c,int n,int p, int x){    int i,r,k = 0;    for(i=0;i<p-1;i++){        c[i] = (i != 0) ? c[i-1] : 0;        do {            c[i]++;            r = choose(n-c[i],p-(i+1));            k = k + r;        } while(k < x);        k = k - r;    }    c[p-1] = c[p-2] + x - k;}    ~\"Algorithm 515: Generation of a Vector from the Lexicographical Index\"; Buckles, B. P., and Lybanon, M. ACM Transactions on Mathematical Software, Vol. 3, No. 2, June 1977.", 
        "type": "2", 
        "id": "794", 
        "parentId": "561"
    }, 
    {
        "content": "I would be wary of automatically upcasing all whitespace-preceded-words in scenarios where I would run the risk of attracting the fury of nitpickers.    I would at least consider implementing a dictionary for exception cases like articles and conjunctions. Behold:         \"Beauty and the Beast\"      And when it comes to proper nouns, the thing gets much uglier.", 
        "type": "2", 
        "id": "795", 
        "parentId": "746"
    }, 
    {
        "content": "The most popular (==standard?) way of determining the time zone I've seen around is simply asking the users themselves. If your website requires subscription, this could be saved in the users' profile data. For anon users, the dates could be displayed as UTC or GMT or some such.  I'm not trying to be a smart aleck. It's just that sometimes some problems have finer solutions outside of any programming context. ", 
        "type": "2", 
        "id": "797", 
        "parentId": "13"
    }, 
    {
        "content": "mbUnit is worth alook, it has a set of features comparable to NUnit, it has its own GUI, or can be integrated into VS if you have Resharper. I would also recommend Rhino Mocks if you are doing any sort of TDD. ", 
        "type": "2", 
        "id": "798", 
        "parentId": "709"
    }, 
    {
        "content": "Have you tried changing the target CPU to x86 instead of \"Any CPU\" in the advanced compiler options? I know that this solves some problems with other OLEDB providers by forcing the use of the 32-bit version. ", 
        "type": "2", 
        "id": "799", 
        "parentId": "717"
    }, 
    {
        "content": "I uploaded it and got an internal error    Premature end of script headers    After much playing around, I found that if I had    import cgiimport cgitb; cgitb.enable()import MySQLdb    It would give me a much more useful answer and say that it was not installed, you can see it yourself -> http://woarl.com/db.py    Oddly enough, this would produce an error    import MySQLdbimport cgiimport cgitb; cgitb.enable()    I looked at some of the other files I had up there and it seems that library was one of the ones I had already tried.", 
        "type": "2", 
        "id": "802", 
        "parentId": "766"
    }, 
    {
        "content": "This is ASP classic, not .Net.  We have to get a way to SFTP into a server to upload and download a couple of files, kicked off by a user.  What have other people used to do SFTP in ASP classic?  Not necessarily opposed to purchasing a control. ", 
        "type": "1", 
        "id": "805", 
        "parentId": -1
    }, 
    {
        "content": "I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that   This isn't possible This isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).   With that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project?   And, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above. ", 
        "type": "1", 
        "id": "810", 
        "parentId": -1
    }, 
    {
        "content": "The magic all seems to be in     visitortime.getTimezoneOffset()    That's cool, I didn't know about that. Does it work in IE, etc?  From there you should be able to use JS to ajax, set cookies, whatever. I'd probably go the cookie route myself.    You'll need to allow the user to change it though. We tried to use geolocation (via maxmind) to do this a while ago, and it was wrong reasonably often - enough to make it not worth doing, so we just let the user set it in their profile, and show a notice to users who haven't set theirs yet.", 
        "type": "2", 
        "id": "817", 
        "parentId": "13"
    }, 
    {
        "content": "I'm partway to my solution with this entry on MSDN (don't know how I couldn't find it before).  User/Machine Hive Subkeys and values entered under this hive will be installed under the HKEY_CURRENT_USER hive when a user chooses \"Just Me\" or the HKEY_USERS hive or when a user chooses \"Everyone\" during installation.  Registry Editor ", 
        "type": "2", 
        "id": "818", 
        "parentId": "810"
    }, 
    {
        "content": "First: Yes, this is something that belongs in the Application for the exact reson you specified: What happens after new user profiles are created? Sure, if you're using a domain it's possible to have some stuff put in the registry on creation, but this is not really a use case. The Application should check if there are seetings and use the default settings if not.    That being said, it IS possible to change other users Keys through the HKEY_USERS Hive.    I have no experience with the Visual Studio 2003 Setup Project, so here is a bit of (totally unrelated) VBScript code that might just give you an idea where to look:    const HKEY_USERS = &H80000003strComputer = \".\"Set objReg=GetObject(\"winmgmts:{impersonationLevel=impersonate}!\\\\\" & strComputer & \"\\root\\default:StdRegProv\")strKeyPath = \"\"objReg.EnumKey HKEY_USERS, strKeyPath, arrSubKeysstrKeyPath = \"\\Software\\Microsoft\\Windows\\CurrentVersion\\WinTrust\\Trust Providers\\Software Publishing\"For Each subkey In arrSubKeys    objReg.SetDWORDValue HKEY_USERS, subkey & strKeyPath, \"State\", 146944Next    (Code Courtesy of Jeroen Ritmeijer)", 
        "type": "2", 
        "id": "820", 
        "parentId": "810"
    }, 
    {
        "content": "You have an ascending list of numbers, what is the most efficient algorithm you can think of to get the ascending list of sums of every two numbers in that list.  Duplicates in the resulting list are irrelevant, you can remove them or avoid them if you like.    To be clear, I'm interested in the algorithm.  Feel free to post code in any language and paradigm that you like.", 
        "type": "1", 
        "id": "826", 
        "parentId": -1
    }, 
    {
        "content": "I'm guessing that because you want to set it for all users, that you're on some kind of shared computer, which is probably running under a domain?    HERE BE DRAGONS    Let's say Joe and Jane regularly log onto the computer, then they will each have 'registries'.    You'll then install your app, and the installer will employ giant hacks and disgusting things to set items under HKCU for them.    THEN, bob will come along and log on (he, and 500 other people have accounts in the domain and so can do this). He's never used this computer before, so he has no registry. The first time he logs in, windows creates him one, but he won't have your setting.     Your app then falls over or behaves incorrectly, and bob complains loudly about those crappy products from raynixon incorporated.    The correct answer is to just have some default settings in your app, which can write them to the registry if it doesn't find them. It's general good practice that your app should never depend on the registry, and should create things as needed, for any registry entry, not just HKCU, anyway", 
        "type": "2", 
        "id": "829", 
        "parentId": "810"
    }, 
    {
        "content": "SQL:  SELECT    u.id,    u.name,    isnull(MAX(h.dateCol), '1900-01-01') dateColWithDefault FROM universe u LEFT JOIN history h     ON u.id=h.id     AND h.dateCol<GETDATE()-1 GROUP BY u.Id, u.name  ", 
        "type": "1", 
        "id": "832", 
        "parentId": -1
    }, 
    {
        "content": "I have designed database tables (normalised, on an MS SQL server) and created a standalone windows front end for an application that will be used by a handful of users to add and edit information. We will add a web interface to allow searching accross our production area at a later date.  I am concerned that if two users start editing the same record then the last to commit the update would be the 'winner' and important information may be lost. A number of solutions come to mind but I'm not sure if I am going to create a bigger headache.    Do nothing and hope that two users are never going to be editing the same record at the same time. - Might never happed but what if it does?  Editing routine could store a copy of the original data as well as the updates and then compare when the user has finished editing. If they differ show user and comfirm update - Would require two copies of data to be stored.  Add last updated DATETIME column and check it matches when we update, if not then show differences. - requires new column in each of the relevant tables.  Create an editing table that registers when users start editing a record that will be checked and prevent other users from editing same record. - would require carful thought of program flow to prevent deadlocks and records becoming locked if a user crashes out of the program.  Are there any better solutions or should I go for one of these?", 
        "type": "1", 
        "id": "833", 
        "parentId": -1
    }, 
    {
        "content": "If you are looking for a truly language agnostic solution then you will be sorely disappointed in my opinion because you'll be stuck with a for loop and some conditionals. However if you opened it up to functional languages or functional language features (I'm looking at you LINQ) then my colleagues here can fill this page with elegant examples in Ruby, Lisp, Erlang, and others.", 
        "type": "2", 
        "id": "834", 
        "parentId": "826"
    }, 
    {
        "content": "I'm trying to setup CruiseControl.net at the moment. So far it works nice, but I have a Problem with the MSBuild Task.  According to the Documentation, it passes CCNetArtifactDirectory to MSBuild. But how do I use it?  I tried this:  <buildArgs>    /noconsolelogger /p:OutputPath=$(CCNetArtifactDirectory)\\test </buildArgs>   But that does not work. In fact, it kills the service with this error:     ThoughtWorks.CruiseControl.Core.Config.Preprocessor.EvaluationException: Reference to unknown symbol CCNetArtifactDirectory   Documentation is rather sparse, and google und mainly offers modifying the .sln Project file, which is what I want to avoid in order to be able to manually build this project later - I would really prefer /p:OutputPath. ", 
        "type": "1", 
        "id": "835", 
        "parentId": -1
    }, 
    {
        "content": "Looks like a web service is going to be the answer for me. On a production box I'd rather not have to go through compiling and maintaining my own special installation of PHP since ODBC support needs to be compiled in, according to the PHP documentation. ", 
        "type": "2", 
        "id": "836", 
        "parentId": "696"
    }, 
    {
        "content": "A solution, albeit one that defers handling of the null value to the code, could be:     DateTime yesterday = DateTime.Now.Date.AddDays(-1);   var collection=     from u in db.Universe     select new     {         u.id,         u.name,         MaxDate =(DateTime?)        (            from h in db.History            where u.Id == h.Id            && h.dateCol < yesterday            select h.dateCol         ).Max()     };   This does not produce exactly the same SQL, but does provide the same logical result. Translating \"complex\" SQL queries to LINQ is not always straightforward. ", 
        "type": "2", 
        "id": "837", 
        "parentId": "832"
    }, 
    {
        "content": "If you expect infrequent collisions, Optimistic Concurrency is probably your best bet.  Scott Mitchell wrote a comprehensive tutorial on implementing that pattern: Implementing Optimistic Concurrency ", 
        "type": "2", 
        "id": "838", 
        "parentId": "833"
    }, 
    {
        "content": "The best I could come up with is to produce a matrix of sums of each pair, and then merge the rows together, a-la merge sort.  I feel like I'm missing some simple insight that will reveal a much more efficient solution.    My algorithm, in Haskell:    matrixOfSums list = [[a+b | b <- list, b >= a] | a <- list]sortedSums = foldl merge [] matrixOfSums--A normal merge, save that we remove duplicatesmerge xs [] = xsmerge [] ys = ysmerge (x:xs) (y:ys) = case compare x y of    LT -> x:(merge xs (y:ys))    EQ -> x:(merge xs (dropWhile (==x) ys))    GT -> y:(merge (x:xs) ys)    I found a minor improvement, one that's more amenable to lazy stream-based coding.  Instead of merging the columns pair-wise, merge all of them at once.  The advantage being that you start getting elements of the list immediately.    -- wide-merge does a standard merge (ala merge-sort) across an arbitrary number of lists-- wideNubMerge does this while eliminating duplicateswideNubMerge :: Ord a => [[a]] -> [a]wideNubMerge ls = wideNubMerge1 $ filter (/= []) lswideNubMerge1 [] = []wideNubMerge1 ls = mini:(wideNubMerge rest)    where mini = minimum $ map head ls          rest = map (dropWhile (== mini)) lsbetterSortedSums = wideNubMerge matrixOfSums    However, if you know you're going to use all of the sums, and there's no advantage to getting some of them earlier, go with 'foldl merge []', as it's faster.", 
        "type": "2", 
        "id": "840", 
        "parentId": "826"
    }, 
    {
        "content": "Suppose I have the following CSS rule in my page:  body {     font-family: Calibri, Trebuchet MS, Helvetica, sans-serif; }   How can I detect which one of the defined fonts was used in the user's browser?  Edit for people wondering why I want to do this: The font I'm detecting contains glyph's that are not available in other fonts and when the user does not have the font I want to display a link asking the user to download that font so they can use my web application with the correct font.  Currently I am displaying the download font link for all users, I want to only display this for people who do not have the correct font installed. ", 
        "type": "1", 
        "id": "845", 
        "parentId": -1
    }, 
    {
        "content": "I've seen it done in a kind of iffy, but pretty reliable way.  Basically, an element is set to use a specific font and a string is set to that element.  If the font set for the element does not exist, it takes the font of the parent element.  So, what they do is measure the width of the rendered string.  If it matches what they expected for the desired font as opposed to the derived font, it's present.  Here's where it came from: Javascript/CSS Font Detector (ajaxian.com; 12 Mar 2007) ", 
        "type": "2", 
        "id": "849", 
        "parentId": "845"
    }, 
    {
        "content": "Is there an easy way to produce MSDN-style documentation from the Visual Studio XML output? I'm not patient enough to set up a good xslt for it because I know I'm not the first person to cross this bridge.    Also, I tried setting up sandcastle recently, but it really made my eyes cross.  Either I was missing something important in the process or it is just way too involved.  I know somebody out there has a really nice dead-simple solution.  I'm reiterating here because I think my formatting made that paragraph non-inviting to read:     I gave sandcastle a try but had a really hard time getting it set up.   What I really have in mind is something much simpler.   That is, unless I just don't understand the sandcastle process.  It seemed like an awful lot of extra baggage to me just to produce something nice for the testers to work with. ", 
        "type": "1", 
        "id": "855", 
        "parentId": -1
    }, 
    {
        "content": "You're looking for Sandcastle  Project Page: Sandcastle Releases  Blog: Sandcastle Blog  NDoc Code Documentation Generator for .NET used to be the tool of choice, but support has all but stopped. ", 
        "type": "2", 
        "id": "858", 
        "parentId": "855"
    }, 
    {
        "content": "Have a look at Sandcastle, which does exactly that. It's also one of the more simpler solutions out there, and it's more or less the tool of choice, so in the long run, maybe we could help you to set up Sandcastle if you specify what issues you encountered during setup?", 
        "type": "2", 
        "id": "859", 
        "parentId": "855"
    }, 
    {
        "content": "Despite what the MSDN article  says about User/Machine Hive, it doesn't write to HKEY_USERS. Rather it writes to HKCU if you select Just Me and HKLM if you select Everyone.    So my solution is going to be to use the User/Machine Hive, and then in the application it checks if the registry entries are in HKCU and if not, copies them from HKLM. I know this probably isn't the most ideal way of doing it, but it has the least amount of changes.", 
        "type": "2", 
        "id": "870", 
        "parentId": "810"
    }, 
    {
        "content": "I've been using Subversion for a few years and after using SourceSafe, I just love Subversion.  Combined with TortoiseSVN, I can't really imagine how it could be any better.    Yet there's a growing number of developers claiming that Subversion has problems and that we should be moving to the new breed of distributed version control systems, such as Git.    How does Git improve upon Subversion? ", 
        "type": "1", 
        "id": "871", 
        "parentId": -1
    }, 
    {
        "content": "Google Tech Talk: Linus Torvalds on git    http://www.youtube.com/watch?v=4XpnKHJAok8    The Git Wiki's comparison page    http://git.or.cz/gitwiki/GitSvnComparsion", 
        "type": "2", 
        "id": "873", 
        "parentId": "871"
    }, 
    {
        "content": "Git is not better than Subversion. But is also not worse. It's different.  The key difference is that it is decentralized. Imagine you are a developer on the road, you develop on your laptop and you want to have source control so that you can go back 3 hours.  With Subversion, you have a Problem: The SVN Repository may be in a location you can't reach (in your company, and you don't have internet at the moment), you cannot commit. If you want to make a copy of your code, you have to literally copy/paste it.  With Git, you do not have this problem. Your local copy is a repository, and you can commit to it and get all benefits of source control. When you regain connectivity to the main repository, you can commit against it.  This looks good at first, but just keep in mind the added complexity to this approach.  Git seems to be the \"new, shiny, cool\" thing. It's by no means bad (there is a reason Linus wrote it for the Linux Kernel development after all), but I feel that many people jump on the \"Distributed Source Control\" train just because it's new and is written by Linus Torvalds, without actually knowing why/if it's better.  Subversion has Problems, but so does Git, Mercurial, CVS, TFS or whatever.  Edit: So this answer is now a year old and still generates many upvotes, so I thought I'll add some more explanations. In the last year since writing this, Git has gained a lot of momentum and support, particularly since sites like GitHub really took off. I'm using both Git and Subversion nowadays and I'd like to share some personal insight.  First of all, Git can be really confusing at first when working decentralized. What is a remote? and How to properly set up the initial repository? are two questions that come up at the beginning, especially compared to SVN's simple \"svnadmin create\", Git's \"git init\" can take the parameters --bare and --shared which seems to be the \"proper\" way to set up a centralized repository. There are reasons for this, but it adds complexity. The documentation of the \"checkout\" command is very confusing to people changing over - the \"proper\" way seems to be \"git clone\", while \"git checkout\" seems to switch branches.  Git REALLY shines when you are decentralized. I have a server at home and a Laptop on the road, and SVN simply doesn't work well here. With SVN, I can't have local source control if I'm not connected to the repository (Yes, I know about SVK or about ways to copy the repo). With Git, that's the default mode anyway. It's an extra command though (git commit commits locally, whereas git push origin master pushes the master branch to the remote named \"origin\").  As said above: Git adds complexity. Two modes of creating repositories, checkout vs. clone, commit vs. push... You have to know which commands work locally and which work with \"the server\" (I'm assuming most people still like a central \"master-repository\").  Also, the tooling is still insufficient, at least on Windows. Yes, there is a Visual Studio AddIn, but I still use git bash with msysgit.  SVN has the advantage that it's MUCH simpler to learn: There is your repository, all changes to towards it, if you know how to create, commit and checkout and you're ready to go and can pickup stuff like branching, update etc. later on.  Git has the advantage that it's MUCH better suited if some developers are not always connected to the master repository. Also, it's much faster than SVN. And from what I hear, branching and merging support is a lot better (which is to be expected, as these are the core reasons it was written).  This also explains why it gains so much buzz on the Internet, as Git is perfectly suited for Open Source projects: Just Fork it, commit your changes to your own Fork, and then ask the original project maintainer to pull your changes. With Git, this just works. Really, try it on Github, it's magic.  What I also see are Git-SVN Bridges: The central repository is a Subversion repo, but developers locally work with Git and the bridge then pushes their changes to SVN.  But even with this lengthy addition, I still stand by my core message: Git is not better or worse, it's just different. If you have the need for \"Offline Source Control\" and the willingness to spend some extra time learning it, it's fantastic. But if you have a strictly centralized Source Control and/or are struggling to introduce Source Control in the first place because your co-workers are not interested, then the simplicity and excellent tooling (at least on Windows) of SVN shine. ", 
        "type": "2", 
        "id": "875", 
        "parentId": "871"
    }, 
    {
        "content": "Well, it's distributed. Benchmarks indicate that it's considerably faster (given its distributed nature, operations like diffs and logs are all local so of course it's blazingly faster in this case), and working folders are smaller (which still blows my mind).  When you're working on subversion, or any other client/server revision control system, you essentially create working copies on your machine by checking-out revisions. This represents a snapshot in time of what the repository looks like. You update your working copy via updates, and you update the repository via commits.  With a distributed version control, you don't have a snapshot, but rather the entire codebase. Wanna do a diff with a 3 month old version? No problem, the 3 month old version is still on your computer. This doesn't only mean things are way faster, but if you're disconnected from your central server, you can still do many of the operations you're used to. In other words, you don't just have a snapshot of a given revision, but the entire codebase.  You'd think that Git would take up a bunch of space on your harddrive, but from a couple benchmarks I've seen, it actually takes less. Don't ask me how. I mean, it was built by Linus, he knows a thing or two about filesystems I guess. ", 
        "type": "2", 
        "id": "876", 
        "parentId": "871"
    }, 
    {
        "content": "You'll need to compile with the target CPU set to x86 to force your code to use the 32 bit version of the VFP OLE Db provider.    Microsoft has stated that there are no plans on releasing a 64-bit edition of the Visual FoxPro OLE Db provider.  For what's worth, Microsoft has also stated that VFP 9 is the final version of Visual FoxPro and support will end in 2015.  If you need the OLE DB provider for VFP 9, you can get it here. ", 
        "type": "2", 
        "id": "877", 
        "parentId": "717"
    }, 
    {
        "content": "Are PHP variables passed by value or by reference? ", 
        "type": "1", 
        "id": "879", 
        "parentId": -1
    }, 
    {
        "content": "Depends on the version, 4 is by value, 5 is by reference.", 
        "type": "2", 
        "id": "880", 
        "parentId": "879"
    }, 
    {
        "content": "PHP variables are assigned by value, passed to functions by value, and when containing/representing objects are passed by reference. You can force variables to pass by reference using an &  Assigned by value/reference example:  $var1 = \"test\"; $var2 = $var1; $var2 = \"new test\"; $var3 = &$var2; $var3 = \"final test\";  print (\"var1: $var1, var2: $var2, var3: $var3);   would output \"var1: test, var2: final test, var3: final test\".  Passed by value/reference exampe:  $var1 = \"foo\"; $var2 = \"bar\";  changeThem($var1, $var2);  print \"var1: $var1, var2: $var2\";  function changeThem($var1, &$var2){     $var1 = \"FOO\";     $var2 = \"BAR\"; }   would output: \"var1: foo, var2 BAR\".  Object variables passed by reference exampe:  class Foo{     public $var1;      function __construct(){         $this->var1 = \"foo\";     }      public function printFoo(){         print $this->var1;     } }   $foo = new Foo();  changeFoo($foo);  $foo->printFoo();  function changeFoo($foo){     $foo->var1 = \"FOO\"; }   Would output: \"FOO\"  (that last example could be better probably...) ", 
        "type": "2", 
        "id": "881", 
        "parentId": "879"
    }, 
    {
        "content": "Rather than coding this out, I figure I'll pseudo-code it in steps and explain my logic, so that better programmers can poke holes in my logic if necessary.   On the first step we start out with a list of numbers length n. For each number we need to create a list of length n-1 becuase we aren't adding a number to itself. By the end we have a list of about n sorted lists that was generated in O(n^2) time.  step 1 (startinglist)  for each number num1 in startinglist    for each number num2 in startinglist       add num1 plus num2 into templist    add templist to sumlist return sumlist    In step 2 because the lists were sorted by design (add a number to each element in a sorted list and the list will still be sorted) we can simply do a mergesort by merging each list together rather than mergesorting the whole lot.  In the end this should take O(n^2) time.  step 2 (sumlist)  create an empty list mergedlist for each list templist in sumlist    set mergelist equal to: merge(mergedlist,templist) return mergedlist   The merge method would be then the normal merge step with a check to make sure that there are no duplicate sums.  I won't write this out because anyone can look up mergesort.  So there's my solution.  The entire algorithm is O(n^2) time.  Feel free to point out any mistakes or improvements. ", 
        "type": "2", 
        "id": "884", 
        "parentId": "826"
    }, 
    {
        "content": "It's by value according to the PHP Documentation.     By default, function arguments are passed by value (so that if the value of the argument within the function is changed, it does not get changed outside of the function). To allow a function to modify its arguments, they must be passed by reference.      To have an argument to a function always passed by reference, prepend an ampersand (&) to the argument name in the function definition.   <?php function add_some_extra(&$string) {     $string .= 'and something extra.'; }  $str = 'This is a string, '; add_some_extra($str); echo $str;    // outputs 'This is a string, and something extra.' ?>  ", 
        "type": "2", 
        "id": "885", 
        "parentId": "879"
    }, 
    {
        "content": "Git and DVCS in general is great for developers doing a lot of coding independently of each other because everyone has their own branch.  If you need a change from someone else, though, she has to commit to her local repo and then she must push that changeset to you or you must pull it from her.    My own reasoning also makes me think DVCS makes things harder for QA and release management if you do things like centralized releases.  Someone has to be responsible for doing that push/pull from everyone else's repository, resolving any conflicts that would have been resolved at initial commit time before, then doing the build, and then having all the other developers re-sync their repos.    All of this can be addressed with human processes, of course; DVCS just broke something that was fixed by centralized version control in order to provide some new conveniences.", 
        "type": "2", 
        "id": "886", 
        "parentId": "871"
    }, 
    {
        "content": "How do you debug PHP scripts?  I am aware of basic debugging such as using the Error Reporting. The breakpoint debugging in PHPEclipse is also quite useful.  What is the best (in terms of fast and easy) way to debug in phpStorm or any other IDE? ", 
        "type": "1", 
        "id": "888", 
        "parentId": -1
    }, 
    {
        "content": "I've used the Zend Studio (5.5), together with Zend Platform. That gives proper debugging, breakpoints/stepping over the code etc., although at a price.", 
        "type": "2", 
        "id": "889", 
        "parentId": "888"
    }, 
    {
        "content": "Try Eclipse PDT to setup an Eclipse environment that has debugging features like you mentioned. The ability to step into the code is a much better way to debug then the old method of var_dump and print at various points to see where your flow goes wrong. When all else fails though and all I have is SSH and vim I still var_dump()/die() to find where the code goes south. ", 
        "type": "2", 
        "id": "890", 
        "parentId": "888"
    }, 
    {
        "content": "print_r( debug_backtrace() );    or something like that :-)", 
        "type": "2", 
        "id": "891", 
        "parentId": "888"
    }, 
    {
        "content": "It's all about the ease of use/steps required to do something.    If I'm developing a single project on my PC/laptop, git is better, because it is far easier to set up and use.   You don't need a server, and you don't need to keep typing repository URL's in when you do merges.    If it were just 2 people, I'd say git is also easier, because you can just push and pull from eachother.    Once you get beyond that though, I'd go for subversion, because at that point you need to set up a 'dedicated' server or location.     You can do this just as well with git as with SVN, but the benefits of git get outweighed by the need to do additional steps to synch with a central server. In SVN you just commit. In git you have to git commit, then git push. The additional step gets annoying simply because you end up doing it so much.    SVN also has the benefit of better GUI tools, however the git ecosystem seems to be catching up quickly, so I wouldn't worry about this in the long term.", 
        "type": "2", 
        "id": "893", 
        "parentId": "871"
    }, 
    {
        "content": "If you have the ability to use WScript.Shell then you can just execute pscp.exe from the Putty package. Obviously this is less then ideal but it will get the job done and let you use SCP/SFTP in classic ASP.", 
        "type": "2", 
        "id": "894", 
        "parentId": "805"
    }, 
    {
        "content": "I am by no means authoritative, but I believe the only supported path is from 6.5 to 7. Certainly that would be the most sane route, then I believe you can migrate from 7 directly to 2005 pretty painlessly.    As for scripting out all the objects - I would advise against it as you will inevitably miss something (unless you database is truly trivial).", 
        "type": "2", 
        "id": "895", 
        "parentId": "194"
    }, 
    {
        "content": "http://www.php.net/manual/en/migration5.oop.php    In PHP 5 there is a new Object Model. PHP's handling of objects has been completely rewritten, allowing for better performance and more features. In previous versions of PHP, objects were handled like primitive types (for instance integers and strings). The drawback of this method was that semantically the whole object was copied when a variable was assigned, or passed as a parameter to a method. In the new approach, objects are referenced by handle, and not by value (one can think of a handle as an object's identifier). ", 
        "type": "2", 
        "id": "896", 
        "parentId": "879"
    }, 
    {
        "content": "Variables containing primitive types are passed by value in PHP5. Variables containing objects are passed by reference. There's quite an interesting article from Linux Journal from 2006 which mentions this and other OO differences between 4 and 5.    http://www.linuxjournal.com/article/9170 ", 
        "type": "2", 
        "id": "897", 
        "parentId": "879"
    }, 
    {
        "content": "How have you implemented Internationalization (i18n) in actual projects you've worked on?  I took an interest in making software cross-cultural after I read the famous post by Joel, The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!). However, I have yet to able to take advantage of this in a real project, besides making sure I used Unicode strings where possible. But making all your strings Unicode and ensuring you understand what encoding everything you work with is in is just the tip of the i18n iceberg.  Everything I have worked on to date has been for use by a controlled set of US English speaking people, or i18n just wasn't something we had time to work on before pushing the project live. So I am looking for any tips or war stories people have about making software more localized in real world projects. ", 
        "type": "1", 
        "id": "898", 
        "parentId": -1
    }, 
    {
        "content": "Given a relatively simple CSS:  <div style=\"width:150px;\">   12333-2333-233-23339392-332332323 </div>   How do I make it so that the string stays constrained to the width of 150, and simply wraps to a newline on the hyphen? ", 
        "type": "1", 
        "id": "904", 
        "parentId": -1
    }, 
    {
        "content": "We're upgrading an existing program from Win2k/SQL Server 2k to Windows 2003 and SQL Server 2005 as well as purchasing a new program that also uses 2k3/2k5. The vendor says that for us to host both databases we need to get the Enterprise version because the softwares clients use different collation for the connections and only Enterprise supports this.  I cannot find anything on MS's site to support this and, honestly, don't want to pay the extra for Enterprise if the Standard edition works. Am I missing some not talked about feature of SQL Server or is this, as I suspect, a vendor trying to upsell me? ", 
        "type": "1", 
        "id": "905", 
        "parentId": -1
    }, 
    {
        "content": "I worked on a project for my previous employer that used .NET, and there was a built in .resx format we used.  We basically had a file that had all translations in the .resx file, and then multiple files with different translations.  The consequence of this is that you have to be very diligent about ensuring that all strings visible in the application are stored in the .resx, and anytime one is changed you have to update all languages you support.  If you get lazy and don't notify the people in charge of translations, or you embed strings without going through your localization system, it will be a nightmare to try and fix it later.  Similarly, if localization is an afterthought, it will be very difficult to put in place.  Bottom line, if you don't have all visible strings stored externally in a standard place, it will be very difficult to find all that need to be localized.  One other note, very strictly avoid concatenating visible strings directly, such as  String message = \"The \" + item + \" is on sale!\";   Instead, you must use something like  String message = String.Format(\"The {0} is on sale!\", item);   The reason for this is that different languages often order the words differently, and concatenating strings directly will need a new build to fix, but if you used some kind of string replacement mechanism like above, you can modify your .resx file (or whatever localization files you use) for the specific language that needs to reorder the words. ", 
        "type": "2", 
        "id": "906", 
        "parentId": "898"
    }, 
    {
        "content": "If you can find a professional or some other super-enterprise version of Visual Studio 6.0 - it came with a copy of MSDE (Basically the predecessor to SQL Express). I believe MSDE 2000 is still available as a free download from Microsoft, but I don't know if you can migrate directly from 6.5 to 2000.    I think in concept, you won't likely face any danger. Years of practice however tell me that you will always miss some object, permission, or other database item that won't manifest itself immediately. If you can script out the entire dump, the better as you will be less likely to miss something - and if you do miss something, it can be easily added to the script and fixed. I would avoid any manual steps (other than hitting the enter key once) like the plague.", 
        "type": "2", 
        "id": "908", 
        "parentId": "194"
    }, 
    {
        "content": "With Git, you can do practically anything offline, because everybody has their own repository.  Making branches and merging between branches is really easy.  Even if you don't have commit rights for a project, you can still have your own repository online, and publish \"push requests\" for your patches. Everybody who likes your patches can pull them into their project, including the official maintainers.  It's trivial to fork a project, modify it, and still keep merging in the bugfixes from the HEAD branch.   Git works for the Linux kernel developers. That means it is really fast (it has to be), and scales to thousands of contributors. Git also uses less space (up to 30 times less space for the Mozilla repository).  Git is very flexible, very TIMTOWTDI (There is more than one way to do it). You can use whatever workflow you want, and Git will support it.  Finally, there's GitHub, a great site for hosting your Git repositories.  Drawbacks of Git:    it's much harder to learn, because Git has more concepts and more commands. revisions don't have version numbers like in subversion many Git commands are cryptic, and error messages are very user-unfriendly it lacks a good GUI (such as the great TortoiseSVN)  ", 
        "type": "2", 
        "id": "910", 
        "parentId": "871"
    }, 
    {
        "content": "Replace your hyphens with this:    &shy;    It's called a \"soft\" hyphen.", 
        "type": "2", 
        "id": "911", 
        "parentId": "904"
    }, 
    {
        "content": "As part of CSS3, it is not yet fully supported, but you can find information on word-wrapping here. Another option is the wbr tag, &shy;, and &#8203; none of which are fully supported either. ", 
        "type": "2", 
        "id": "912", 
        "parentId": "904"
    }, 
    {
        "content": "Some fun things:      Having a PHP and MySQL Application that works well with German and French, but now needs to support Russian and Chinese. I think I move this over to .net, as PHP's Unicode support is - in my opinion - not really good. Sure, juggling around with utf8_de/encode or the mbstring-functions is fun. Almost as fun as having Freddy Kr\u00fcger visit you at night...  Realizing that some languages are a LOT more Verbose than others. German is a LOT more verbose than English usually, and seeing how the German Version destroys the User Interface because too little space was allocated was not fun. Some products gained some fame for their creative ways to work around that, with Oblivion's \"Schw.Tr.d.Le.En.W.\" being memorable :-)  Playing around with date formats, woohoo! Yes, there ARE actually people in the world who use date formats where the day goes in the middle. Sooooo much fun trying to find out what 07/02/2008 is supposed to mean, just because some users might believe it could be July 2... But then again, you guys over the pond may believe the same about users who put the month in the middle :-P, especially because in English, July 2 sounds a lot better than 2nd of July, something that does not neccessarily apply to other languages (i.e. in German, you would never say Juli 2 but always Zweiter Juli). I use 2008-02-07 whenever possible. It's clear that it means February 7 and it sorts properly, but dd/mm vs. mm/dd can be a really tricky problem.  Anoter fun thing, Number formats! 10.000,50 vs 10,000.50 vs. 10 000,50 vs. 10'000,50... This is my biggest nightmare right now, having to support a multi-cultural environent but not having any way to reliably know what number format the user will use.  Formal or Informal. In some language, there are two ways to address people, a formal way and a more informal way. In English, you just say \"You\", but in German you have to decide between the formal \"Sie\" and the informal \"Du\", same for French Tu/Vous. It's usually a safe bet to choose the formal way, but this is easily overlooked.  Calendars. In Europe, the first day of the Week is Monday, whereas in the US it's Sunday. Calendar Widgets are nice. Showing a Calendar with Sunday on the left and Saturday on the right to a European user is not so nice, it confuses them.  ", 
        "type": "2", 
        "id": "921", 
        "parentId": "898"
    }, 
    {
        "content": "What's the simplest way to connect and query a database for a set of records in C#? ", 
        "type": "1", 
        "id": "930", 
        "parentId": -1
    }, 
    {
        "content": "@Bernard:     I have to admit, most of your example went straight over my head. It does compile, and seems to work, though. Is this safe for SMP systems or SpeedStep?   That's a good question... I think the code's ok. From a practical standpoint, we use it in my company every day, and we run on a pretty wide array of boxes, everything from 2-8 cores. Of course, YMMV, etc, but it seems to be a reliable and low-overhead (because it doesn't make a context switch into system-space) method of timing.  Generally how it works is:   declare the block of code to be assembler (and volatile, so the optimizer will leave it alone). execute the CPUID instruction.  In addition to getting some CPU information (which we don't do anything with) it synchronizes the CPU's execution buffer so that the timings aren't affected by out-of-order execution. execute the rdtsc (read timestamp) execution.  This fetches the number of machine cycles executed since the processor was reset.  This is a 64-bit value, so with current CPU speeds it will wrap around every 194 years or so. Interestingly, in the original Pentium reference, they note it wraps around every 5800 years or so. the last couple of lines store the values from the registers into the variables hi and lo, and put that into the 64-bit return value.   Specific notes:   out-of-order execution can cause incorrect results, so we execute the \"cpuid\" instruction which in addition to giving you some information about the cpu also synchronizes any out-of-order instruction execution. Most OS's synchronize the counters on the CPUs when they start, so the answer is good to within a couple of nano-seconds. The hibernating comment is probably true, but in practice you probably don't care about timings across hibernation boundaries. regarding speedstep: Newer Intel CPUs compensate for the speed changes and returns an adjusted count.  I did a quick scan over some of the boxes on our network and found only one box that didn't have it: a Pentium 3 running some old database server. (these are linux boxes, so I checked with: grep constant_tsc /proc/cpuinfo) I'm not sure about the AMD CPUs, we're primarily an Intel shop, although I know some of our low-level systems gurus did an AMD evaluation.   Hope this satisfies your curiosity, it's an interesting and (IMHO) under-studied area of programming.  You know when Jeff and Joel were talking about whether or not a programmer should know C?  I was shouting at them, \"hey forget that high-level C stuff... assembler is what you should learn if you want to know what the computer is doing!\" ", 
        "type": "2", 
        "id": "931", 
        "parentId": "88"
    }, 
    {
        "content": "Attempting to insert an escape character into a table results in a warning.   For example:  create table EscapeTest (text varchar(50));  insert into EscapeTest (text) values ('This is the first part \\n And this is the second');   Produces the warning:  WARNING:  nonstandard use of escape in a string literal   (Using PSQL 8.2)  Anyone know how to get around this? ", 
        "type": "1", 
        "id": "935", 
        "parentId": -1
    }, 
    {
        "content": "Does doubling the \\ work?    insert into EscapeTest (text) values ('This will be inserted \\\\n This will not be');", 
        "type": "2", 
        "id": "936", 
        "parentId": "935"
    }, 
    {
        "content": "Partially. The text is inserted, but the warning is still generated.  I found a discussion that indicated the text needed to be preceded with 'E', as such:  insert into EscapeTest (text) values (E'This is the first part \\n And this is the second');   This suppressed the warning, but the text was still not being returned correctly. When I added the additional slash as Michael suggested, it worked.  As such:  insert into EscapeTest (text) values (E'This is the first part \\\\n And this is the second');  ", 
        "type": "2", 
        "id": "938", 
        "parentId": "935"
    }, 
    {
        "content": "There is nothing I know of that can do this without you at least writing a little bit of code... You will need 2 separate library:   A CSV Parser Framework  An XML Serialization Framework   The CSV parser I would recommend (unless you want to have a little bit of fun to write your own CSV Parser) is OpenCSV (A SourceForge Project for parsing CSV Data)  The XML Serialization Framework should be something that can scale in case you want to transform large (or huge) CSV file to XML: My recommendation is the Sun Java Streaming XML Parser Framework (See here) which allows pull-parsing AND serialization. ", 
        "type": "2", 
        "id": "939", 
        "parentId": "123"
    }, 
    {
        "content": "Very roughly and from memory since I don't have code on this laptop:  using (OleDBConnection conn = new OleDbConnection()) {   conn.ConnectionString = \"Whatever connection string\";    using (OleDbCommand cmd = new OleDbCommand())   {     cmd.Connection = conn;     cmd.CommandText = \"Select * from CoolTable\";      using (OleDbDataReader dr = cmd.ExecuteReader())     {       while (dr.Read())       {         // do something like Console.WriteLine(dr[\"column name\"] as String);       }     }   } }  ", 
        "type": "2", 
        "id": "940", 
        "parentId": "930"
    }, 
    {
        "content": "All editions of SQL Server 2000/2005/2008 support having multiple databases, each using their own collation sequence.  You don't need the Enterprise version.    When you have a database that uses a collation sequence that is different from default collation for the database server, you will need to take some extra precautions if you use temporary tables and/or table variables.  Temp tables/variables live in the tempdb database, which uses the collation seqyuence used by by the master databases.  Just remember to use \"COLLATE database_default\" when defining character fields in the temp tables/variables.  I blogged about that not too long ago, if you want some more details. ", 
        "type": "2", 
        "id": "942", 
        "parentId": "905"
    }, 
    {
        "content": "Cool.    I also found the documentation regarding the E:    http://www.postgresql.org/docs/8.3/interactive/sql-syntax-lexical.html#SQL-SYNTAX-STRINGS        PostgreSQL also accepts \"escape\" string constants, which are an extension to the SQL standard. An escape string constant is specified by writing the letter E (upper or lower case) just before the opening single quote, e.g. E'foo'. (When continuing an escape string constant across lines, write E only before the first opening quote.) Within an escape string, a backslash character (\\) begins a C-like backslash escape sequence, in which the combination of backslash and following character(s) represents a special byte value. \\b is a backspace, \\f is a form feed, \\n is a newline, \\r is a carriage return, \\t is a tab. Also supported are \\digits, where digits represents an octal byte value, and \\xhexdigits, where hexdigits represents a hexadecimal byte value. (It is your responsibility that the byte sequences you create are valid characters in the server character set encoding.) Any other character following a backslash is taken literally. Thus, to include a backslash character, write two backslashes (\\\\). Also, a single quote can be included in an escape string by writing \\', in addition to the normal way of ''.  ", 
        "type": "2", 
        "id": "943", 
        "parentId": "935"
    }, 
    {
        "content": "I'm maintaining a .NET 1.1 application, and one of the things I've been tasked with is making sure the user doesn't see any unfriendly error notifications.  I've added handlers to Application.ThreadException and AppDomain.CurrentDomain.UnhandledException, which do get called. My problem is that the standard CLR error dialog is still displayed (before the exception handler is called).  Jeff talks about this problem on his blog here and here. But there's no solution. So what is the standard way in .NET 1.1 to handle uncaught exceptions and display a friendly dialog box?  Edit: Jeff's response was marked as the correct answer, because the link he provided has the most complete information on how to do what's required. ", 
        "type": "1", 
        "id": "944", 
        "parentId": -1
    }, 
    {
        "content": "I have imported the kernel32 library so I have the createMutex function available but I am not quite sure of the various parameters and return values.  This is classic Visual Basic, not Visual Basic.NET but I can probably work with either language in the form of an answer. ", 
        "type": "1", 
        "id": "947", 
        "parentId": -1
    }, 
    {
        "content": "You can upgrade 6.5 to SQL Server 2000.  You may have an easier time getting a hold of SQL Server or the 2000 version of the MSDE.  Microsoft has a page on going from 6.5 to 2000.  Once you have the database in 2000 format, SQL Server 2005 will have no trouble upgrading it to the 2005 format.      If you don't have SQL Server 2000, you can download the MSDE 2000 version directly from Microsoft.", 
        "type": "2", 
        "id": "950", 
        "parentId": "194"
    }, 
    {
        "content": "@Goyuix -- that's excellent for something written from memory. tested it here -- found the connection wasn't opened. Otherwise very nice.  using System.Data.OleDb; ...  using (OleDbConnection conn = new OleDbConnection()) {     conn.ConnectionString = \"Provider=sqloledb;Data Source=yourServername\\\\yourInstance;Initial Catalog=databaseName;Integrated Security=SSPI;\";      using (OleDbCommand cmd = new OleDbCommand())     {         conn.Open();         cmd.Connection = conn;         cmd.CommandText = \"Select * from yourTable\";          using (OleDbDataReader dr = cmd.ExecuteReader())         {             while (dr.Read())             {                 Console.WriteLine(dr[\"columnName\"]);             }         }     } }  ", 
        "type": "2", 
        "id": "951", 
        "parentId": "930"
    }, 
    {
        "content": "Encoding flash video is actually very easy with ffmpeg.  You can use one command to convert from just about any video format, ffmpeg is smart enough to figure the rest out, and it'll use every processor on your machine.  Invoking it is easy:    ffmpeg -i input.avi output.flv    ffmpeg will guess at the bitrate you want, but if you'd like to specify one, you can use the -b option, so -b 500000 is 500kbps for example.  There's a ton of options of course, but I generally get good results without much tinkering.  This is a good place to start if you're looking for more options: video options.    You don't need a special web server to show flash video.  I've done just fine by simply pushing .flv files up to a standard web server, and linking to them with a good swf player, like flowplayer.    WMVs are fine if you can be sure that all of your users will always use [a recent, up to date version of] Windows only, but even then, Flash is often a better fit for the web.  The player is even extremely skinnable and can be controlled with javascript.", 
        "type": "2", 
        "id": "971", 
        "parentId": "164"
    }, 
    {
        "content": "I've read that it is possible to add a method to an existing object (e.g. not in the class definition) in Python, I think this is called Monkey Patching (or in some cases Duck Punching). I understand that it's not always a good decision to do so. But, how might one do this?  UPDATE 8/04/2008 00:21:01 EST:  That looks like a good answer John Downey, I tried it but it appears that it ends up being not a true method.  Your example defines the new patch function with an argument of self, but if you write actual code that way, the now patched class method asks for an argument named self (it doesn't automagically recognize it as the object to which it is supposed to bind, which is what would happen if defined within the class definition), meaning you have to call class.patch(obj) instead of just class.patch() if you want the same functionality as a true method.  It looks like Python isn't really treating it as a method, but more just as a variable which happens to be a function (and as such is callable).  Is there any way to attach an actual method to a class?  Oh, and Ryan, that isn't exactly what I was looking for (it isn't a builtin functionality), but it is quite cool nonetheless. ", 
        "type": "1", 
        "id": "972", 
        "parentId": -1
    }, 
    {
        "content": "The database will do this for you.  Look at \"select ... for update\", which is designed just for this kind of thing.  It will give you a write lock on the selected rows, which you can then commit or roll back.", 
        "type": "2", 
        "id": "981", 
        "parentId": "833"
    }, 
    {
        "content": "In Python monkey patching generally works by overwriting a class or functions signature with your own. Below is an example from the Zope Wiki:    from SomeOtherProduct.SomeModule import SomeClassdef speak(self):   return \"ook ook eee eee eee!\"SomeClass.speak = speak    That code will overwrite/create a method called speak on the class. In Jeff Atwood's recent post on monkey patching. He shows an example in C# 3.0 which is the current language I use for work.", 
        "type": "2", 
        "id": "982", 
        "parentId": "972"
    }, 
    {
        "content": "I don't know Python syntax, but I know Ruby can do it, and it is rather trivial.  Let's say you want to add a method to Array that prints the length to standard out:    class Array  def print_length    puts length  endend    If you don't want to modify the whole class, you can just add the method to a single instance of the array, and no other arrays will have the method:    array = [1, 2, 3]def array.print_length  puts lengthend    Just be aware of the issues involved in using this feature.  Jeff Atwood actually wrote about it not too long ago.", 
        "type": "2", 
        "id": "984", 
        "parentId": "972"
    }, 
    {
        "content": "is this a console app or a winforms app? If it's a .NET 1.1 console app this is, sadly, by design -- it's confirmed by a MSFT dev in the second blog post you referenced:        BTW, on my 1.1 machine the example from MSDN does have the expected output; it's just that the second line doesn't show up until after you've attached a debugger (or not). In v2 we've flipped things around so that the UnhandledException event fires before the debugger attaches, which seems to be what most people expect.      Sounds like .NET 2.0 does this better (thank goodness), but honestly, I never had time to go back and check.", 
        "type": "2", 
        "id": "986", 
        "parentId": "944"
    }, 
    {
        "content": "It's a WinForms app. The exceptions that are caught by Application.ThreadException work fine, and I don't get the ugly .NET exception box (OK to terminate, cancel to debug? who came up with that??).    I was getting some exceptions that weren't being caught by that and ended up going to the AppDomain.UnhandledException event that were causing problems. I think I've caught most of those exceptions and I am displaying them in our nice error box now.    So I'll just have to hope there are not some other circumstances that would cause exceptions to not be caught by the Application.ThreadException handler.", 
        "type": "2", 
        "id": "990", 
        "parentId": "944"
    }, 
    {
        "content": "Often while editing config files, I'll open one with vi and then when I go to save it realize that I didn't type    sudo vi filename      Is there any way to give vi sudo privileges to save the file? I seem to recall seeing something about this while looking up some stuff about vi a while ago, but now I can't find it.", 
        "type": "1", 
        "id": "1005", 
        "parentId": -1
    }, 
    {
        "content": "A quick Google seems to give this advice:      Don't try to edit if it's read-only.  You might be able to change the permissions on the file. (Whether or not it will let you save is up to experimentation.)  If you still edited anyway, save to a temporary file and then move it.      http://ubuntuforums.org/showthread.php?t=782136", 
        "type": "2", 
        "id": "1006", 
        "parentId": "1005"
    }, 
    {
        "content": "I need to grab the base64-encoded representation of the ViewState. Obviously this would not be available until fairly late in the request lifecycle, which is OK.  For example, if the output of the page includes:  <input type=\"hidden\" name=\"__VIEWSTATE\"    id=\"__VIEWSTATE\" value=\"/wEPDwUJODU0Njc5MD...==\" />   I need a way on the server side to get the value \"/wEPDwUJODU0Njc5MD...==\"  To clarify, I need this value when the page is being rendered, not on PostBack. e.g. I need to know the ViewState value that is being sent to the client, not the ViewState I'm getting back from them. ", 
        "type": "1", 
        "id": "1010", 
        "parentId": -1
    }, 
    {
        "content": "Ryan's advice is generally good, however, if following step 3, don't move the temporary file; it'll have the wrong ownership and permissions. Instead, sudoedit the correct file and read in the contents (using :r or the like) of the temporary file.    If following step 2, use :w! to force the file to be written.", 
        "type": "2", 
        "id": "1012", 
        "parentId": "1005"
    }, 
    {
        "content": "Oh, in WinForms you definitely should be able to get it to work. The only thing you have to watch out for is things happening on different threads.    I have an old CodeProject article here which should help:    http://www.codeproject.com/KB/exception/ExceptionHandling.aspx", 
        "type": "2", 
        "id": "1016", 
        "parentId": "944"
    }, 
    {
        "content": "That's definitely a good way to do it.  But you if you happen to be using a database that supports LINQ to SQL, it can be a lot more fun.  It can look something like this:    MyDB db = new MyDB(\"Data Source=...\");var q = from db.MyTable        select c;foreach (var c in q)  Console.WriteLine(c.MyField.ToString());", 
        "type": "2", 
        "id": "1022", 
        "parentId": "930"
    }, 
    {
        "content": "The CCNetArtifactDirectory is passed to the MSBuild by default, so you dont need to worry about it. MSBuild will place the build output in the \"bin location\" relevant to the working directory that you have specified.  <executable>c:\\WINDOWS\\Microsoft.NET\\Framework\\v3.5\\MSBuild.exe</executable> <workingDirectory>C:\\data\\projects\\FooSolution\\</workingDirectory> <projectFile>FooSolution.sln</projectFile> <buildArgs>/noconsolelogger /p:Configuration=Debug </buildArgs>   So in the above example your build output will be put in C:\\data\\projects\\FooSolution[ProjectName]\\bin\\Debug. Should you want to output to a different location you may want to look at of the  tag in CCNET.  <publishers>   <xmllogger />   <buildpublisher>     <sourceDir>C:\\data\\projects\\FooSolution\\FooProject\\bin\\Debug</sourceDir>     <publishDir>C:\\published\\FooSolution\\</publishDir>     <useLabelSubDirectory>false</useLabelSubDirectory>   </buildpublisher> </publishers>   This will allow you to publish your output to a different location. ", 
        "type": "2", 
        "id": "1023", 
        "parentId": "835"
    }, 
    {
        "content": "After upgrading a rails 1.2 website to 2.1, the ExceptionNotifier plugin no longer works, complaining about this error:  ActionView::TemplateFinder::InvalidViewPath:  Unprocessed view path found: \"/path/to/appname/vendor/plugins/exception_notification/lib/../views\".  Set your view paths with #append_view_path, #prepend_view_path, or #view_paths=.   What causes it and how do I fix it? ", 
        "type": "1", 
        "id": "1024", 
        "parentId": -1
    }, 
    {
        "content": "Well, based on the documentation it looks like:   Security attributes (can pass null) Whether it's initially owned (can pass false) The name of it   HTH ", 
        "type": "2", 
        "id": "1025", 
        "parentId": "947"
    }, 
    {
        "content": "This was caused by a change in rails 2.1 which prevents rails from loading views from any arbitrary path for security reasons.  There is now an updated version of the plugin on github, so the solution is to use that.    The old solution here for posterity  To work around it, edit init.rb under your vendor/plugins/exception_notification directory, and add the following code to the end  ActionController::Base.class_eval do   append_view_path File.dirname(__FILE__) + '/lib/../views' end   This adds the ExceptionNotifier plugins' views folder to the list, so it is allowed to load them. ", 
        "type": "2", 
        "id": "1026", 
        "parentId": "1024"
    }, 
    {
        "content": "The VB code looks something like this:  hMutex = CreateMutex(ByVal 0&, 1, ByVal 0&)   The first parameter is a pointer to an SECURITY_ATTRIBUTES structure. If you don't know what it is, you don't need it. Pass NULL (0).  The second parameter is TRUE (non-zero, or 1) if the calling thread should take ownership of the mutex. FALSE otherwise.  The third parameter is the mutex name and may be NULL (0), as shown. If you need a named mutex, pass the name (anything unique) in. Not sure whether the VB wrapper marshals the length-prefixed VB string type (BSTR) over to a null-terminated Ascii/Unicode string if not, you'll need to do that and numerous examples are out there.  Good luck! ", 
        "type": "2", 
        "id": "1028", 
        "parentId": "947"
    }, 
    {
        "content": "Does anyone know of a simple way to retrieve the country for a given IP Address? Preferably in ISO_3166-1 format? ", 
        "type": "1", 
        "id": "1033", 
        "parentId": -1
    }, 
    {
        "content": "Here's a nice free service with a public API:  http://www.hostip.info/use.html", 
        "type": "2", 
        "id": "1034", 
        "parentId": "1033"
    }, 
    {
        "content": "What is the best way to display Flash content in a C# WinForms application? I would like to create a user control (similar to the current PictureBox) that will be able to display images and flash content.  It would be great to be able to load the flash content from a stream of sorts rather than a file on disk. ", 
        "type": "1", 
        "id": "1037", 
        "parentId": -1
    }, 
    {
        "content": "While I haven't used a flash object inside a windows form application myself, I do know that it's possible.  In Visual studio on your toolbox, choose to add a new component.  Then in the new window that appears choose the \"COM Components\" tab to get a list in which you can find the \"Shockwave Flash Object\"    Once added to the toolbox, simply use the control as you would use any other \"standard\" control from visual studio.    three simple commands are available to interact with the control:      AxShockwaveFlash1.Stop()  AxShockwaveFlash1.Movie = FilePath &  \"\\FileName.swf\"  AxShockwaveFlash1.Play()      which, I think, are all self explanatory.        It would be great to be able to load    the flash content from a stream of    sorts rather than a file on disk.      I just saw you are also looking for a means to load the content from a stream,  and because I'm not really sure that is possible with the shockwave flash object I will give you another option (two actually).    the first is the one I would advise you to use only when necessary, as it uses the full blown \"webbrowser component\" (also available as an extra toolbox item), which is like trying to shoot a fly with a bazooka.  of course it will work, as the control will act as a real browser window (actually the internet explorer browser), but its not really meant to be used in the way you need it.    the second option is to use something I just discovered while looking for more information about playing flash content inside a windows form. F-IN-BOX is a commercial solution that will also play content from a given website URL. (The link provided will direct you to the .NET code you have to use).", 
        "type": "2", 
        "id": "1039", 
        "parentId": "1037"
    }, 
    {
        "content": "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete(). ", 
        "type": "1", 
        "id": "1040", 
        "parentId": -1
    }, 
    {
        "content": "I'm looking for a robust, easy-to-use, regular expression evaluator for native C++, either platform-independent or Windows-specific.  Requirements:   Can't use Boost or ACE regex libraries (unfortunately) Can't use .NET Regex (or any managed code)   The main requirement is that it should be standalone and open. ", 
        "type": "1", 
        "id": "1041", 
        "parentId": -1
    }, 
    {
        "content": "For instance, my query is like the following using SQL Server 2005:  SELECT * FROM Table WHERE FREETEXT(SearchField, 'c#')   I have a full text index defined to use the column SearchField which returns results when using:  SELECT * FROM Table WHERE SearchField LIKE '%c#%'   I believe # is a special letter, so how do I allow FREETEXT to work correctly for the query above? ", 
        "type": "1", 
        "id": "1042", 
        "parentId": -1
    }, 
    {
        "content": "You can use this program, Handle, to find which process has the lock on your file. It's a command-line tool, so I guess you use the output from that... I'm not sure about finding it programmatically.  If deleting the file can wait, you could specify it for deletion when your computer next starts up:   Start REGEDT32 (W2K) or REGEDIT (WXP) and navigate to:  HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Session Manager  W2K and WXP   W2K:EditAdd Value...Data Type: REG_MULTI_SZValue Name: PendingFileRenameOperationsOK WXP:EditNewMulti-String Valueenter PendingFileRenameOperations  In the Data area, enter \"\\??\\\" + filename to be deleted. LFNs may be entered without being embedded in quotes. To delete C:\\Long Directory Name\\Long File Name.exe, enter the following data:  \\??\\C:\\Long Directory Name\\Long File Name.exe   Then press OK. The \"destination file name\" is a null (zero) string. It is entered as follows:   W2K:EditBinaryselect Data Format: Hexclick at the end of the hex stringenter 0000 (four zeros)OK WXP:Right-click the valuechoose \"Modify Binary Data\"click at the end of the hex stringenter 0000 (four zeros)OK  Close REGEDT32/REGEDIT and reboot to delete the file.   (Shamelessly stolen from some random forum, for posterity's sake.) ", 
        "type": "2", 
        "id": "1043", 
        "parentId": "1040"
    }, 
    {
        "content": "Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the MoveFileEx API function to mark the file for deletion upon next reboot.  If it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions. ", 
        "type": "2", 
        "id": "1044", 
        "parentId": "1040"
    }, 
    {
        "content": "Quoting a much-replicated help page about Indexing Service query language:     To use specially treated characters such as &, |, ^, #, @, $, (, ), in a query, enclose your query in quotation marks (\u201c).   As far as I know, full text search in MSSQL is also done by the Indexing Service, so this might help. ", 
        "type": "2", 
        "id": "1047", 
        "parentId": "1042"
    }, 
    {
        "content": "If you want to do it programatically. I'm not sure... and I'd really recommend against it.  If you're just troubleshooting stuff on your own machine, SysInternals Process Explorer can help you    Run it, use the Find Handle command (I think it's either in the find or handle menu), and search for the name of your file. Once the handle(s) is found, you can forcibly close them.    You can then delete the file and so on.    Beware, doing this may cause the program which owns the handles to behave strangely, as you've just pulled the proverbial rug out from under it, but it works well when you are debugging your own errant code, or when visual studio / windows explorer is being crap and not releasing file handles even though you told them to close the file ages ago... sigh :-)", 
        "type": "2", 
        "id": "1049", 
        "parentId": "1040"
    }, 
    {
        "content": "Oh, one big hack I employed years ago, is that Windows won't let you delete files, but it does let you move them.  Pseudo-sort-of-code:  mv %WINDIR%\\System32\\mfc42.dll %WINDIR\\System32\\mfc42.dll.old Install new mfc42.dll Tell user to save work and restart applications   When the applications restarted (note we didn't need to reboot the machine), they loaded the new mfc42.dll, and all was well. That, coupled with PendingFileOperations to delete the old one the next time the whole system restarted, worked pretty well. ", 
        "type": "2", 
        "id": "1050", 
        "parentId": "1040"
    }, 
    {
        "content": "The typical method is as follows. You've said you want to do this in C# so here goes...    If you don't know which process has the file locked, you'll need to examine each process's handle list, and query each handle to determine if it identifies the locked file. Doing this in C# will likely require P/Invoke or an intermediary C++/CLI to call the native APIs you'll need.  Once you've figured out which process(es) have the file locked, you'll need to safely inject a small native DLL into the process (you can also inject a managed DLL, but this is messier, as you then have to start or attach to the .NET runtime).  That bootstrap DLL then closes the handle using CloseHandle etc.  Essentially: the way to unlock a \"locked\" file is to inject a DLL into the offending process's address space and close it yourself. You can do this using native or managed code. No matter what, you're going to need a small amount of native code or at least P/Invoke into the same.  Helpful links:    http://www.codeproject.com/KB/threads/winspy.aspx  http://damianblog.com/2008/07/02/net-code-injection/  Good luck!", 
        "type": "2", 
        "id": "1051", 
        "parentId": "1040"
    }, 
    {
        "content": "Most mathematicians agree that:     e\u03c0i + 1 = 0   However, most floating point implementations disagree. How well can we settle this dispute?  I'm keen to hear about different languages and implementations, and various methods to make the result as close to zero as possible. Be creative! ", 
        "type": "1", 
        "id": "1053", 
        "parentId": -1
    }, 
    {
        "content": "Here's a short list of implementations and languages I've tried. It's sorted by closeness to zero:   Scheme: (+ 1 (make-polar 1 (atan 0 -1)))  \u21d2 0.0+1.2246063538223773e-16i (Chez Scheme, MIT Scheme) \u21d2 0.0+1.22460635382238e-16i (Guile) \u21d2 0.0+1.22464679914735e-16i (Chicken with numbers egg) \u21d2 0.0+1.2246467991473532e-16i (MzScheme, SISC, Gauche, Gambit) \u21d2 0.0+1.2246467991473533e-16i (SCM)  Common Lisp: (1+ (exp (complex 0 pi)))  \u21d2 #C(0.0L0 -5.0165576136843360246L-20) (CLISP) \u21d2 #C(0.0d0 1.2246063538223773d-16) (CMUCL) \u21d2 #C(0.0d0 1.2246467991473532d-16) (SBCL)  Perl: use Math::Complex; Math::Complex->emake(1, pi) + 1  \u21d2 1.22464679914735e-16i  Python: from cmath import exp, pi; exp(complex(0, pi)) + 1  \u21d2 1.2246467991473532e-16j (CPython)  Ruby: require 'complex'; Complex::polar(1, Math::PI) + 1  \u21d2 Complex(0.0, 1.22464679914735e-16) (MRI) \u21d2 Complex(0.0, 1.2246467991473532e-16) (JRuby)  R: complex(argument = pi) + 1  \u21d2 0+1.224606353822377e-16i   ", 
        "type": "2", 
        "id": "1054", 
        "parentId": "1053"
    }, 
    {
        "content": "try libpcre    If you're stuck on windows they have a windows port which should work. I know e-texteditor uses it, so at least that's proof it works :-)", 
        "type": "2", 
        "id": "1055", 
        "parentId": "1041"
    }, 
    {
        "content": "A lot of people (including my company) seem to use MaxMind GeoIP.  They have a free version GeoLite which is not as accurate as the paid version, but if you're just after something simple, it may be good enough. ", 
        "type": "2", 
        "id": "1056", 
        "parentId": "1033"
    }, 
    {
        "content": "Is it possible to settle this dispute?  My first thought is to look to a symbolic language, like Maple. I don't think that counts as floating point though.  In fact, how does one represent i (or j for the engineers) in a conventional programming language?  Perhaps a better example is sin(\u03c0) = 0? (Or have I missed the point again?) ", 
        "type": "2", 
        "id": "1057", 
        "parentId": "1053"
    }, 
    {
        "content": "The # char is indexed as punctuation and therefore ignored, so it looks like we'll remove the letter C from our word indexing ignore lists.    Tested it locally after doing that and rebuilding the indexes and I get results!    Looking at using a different word breaker language on the indexed column, so that those special characters aren't ignored.    EDIT: I also found this information:        c# is indexed as c (if c is not in your noise word list, see more on noise word lists later), but C# is indexed as C# (in SQL 2005 and SQL 2000 running on Win2003 regardless if C or c is in your noise word list). It is not only C# that is stored as C#, but any capital letter followed by #. Conversely, c++ ( and any other lower-cased letter followed by a ++) is indexed as c (regardless of whether c is in your noise word list).  ", 
        "type": "2", 
        "id": "1061", 
        "parentId": "1042"
    }, 
    {
        "content": "The GNU C Library supports regular expressions.  It's open, and the RE code seems to be easily extractable.", 
        "type": "2", 
        "id": "1062", 
        "parentId": "1041"
    }, 
    {
        "content": "I'd like to display ~100 floating cubes using DirectX or OpenGL.  I'm looking for either some sample source code, or a description of the technique. I know this kind of thing is easy for you accomplished '3D' gurus out there but I have enough trouble getting even one cube to display correctly.  I've combed the net for a good series of tutorials and although they talk about how to do 3D primitives, what I can't find is information on how to do large numbers of 3D primitives - cubes, spheres, pyramids, and so forth. ", 
        "type": "1", 
        "id": "1064", 
        "parentId": -1
    }, 
    {
        "content": "In general, you can't change the effective user id of the vi process, but you can do this:    :w !sudo tee myfile", 
        "type": "2", 
        "id": "1065", 
        "parentId": "1005"
    }, 
    {
        "content": "Sven, you reached the same conclusion as I did: I found the Shockwave Flash Object, all be it from a slightly different route, but was stumped on how to load the files from somewhere other than file on disk/URL. The F-IN-BOX, although just a wrapper of the Shockwave Flash Object seems to provide much more functionality, which may just help me!  Shooting flys with bazookas may be fun, but an embeded web brower is not the path that I am looking for. :)  There was a link on Adobe's site that talked about \"Embedding and Communicating with the Macromedia Flash Player in C# Windows Applications\" but they seem to have removed it :( ", 
        "type": "2", 
        "id": "1066", 
        "parentId": "1037"
    }, 
    {
        "content": "I'm working on a multithreaded C++ application that is corrupting the heap.  The usual tools to locate this corruption seem to be inapplicable.  Old builds (18 months old) of the source code exhibit the same behaviour as the most recent release, so this has been around for a long time and just wasn't noticed; on the downside, source deltas can't be used to identify when the bug was introduced - there are a lot of code changes in the repository.  The prompt for crashing behaviuor is to generate throughput in this system - socket transfer of data which is munged into an internal representation.  I have a set of test data that will periodically cause the app to exception (various places, various causes - including heap alloc failing, thus: heap corruption).  The behaviour seems related to CPU power or memory bandwidth; the more of each the machine has, the easier it is to crash.  Disabling a hyper-threading core or a dual-core core reduces the rate of (but does not eliminate) corruption.  This suggests a timing related issue.  Now here's the rub: When it's run under a lightweight debug environment (say Visual Studio 98 / AKA MSVC6) the heap corruption is reasonably easy to reproduce - ten or fifteen minutes pass before something fails horrendously and exceptions, like an alloc; when running under a sophisticated debug environment (Rational Purify, VS2008/MSVC9 or even Microsoft Application Verifier) the system becomes memory-speed bound and doesn't crash (Memory-bound: CPU is not getting above 50%, disk light is not on, the program's going as fast it can, box consuming 1.3G of 2G of RAM).  So, I've got a choice between being able to reproduce the problem (but not identify the cause) or being able to idenify the cause or a problem I can't reproduce.  My current best guesses as to where to next is:   Get an insanely grunty box (to replace the current dev box: 2Gb RAM in an E6550 Core2 Duo); this will make it possible to repro the crash causing mis-behaviour when running under a powerful debug environment; or Rewrite operators new and delete to use VirtualAlloc and VirtualProtect to mark memory as read-only as soon as it's done with.  Run under MSVC6 and have the OS catch the bad-guy who's writing to freed memory.  Yes, this is a sign of desperation: who the hell rewrites new and delete?!  I wonder if this is going to make it as slow as under Purify et al.   And, no: Shipping with Purify instrumentation built in is not an option.  A colleague just walked past and asked \"Stack Overflow?  Are we getting stack overflows now?!?\"  And now, the question: How do I locate the heap corruptor?    Update: balancing new[] and delete[] seems to have gotten a long way towards solving the problem.  Instead of 15mins, the app now goes about two hours before crashing.  Not there yet.  Any further suggestions? The heap corruption persists.  Update: a release build under Visual Studio 2008 seems dramatically better; current suspicion rests on the STL implementation that ships with VS98.          Reproduce the problem. Dr Watson will produce a dump that might be helpful in further analysis.       I'll take a note of that, but I'm concerned that Dr Watson will only be tripped up after the fact, not when the heap is getting stomped on.     Another try might be using WinDebug as a debugging tool which is quite powerful being at the same time also lightweight.   Got that going at the moment, again: not much help until something goes wrong.  I want to catch the vandal in the act.     Maybe these tools will allow you at least to narrow the problem to certain component.   I don't hold much hope, but desperate times call for...     And are you sure that all the components of the project have correct runtime library settings (C/C++ tab, Code Generation category in VS 6.0 project settings)?   No I'm not, and I'll spend a couple of hours tomorrow going through the workspace (58 projects in it) and checking they're all compiling and linking with the appropriate flags.  Update: This took 30 seconds.  Select all projects in the Settings dialog, unselect until you find the project(s) that don't have the right settings (they all had the right settings). ", 
        "type": "1", 
        "id": "1069", 
        "parentId": -1
    }, 
    {
        "content": "What is the correct way to get the process size on Solaris, HP-UX and AIX? Should we use top or ps -o vsz or something else? ", 
        "type": "1", 
        "id": "1070", 
        "parentId": -1
    }, 
    {
        "content": "What I did when working against a database of unknown performance was to measure turnaround time on my queries.  I kept upping the thread count until turn-around time dropped, and dropping the thread count until turn-around time improved (well, it was processes in my environment, but whatever).    There were moving averages and all sorts of metrics involved, but the take-away lesson was: just adapt to how things are working at the moment.  You never know when the DBAs will improve performance or hardware will be upgraded, or perhaps another process will come along to load down the system while you're running.  So adapt.  Oh, and another thing: avoid process switches if you can - batch things up.    Oh, I should make this clear: this all happened at run time, not during development. ", 
        "type": "2", 
        "id": "1071", 
        "parentId": "264"
    }, 
    {
        "content": "You tried old builds, but is there a reason you can't keep going further back in the repository history and seeing exactly when the bug was introduced?    Otherwise, I would suggest adding simple logging of some kind to help track down the problem, though I am at a loss of what specifically you might want to log.    If you can find out what exactly CAN cause this problem, via google and documentation of the exceptions you are getting, maybe that will give further insight on what to look for in the code.", 
        "type": "2", 
        "id": "1072", 
        "parentId": "1069"
    }, 
    {
        "content": "My first choice would be a dedicated heap tool such as pageheap.exe.  Rewriting new and delete might be useful, but that doesn't catch the allocs committed by lower-level code. If this is what you want, better to Detour the low-level alloc APIs using Microsoft Detours.  Also sanity checks such as: verify your run-time libraries match (release vs. debug, multi-threaded vs. single-threaded, dll vs. static lib), look for bad deletes (eg, delete where delete [] should have been used), make sure you're not mixing and matching your allocs.  Also try selectively turning off threads and see when/if the problem goes away.  What does the call stack etc look like at the time of the first exception? ", 
        "type": "2", 
        "id": "1073", 
        "parentId": "1069"
    }, 
    {
        "content": "Rex, I suspect a good place to start looking is solutions that compress the ViewState -- they're grabbing ViewState on the server before it's sent down to the client and gzipping it. That's exactly where you want to be.      Scott Hanselman on ViewState Compression (2005)  ViewState Compression with System.IO.Compression (2007)  ", 
        "type": "2", 
        "id": "1074", 
        "parentId": "1010"
    }, 
    {
        "content": "The trouble with international standards is that pretty much noone uses them. I try where I can, but I am forced to use dd/mm/yyyy almost everywhere in real life, which means I am so used to it it's always a conscious process to use ISO-8601. For the majority of people who don't even try to use ISO-8601 it's even worse. If you can internationalize where you can, I think it's a great advantage.", 
        "type": "2", 
        "id": "1077", 
        "parentId": "761"
    }, 
    {
        "content": "Yes, you are right to lock at the VSZ.  ps u will give you the VSZ and RSS, which are the virtual memory size and resident set size.  The RSS is how much physical memory has been allocated to the process, and the VSZ is the virtual memory size of the process.  If you have several copies of a program running, a lot of the memory in the VSZ will be shared between those processes. ", 
        "type": "2", 
        "id": "1082", 
        "parentId": "1070"
    }, 
    {
        "content": "I was wondering if there is any good and clean oo implementation of bayesian filtering for spam and text classification? For learning purposes.", 
        "type": "1", 
        "id": "1083", 
        "parentId": -1
    }, 
    {
        "content": "My first action would be as follows:    Build the binaries in \"Release\" version but creating debug info file (you will find this possibility in project settings).  Use Dr Watson as a defualt debugger (DrWtsn32 -I) on a machine on which you want to reproduce the problem.  Repdroduce the problem. Dr Watson will produce a dump that might be helpful in further analysis.   Another try might be using WinDebug as a debugging tool which is quite powerful being at the same time also lightweight.   Maybe these tools will allow you at least to narrow the problem to certain component.  And are you sure that all the components of the project have correct runtime library settings (C/C++ tab, Code Generation category in VS 6.0 project settings)?", 
        "type": "2", 
        "id": "1086", 
        "parentId": "1069"
    }, 
    {
        "content": "Maybe https://ci-bayes.dev.java.net/ or http://www.cs.cmu.edu/~javabayes/Home/node2.html?  I never played with it either. ", 
        "type": "2", 
        "id": "1090", 
        "parentId": "1083"
    }, 
    {
        "content": "Just use glTranslatef (or the DirectX equivalent) to draw a cube using the same code, but moving the relative point where you draw it. Maybe there's a better way to do it though, I'm fairly new to OpenGL. Be sure to set your viewpoint so you can see them all.", 
        "type": "2", 
        "id": "1092", 
        "parentId": "1064"
    }, 
    {
        "content": "See this blog post where the author describes a method for overriding the default behavior for generating the ViewState and instead shows how to save it on the server Session object.        In ASP.NET 2.0, ViewState is saved by    a descendant of PageStatePersister    class. This class is an abstract class    for saving and loading ViewsState and    there are two implemented descendants    of this class in .Net Framework, named    HiddenFieldPageStatePersister and    SessionPageStatePersister. By default    HiddenFieldPageStatePersister is used    to save/load ViewState information,    but we can easily get the    SessionPageStatePersister to work and    save ViewState in Session object.      Although I did not test his code, it seems to show exactly what you want: a way to gain access to ViewState code while still on the server, before postback. ", 
        "type": "2", 
        "id": "1093", 
        "parentId": "1010"
    }, 
    {
        "content": "Here is an implementation of Bayesian filtering in C#: A Naive Bayesian Spam Filter for C# (hosted on CodeProject).", 
        "type": "2", 
        "id": "1095", 
        "parentId": "1083"
    }, 
    {
        "content": "You say you have enough trouble getting one cube to display... so I am not sure if you have got one to display or not.    Basically... put your code for writing a cube in one function, then just call that function 100 times.    void DrawCube(){    //code to draw the cube}void DisplayCubes(){    for(int i = 0; i < 10; ++i)    {            for(int j = 0; j < 10; ++j)         {             glPushMatrix();             //alter these values depending on the size of your cubes.             //This call makes sure that your cubes aren't drawn overtop of each other             glTranslatef(i*5.0, j*5.0, 0);             DrawCube();             glPopMatrix();         }    }              }    That is the basic outline for how you could go about doing this. If you want something more efficient take a look into Display Lists sometime once you have the basics figured out :)", 
        "type": "2", 
        "id": "1096", 
        "parentId": "1064"
    }, 
    {
        "content": "Exceptions in C++ don't need to be caught (no compile time errors) by the calling function. So it's up to developer's judgment whether to catch it using try/catch (unlike in Java).   Is there a way one can ensure that the exceptions thrown are always caught using try/catch by the calling function? ", 
        "type": "1", 
        "id": "1104", 
        "parentId": -1
    }, 
    {
        "content": "Given that indexing is so important as your data set increases in size, can someone explain how does indexing works at a database agnostic level?  For information on queries to index a field, check out How do I index a database column ", 
        "type": "1", 
        "id": "1108", 
        "parentId": -1
    }, 
    {
        "content": "No.  See A Pragmatic Look at Exception Specifications for reasons why not.   The only way you can \"help\" this is to document the exceptions your function can throw, say as a comment in the header file declaring it. This is not enforced by the compiler or anything. Use code reviews for that purpose. ", 
        "type": "2", 
        "id": "1109", 
        "parentId": "1104"
    }, 
    {
        "content": "AppDomain.UnhandledException is an event, not a global exception handler. This means, by the time it is raised, your application is already on its way down the drain, and there is nothing you can do about it, except for doing cleanup and error logging.    What happened behind the scenes is this: The framework detected the exception, walked up the call stack to the very top, found no handlers that would recover from the error, so was unable to determine if it was safe to continue execution. So, it started the shutdown sequence, and fired up this event as a courtesy to you so you can pay your respects to your already-doomed process. This happens when an exception is left unhandled in the main thread.    There is no single-point solution to this kind of error. You need to put a real exception handler (a catch block) upstream of all places where this error occurs and forward it to (for example) a global handler method/class that will determine if it is safe to simply report and continue, based on exception type and/or content.    Edit: It is possible to disable (=hack) the error-reporting mechanism built into Windows so the mandatory \"crash and burn\" dialog does not get displayed when your app goes down. However, this becomes effective for all the applications in the system, not just your own.", 
        "type": "2", 
        "id": "1114", 
        "parentId": "944"
    }, 
    {
        "content": "I've just set up Sandcastle again. Try installing it (the May 2008 release) and search for SandcastleGui.exe or something similar (it's in the examples folder or so).  Click Add Assembly and add your Assembly or Assemblies, add any .xml Documentation files (the ones generated by the compiler if you enabled that option) and then Build.  It will take some time, but the result will be worth the effort. It will actually look up stuff from MSDN, so your resulting documentation will also have the Class Inheritance all the way down to System.Object with links to MSDN and stuff.  Sandcastle seems a bit complicated at first, especially when you want to use it in an automated build, but I am absolutely sure it will be worth the effort.  Also have a look at Sandcastle Help File Builder, this is a somewhat more advanced GUI for it. ", 
        "type": "2", 
        "id": "1120", 
        "parentId": "855"
    }, 
    {
        "content": "Follow this simple 5 step article and you are pretty much done. As a bonus you can use H2Viewer to view Html Help 2.x files.", 
        "type": "2", 
        "id": "1123", 
        "parentId": "855"
    }, 
    {
        "content": "Why is it needed?  When data is stored on disk based storage devices, it is stored as blocks of data. These blocks are accessed in their entirety, making them the atomic disk access operation. Disk blocks are structured in much the same way as linked lists; both contain a section for data, a pointer to the location of the next node (or block), and both need not be stored contiguously.  Due to the fact that a number of records can only be sorted on one field, we can state that searching on a field that isn\u2019t sorted requires a Linear Search which requires N/2 block accesses (on average), where N is the number of blocks that the table spans. If that field is a non-key field (i.e. doesn\u2019t contain unique entries) then the entire table space must be searched at N block accesses.  Whereas with a sorted field, a Binary Search may be used, this has log2 N block accesses. Also since the data is sorted given a non-key field, the rest of the table doesn\u2019t need to be searched for duplicate values, once a higher value is found. Thus the performance increase is substantial.  What is indexing?  Indexing is a way of sorting a number of records on multiple fields. Creating an index on a field in a table creates another data structure which holds the field value, and pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it.  The downside to indexing is that these indexes require additional space on the disk, since the indexes are stored together in a table using the MyISAM engine, this file can quickly reach the size limits of the underlying file system if many fields within the same table are indexed.  How does it work?  Firstly, let\u2019s outline a sample database table schema;    Field name       Data type      Size on disk id (Primary key) Unsigned INT   4 bytes firstName        Char(50)       50 bytes lastName         Char(50)       50 bytes emailAddress     Char(100)      100 bytes   Note: char was used in place of varchar to allow for an accurate size on disk value.  This sample database contains five million rows, and is unindexed. The performance of several queries will now be analyzed. These are a query using the id (a sorted key field) and one using the firstName (a non-key unsorted field).  Example 1  Given our sample database of r = 5,000,000 records of a fixed size giving a record length of R = 204 bytes and they are stored in a table using the MyISAM engine which is using the default block size B = 1,024 bytes. The blocking factor of the table would be bfr = (B/R) = 1024/204 = 5 records per disk block. The total number of blocks required to hold the table is N = (r/bfr) = 5000000/5 = 1,000,000 blocks.   A linear search on the id field would require an average of N/2 = 500,000 block accesses to find a value given that the id field is a key field. But since the id field is also sorted a binary search can be conducted requiring an average of log2 1000000 = 19.93 = 20 block accesses. Instantly we can see this is a drastic improvement.  Now the firstName field is neither sorted nor a key field, so a binary search is impossible, nor are the values unique, and thus the table will require searching to the end for an exact N = 1,000,000 block accesses. It is this situation that indexing aims to correct.  Given that an index record contains only the indexed field and a pointer to the original record, it stands to reason that it will be smaller than the multi-field record that it points to. So the index itself requires fewer disk blocks than the original table, which therefore requires fewer block accesses to iterate through. The schema for an index on the firstName field is outlined below;    Field name       Data type      Size on disk firstName        Char(50)       50 bytes (record pointer) Special        4 bytes   Note: Pointers in MySQL are 2, 3, 4 or 5 bytes in length depending on the size of the table.  Example 2  Given our sample database of r = 5,000,000 records with an index record length of R = 54 bytes and using the default block size B = 1,024 bytes. The blocking factor of the index would be bfr = (B/R) = 1024/54 = 18 records per disk block. The total number of blocks required to hold the table is N = (r/bfr) = 5000000/18 = 277,778 blocks.   Now a search using the firstName field can utilise the index to increase performance. This allows for a binary search of the index with an average of log2 277778 = 18.08 = 19 block accesses. To find the address of the actual record, which requires a further block access to read, bringing the total to 19 + 1 = 20 block accesses, a far cry from the 277,778 block accesses required by the non-indexed table.  When should it be used?  Given that creating an index requires additional disk space (277,778 blocks extra from the above example), and that too many indexes can cause issues arising from the file systems size limits, careful thought must be used to select the correct fields to index.  Since indexes are only used to speed up the searching for a matching field within the records, it stands to reason that indexing fields used only for output would be simply a waste of disk space and processing time when doing an insert or delete operation, and thus should be avoided. Also given the nature of a binary search, the cardinality or uniqueness of the data is important. Indexing on a field with a cardinality of 2 would split the data in half, whereas a cardinality of 1,000 would return approximately 1,000 records. With such a low cardinality the effectiveness is reduced to a linear sort, and the query optimizer will avoid using the index if the cardinality is less than 30% of the record number, effectively making the index a waste of space. ", 
        "type": "2", 
        "id": "1130", 
        "parentId": "1108"
    }, 
    {
        "content": "Back in the old days, Help was not trivial but possible: generate some funky .rtf file with special tags, run it through a compiler, and you got a WinHelp file (.hlp) that actually works really well.  Then, Microsoft decided that WinHelp was not hip and cool anymore and switched to CHM, up to the point they actually axed WinHelp from Vista.  Now, CHM maybe nice, but everyone that tried to open a .chm file on the Network will know the nice \"Navigation to the webpage was canceled\" screen that is caused by security restrictions.  While there are ways to make CHM work off the network, this is hardly a good choice, because when a user presses the Help Button he wants help and not have to make some funky settings.  Bottom Line: I find CHM absolutely unusable. But with WinHelp not being an option anymore either, I wonder what the alternatives are, especially when it comes to integrate with my Application (i.e. for WinHelp and CHM there are functions that allow you to directly jump to a topic)?  PDF has the disadvantage of requiring the Adobe Reader (or one of the more lightweight ones that not many people use). I could live with that seeing as this is kind of standard nowadays, but can you tell it reliably to jump to a given page/anchor?  HTML files seem to be the best choice, you then just have to deal with different browsers (CSS and stuff).  Edit: I am looking to create my own Help Files. As I am a fan of the \"No Setup, Just Extract and Run\" Philosophy, i had that problem many times in the past because many of my users will run it off the network, which causes exactly this problem.  So i am looking for a more robust and future-proof way to provide help to my users without having to code a different help system for each application i make.  CHM is a really nice format, but that Security Stuff makes it unusable, as a Help system is supposed to provide help to the user, not to generate even more problems. ", 
        "type": "1", 
        "id": "1131", 
        "parentId": -1
    }, 
    {
        "content": "HTML would be the next best choice, ONLY IF you would serve them from a public web server. If you tried to bundle it with your app, all the files (and images (and stylesheets (and ...) ) ) would make CHM look like a gift from gods.    That said, when actually bundled in the installation package, (instead of being served over the network), I found the CHM files to work nicely.    OTOH, another pitfall about CHM files: Even if you try to open a CHM file on a local disk, you may bump into the security block if you initially downloaded it from somewhere, because the file could be marked as \"came from external source\" when it was obtained.", 
        "type": "2", 
        "id": "1135", 
        "parentId": "1131"
    }, 
    {
        "content": "Is the question how to generate your own help files, or what is the best help file format?    Personally, I find CHM to be excellent.  One of the first things I do when setting up a machine is to download the PHP Manual in CHM format (http://www.php.net/download-docs.php) and add a hotkey to it in Crimson Editor.  So when I press F1 it loads the CHM and performs a search for the word my cursor is on (great for quick function reference).  ", 
        "type": "2", 
        "id": "1136", 
        "parentId": "1131"
    }, 
    {
        "content": "Our software is both distributed locally to the clients and served from a network share. We opted for generating both a CHM file and a set of HTML files for serving from the network. Users starting the program locally use the CHM file, and users getting their program served from a network share has to use the HTML files.    We use Help and Manual and can thus easily produce both types of output from the same source project. The HTML files also contain searching capabilities and doesn't require a web server, so though it isn't an optimal solution, works fine.    So far all the single-file types for Windows seems broken in one way or another:      WinHelp - obsoleted  HtmlHelp (CHM) - obsoleted on Vista, doesn't work from network share, other than that works really nice  Microsoft Help 2 (HXS) - this seems to work right up until the point when it doesn't, corrupted indexes or similar, this is used by Visual Studio 2005 and above, as an example  ", 
        "type": "2", 
        "id": "1141", 
        "parentId": "1131"
    }, 
    {
        "content": "In French, but you should be able to find the download link :)  PHP Naive Bayesian Filter", 
        "type": "2", 
        "id": "1142", 
        "parentId": "1083"
    }, 
    {
        "content": "I've tried to write a string replace function in C, which works on a char *, which has been allocated using malloc().  It's a little different in that it will find and replace strings, rather than characters in the starting string.  It's trivial to do if the search and replace strings are the same length (or the replace string is shorter than the search string), since I have enough space allocated.  If I try to use realloc(), I get an error that tells me I am doing a double free - which I don't see how I am, since I am only using realloc().  Perhaps a little code will help:  void strrep(char *input, char *search, char *replace) {     int searchLen = strlen(search);     int replaceLen = strlen(replace);     int delta = replaceLen - searchLen;     char *find = input;      while (find = strstr(find, search)) {          if (delta > 0) {             realloc(input, strlen(input) + delta);             find = strstr(input, search);                     }          memmove(find + replaceLen, find + searchLen, strlen(input) - (find - input));         memmove(find, replace, replaceLen);     } }   The program works, until I try to realloc() in an instance where the replaced string will be longer than the initial string.  (It still kind of works, it just spits out errors as well as the result).  If it helps, the calling code looks like:  #include <stdio.h> #include <string.h> #include <stdlib.h>  void strrep(char *input, char *search, char *replace);  int main(void) {     char *input = malloc(81);      while ((fgets(input, 81, stdin)) != NULL) {         strrep(input, \"Noel\", \"Christmas\");     } }  ", 
        "type": "1", 
        "id": "1145", 
        "parentId": -1
    }, 
    {
        "content": "    Anyone know of any services that will    match IP to geographic location      Well, lucky for you that answer can be found on our very own stackoverflow website:  http://stackoverflow.com/questions/1033/ip-to-country    spoiler: http://www.hostip.info/use.html", 
        "type": "2", 
        "id": "1148", 
        "parentId": "13"
    }, 
    {
        "content": "Just a shot in the dark because I haven't tried it yet but when you realloc it returns the pointer much like malloc. Because realloc can move the pointer if needed you are most likely operating on an invalid pointer if you don't do the following:    input = realloc(input, strlen(input) + delta);", 
        "type": "2", 
        "id": "1149", 
        "parentId": "1145"
    }, 
    {
        "content": "Note, try to edit your code to get rid of the html escape codes.    Well, though it has been a while since I used C/C++, realloc that grows only reuses the memory pointer value if there is room in memory after your original block.    For instance, consider this:    (xxxxxxxxxx..........)    If your pointer points to the first x, and . means free memory location, and you grow the memory size pointed to by your variable by 5 bytes, it'll succeed. This is of course a simplified example as blocks are rounded up to a certain size for alignment, but anyway.    However, if you subsequently try to grow it by another 10 bytes, and there is only 5 available, it will need to move the block in memory and update your pointer.    However, in your example you are passing the function a pointer to the character, not a pointer to your variable, and thus while the strrep function internally might be able to adjust the variable in use, it is a local variable to the strrep function and your calling code will be left with the original pointer variable value.    This pointer value, however, has been freed.    In your case, input is the culprit.    However, I would make another suggestion. In your case it looks like the input variable is indeed input, and if it is, it shouldn't be modified, at all.    I would thus try to find another way to do what you want to do, without changing input, as side-effects like this can be hard to track down.", 
        "type": "2", 
        "id": "1153", 
        "parentId": "1145"
    }, 
    {
        "content": "As a general rule, you should never do a free or realloc on a user provided buffer. You don't know where the user allocated the space (in your module, in another DLL) so you cannot use any of the allocation functions on a user buffer.    Provided that you now cannot do any reallocation within your function, you should change a little its behavior like doing only one replacement, so the user will be able to compute the resulting string max length and provide you with a buffer long enough for this one replacement to occur.    Then you could create another function to do the multiple replacements, but you will have to allocate the whole space for the resulting string and copy the user input string. Then you must provide a way to delete the string you allocated.    Resulting in:    void  strrep(char *input, char *search, char *replace);char* strrepm(char *input, char *search, char *replace);void  strrepmfree(char *input);", 
        "type": "2", 
        "id": "1154", 
        "parentId": "1145"
    }, 
    {
        "content": "My quick hints.  Instead of: void strrep(char *input, char *search, char *replace) try: void strrep(char *&input, char *search, char *replace)  and than in the body: input = realloc(input, strlen(input) + delta);  Generally read about passing function arguments as values/reference and realloc() description :).", 
        "type": "2", 
        "id": "1155", 
        "parentId": "1145"
    }, 
    {
        "content": "Hopefully, I can get answers for each database server.    For an outline of how indexing works check out: http://stackoverflow.com/questions/1108/how-does-database-indexing-work", 
        "type": "1", 
        "id": "1156", 
        "parentId": -1
    }, 
    {
        "content": "The following is SQL92 standard so should be supported by the majority of RDMBS that use SQL:    CREATE INDEX [index name] ON [table name] ( [column name] )", 
        "type": "2", 
        "id": "1157", 
        "parentId": "1156"
    }, 
    {
        "content": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.    I would like to use the latest revision number to generate AssemblyInfo.cs while compiling.  How can I retrieve the latest revision from subversion and use the value in CCNET?    Edit: I'm not using NAnt - only MSBuild.", 
        "type": "1", 
        "id": "1160", 
        "parentId": -1
    }, 
    {
        "content": "This seems to work;    char *strrep(char *string, const char *search, const char *replace) {    char *p = strstr(string, search);    if (p) {        int occurrence = p - string;        int stringlength = strlen(string);        int searchlength = strlen(search);        int replacelength = strlen(replace);        if (replacelength > searchlength) {            string = (char *) realloc(string, strlen(string)                 + replacelength - searchlength + 1);        }        if (replacelength != searchlength) {            memmove(string + occurrence + replacelength,                         string + occurrence + searchlength,                         stringlength - occurrence - searchlength + 1);        }        strncpy(string + occurrence, replace, replacelength);    }    return string;}    Sigh, is there anyway to post code without it sucking?", 
        "type": "2", 
        "id": "1163", 
        "parentId": "1145"
    }, 
    {
        "content": "I am currently \"manually\" doing it through a prebuild-exec Task, using my cmdnetsvnrev tool, but if someone knows a better ccnet-integrated way of doing it, i'd be happy to hear :-)", 
        "type": "2", 
        "id": "1164", 
        "parentId": "1160"
    }, 
    {
        "content": "I found this project on google code. This is CCNET plugin to generate the label in CCNET.  The DLL is tested with CCNET 1.3 but it works with CCNET 1.4 for me. I'm successfully using this plugin to label my build.  Now onto passing it to MSBuild... ", 
        "type": "2", 
        "id": "1168", 
        "parentId": "1160"
    }, 
    {
        "content": "You have basically two options. Either you write a simple script that will start and parse output from  svn.exe info --revision HEAD  to obtain revision number (then generating AssemblyInfo.cs is pretty much straight forward) or just use plugin for CCNET. Here it is:     SVN Revision Labeller is a plugin for   CruiseControl.NET that allows you to   generate CruiseControl labels for your   builds, based upon the revision number   of your Subversion working copy. This   can be customised with a prefix and/or   major/minor version numbers.      http://code.google.com/p/svnrevisionlabeller/   I prefer the first option because it's only roughly 20 lines of code:  using System; using System.Diagnostics;  namespace SvnRevisionNumberParserSample {     class Program     {         static void Main()         {             Process p = Process.Start(new ProcessStartInfo()                 {                     FileName = @\"C:\\Program Files\\SlikSvn\\bin\\svn.exe\", // path to your svn.exe                     UseShellExecute = false,                     RedirectStandardOutput = true,                     Arguments = \"info --revision HEAD\",                     WorkingDirectory = @\"C:\\MyProject\" // path to your svn working copy                 });              // command \"svn.exe info --revision HEAD\" will produce a few lines of output             p.WaitForExit();              // our line starts with \"Revision: \"             while (!p.StandardOutput.EndOfStream)             {                 string line = p.StandardOutput.ReadLine();                 if (line.StartsWith(\"Revision: \"))                 {                     string revision = line.Substring(\"Revision: \".Length);                     Console.WriteLine(revision); // show revision number on screen                                            break;                 }             }              Console.Read();         }     } }  ", 
        "type": "2", 
        "id": "1169", 
        "parentId": "1160"
    }, 
    {
        "content": "I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS. ", 
        "type": "1", 
        "id": "1171", 
        "parentId": -1
    }, 
    {
        "content": "If you prefer doing it on the MSBuild side over the CCNet config, looks like the MSBuild Community Tasks extension's SvnVersion task might do the trick. ", 
        "type": "2", 
        "id": "1172", 
        "parentId": "1160"
    }, 
    {
        "content": "A dictionary may also contain overhead, depending on the actual implementation. A hashtable usually contain some prime number of available nodes to begin with, even though you might only use a couple of the nodes.    Judging by your example, \"Property\", would you be better of with a class approach for the final level and real properties? Or is the names of the properties changing a lot from node to node?    I'd say that what \"efficient\" means depends on a lot of things, like:      speed of updates (insert, update, delete)  speed of random access retrieval  speed of sequential retrieval  memory used      I think that you'll find that a data structure that is speedy will generally consume more memory than one that is slow. This isn't always the case, but most data structures seems to follow this.    A dictionary might be easy to use, and give you relatively uniformly fast access, it will most likely use more memory than, as you suggest, lists. Lists, however, generally tend to contain more overhead when you insert data into it, unless they preallocate X nodes, in which they will again use more memory.    My suggestion, in general, would be to just use the method that seems the most natural to you, and then do a \"stress test\" of the system, adding a substantial amount of data to it and see if it becomes a problem.    You might also consider adding a layer of abstraction to your system, so that you don't have to change the programming interface if you later on need to change the internal data structure.", 
        "type": "2", 
        "id": "1174", 
        "parentId": "1171"
    }, 
    {
        "content": "If you are doing \"just extract and run\", you are going to run in security issues.  This is especially true if you are users are running Vista (or later).  is there a reason why you wanted to avoid packaging your applications inside an installer?  Using an installer would alleviate the \"external source\" problem.  You would be able to use .chm files without any problems.    We use InstallAware to create our install packages.  It's not cheap, but is very good.  If cost is your concern, WIX is open source and pretty robust.  WIX does have a learning curve, but it's easy to work with.", 
        "type": "2", 
        "id": "1175", 
        "parentId": "1131"
    }, 
    {
        "content": "I have just recently started to study Ruby, and in lieu of Jeff's advice over the weekend...      Stop theorizing.  Write lots of software.  Learn from your mistakes.       ...I was interested in honing my skills while helping out the Open Source Community the process so I thought I'd ask if anyone have any suggestions for cool/interesting Open Source Projects written in Ruby that you know of or are involved in.", 
        "type": "1", 
        "id": "1176", 
        "parentId": -1
    }, 
    {
        "content": "I am looking to allow users to control of subdomain of an app I am toying with, much like Basecamp where it is customusername.seework.com.  What is required on the DNS end to allow these to be created dynamically and be available instantly.   And how do you recommend dealing with this in the logic of the site? Htaccess rule to  lookup the subdomain in the DB? ", 
        "type": "1", 
        "id": "1180", 
        "parentId": -1
    }, 
    {
        "content": "The GNU C library regular expressions facility (regcomp(), regexec() and friends) is broken. Use libetre instead; the function signatures match the ones provided by glibc.  http://laurikari.net/tre/", 
        "type": "2", 
        "id": "1183", 
        "parentId": "1041"
    }, 
    {
        "content": "The trick to that is to use URL rewriting so that name.domain.com transparently maps to something like domain.com/users/name on your server.  Once you start down that path, it's fairly trivial to implement.", 
        "type": "2", 
        "id": "1185", 
        "parentId": "1180"
    }, 
    {
        "content": "Well, you didn't specify Rails, so I'm going to throw Shoes out there. First, building shoes apps is probably the best way to learn Ruby (Rails is great, but I find mastering Ruby far more fun/useful). Secondly, while I certainly don't think building crossplatform UI components is trivial, shoes is relatively new, and relatively small. There are no doubt countless additions that could be made. ", 
        "type": "2", 
        "id": "1186", 
        "parentId": "1176"
    }, 
    {
        "content": "Don't worry about DNS and URL rewriting    Your DNS record will be static, something like:    *.YOURDOMAIN.COM A 123.123.123.123    Ask your DNS provider to do it for you (if it's not done already) or do it by yourself if you have control over your DNS records. This will automatically point all your subdomains (current and future ones) into the same HTTP server.    Once it's done, you will only need to parse HOST header on every single http request to detect what hostname was used to access your server-side scripts on your http server.    Assuming you're using ASP.NET, this is kind of silly example I came up with but works and demonstrates simplicity of this approach:    <%@ Language=\"C#\" %><%string subDomain = Request.Url.Host.Split('.')[0].ToUpper();if (subDomain == \"CLIENTXXX\") Response.Write(\"Hello CLIENTXXX, your secret number is 33\");else if (subDomain == \"CLIENTYYY\") Response.Write(\"Hello CLIENTYYY, your secret number is 44\");else Response.Write(subDomain+\" doesn't exist\");%>", 
        "type": "2", 
        "id": "1187", 
        "parentId": "1180"
    }, 
    {
        "content": "One of the sites I maintain relies heavily on use of ViewState (it isn't my code). However, on certain pages where the ViewState is extra-bloated, Safari throws a \"Validation of viewstate MAC failed\" error.  This appears to only happen in Safari. Firefox, IE and Opera all load successfully in the same scenario. ", 
        "type": "1", 
        "id": "1189", 
        "parentId": -1
    }, 
    {
        "content": "I've been doing a little research into this and whilst I'm not entirely sure its the cause I believe it is because Safari is not returning the full result set (hence cropping it).    I have been in dicussion with another developer and found the following post on Channel 9 as well which recommends making use of the SQL State service to store the viewstate avoiding the postback issue and also page size.    http://channel9.msdn.com/forums/TechOff/250549-ASPNET-ViewState-flawed-architecture/?CommentID=270477#263702    Does this seem like the best solution?", 
        "type": "2", 
        "id": "1190", 
        "parentId": "1189"
    }, 
    {
        "content": "Making a class-based structure would probably have more overhead than the dict-based structure, since in python classes actually use dicts when they are implemented.", 
        "type": "2", 
        "id": "1191", 
        "parentId": "1171"
    }, 
    {
        "content": "My first port of call would be to go through the elements on the page and see which controls:      Will still work when I switch ViewState off  Can be moved out of the page and into an AJAX call to be loaded when required      Failing that, and here's the disclaimer - I've never used this solution on a web-facing site - but in the past where I've wanted to eliminate massive ViewStates in limited-audience applications I have stored the ViewState in the Session.    It has worked for me because the hit to memory isn't significant for the number of users, but if you're running a fairly popular site I wouldn't recommend this approach.  However, if the Session solution works for Safari you could always detect the user agent and fudge appropriately.", 
        "type": "2", 
        "id": "1202", 
        "parentId": "1189"
    }, 
    {
        "content": "    Customizing csproj files to autogenerate AssemblyInfo.cs     http://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx        Every time we create a new C# project,    Visual Studio puts there the    AssemblyInfo.cs file for us. The file    defines the assembly meta-data like    its version, configuration, or    producer.      Found the above technique to auto-gen AssemblyInfo.cs using MSBuild. Will post sample shortly.", 
        "type": "2", 
        "id": "1216", 
        "parentId": "1160"
    }, 
    {
        "content": "C and C++ compilers will generate a warning when you compare signed and unsigned types; in your example code, you couldn't make your loop variable unsigned and have the compiler generate code without warnings (assuming said warnings were turned on).    Naturally, you're compiling with warnings turned all the way up, right?    And, have you considered compiling with \"treat warnings as errors\" to take it that one step further?    The downside with using signed numbers is that there's a temptation to overload them so that, for example, the values 0->n are the menu selection, and -1 means nothing's selected - rather than creating a class that has two variables, one to indicate if something is selected and another to store what that selection is.  Before you know it, you're testing for negative one all over the place and the compiler is complaining about how you're wanting to compare the menu selection against the number of menu selections you have - but that's dangerous because they're different types.  So don't do that.", 
        "type": "2", 
        "id": "1226", 
        "parentId": "336"
    }, 
    {
        "content": "I want to link to a specific slide in an online PowerPoint file, (e.g.  http://www.example.com/hello.ppt) but what I want is that when people click on my link, it goes straight to the nth slide.  Is this possible? ", 
        "type": "1", 
        "id": "1229", 
        "parentId": -1
    }, 
    {
        "content": "The way we do this is to have a 'catch all' for our domain name registered in DNS so that anything.ourdomain.com will point to our server.  With Apache you can set up a similar catch-all for your vhosts.  The ServerName must be a single static name but the ServerAlias directive can contain a pattern.  Servername www.ourdomain.com ServerAlias *.ourdomain.com   Now all of the domains will trigger the vhost for our project.  The final part is to decode the domain name actually used so that you can work out the username in your code, something like (PHP):  list( $username ) = explode( \".\", $_SERVER[ \"HTTP_HOST\" ] );   or a RewriteRule as already suggested that silently maps user.ourdomain.com/foo/bar to www.ourdomain.com/foo/bar?user=user or whatever you prefer. ", 
        "type": "2", 
        "id": "1232", 
        "parentId": "1180"
    }, 
    {
        "content": "I have written a NAnt build file that handles parsing SVN information and creating properties. I then use those property values for a variety of build tasks, including setting the label on the build. I use this target combined with the SVN Revision Labeller mentioned by lubos hasko with great results.    <target name=\"svninfo\" description=\"get the svn checkout information\">    <property name=\"svn.infotempfile\" value=\"${build.directory}\\svninfo.txt\" />    <exec program=\"${svn.executable}\" output=\"${svn.infotempfile}\">        <arg value=\"info\" />    </exec>    <loadfile file=\"${svn.infotempfile}\" property=\"svn.info\" />    <delete file=\"${svn.infotempfile}\" />    <property name=\"match\" value=\"\" />    <regex pattern=\"URL: (?'match'.*)\" input=\"${svn.info}\" />    <property name=\"svn.info.url\" value=\"${match}\"/>    <regex pattern=\"Repository Root: (?'match'.*)\" input=\"${svn.info}\" />    <property name=\"svn.info.repositoryroot\" value=\"${match}\"/>    <regex pattern=\"Revision: (?'match'\\d+)\" input=\"${svn.info}\" />    <property name=\"svn.info.revision\" value=\"${match}\"/>    <regex pattern=\"Last Changed Author: (?'match'\\w+)\" input=\"${svn.info}\" />    <property name=\"svn.info.lastchangedauthor\" value=\"${match}\"/>    <echo message=\"URL: ${svn.info.url}\" />    <echo message=\"Repository Root: ${svn.info.repositoryroot}\" />    <echo message=\"Revision: ${svn.info.revision}\" />    <echo message=\"Last Changed Author: ${svn.info.lastchangedauthor}\" /></target>", 
        "type": "2", 
        "id": "1235", 
        "parentId": "1160"
    }
]